{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import gc\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, StratifiedKFold, KFold, train_test_split, GridSearchCV \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import linear_model\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import shap\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, SelectPercentile, SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 302)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>0.726</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.415</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>2.493</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-1.887</td>\n",
       "      <td>2.412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>1.548</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-2.386</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>0.557</td>\n",
       "      <td>-0.881</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.247</td>\n",
       "      <td>2.316</td>\n",
       "      <td>1.268</td>\n",
       "      <td>1.679</td>\n",
       "      <td>...</td>\n",
       "      <td>1.131</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-1.398</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.667</td>\n",
       "      <td>-1.175</td>\n",
       "      <td>2.330</td>\n",
       "      <td>2.104</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-1.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.252</td>\n",
       "      <td>-1.370</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>2.246</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.479</td>\n",
       "      <td>-0.629</td>\n",
       "      <td>1.642</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.978</td>\n",
       "      <td>2.801</td>\n",
       "      <td>-1.643</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.864</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>1.598</td>\n",
       "      <td>-0.693</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>-0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.410</td>\n",
       "      <td>-1.097</td>\n",
       "      <td>1.170</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>-1.141</td>\n",
       "      <td>0.355</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.546</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>1.387</td>\n",
       "      <td>1.021</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>1.931</td>\n",
       "      <td>1.190</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.811</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>1.068</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>1.045</td>\n",
       "      <td>-1.281</td>\n",
       "      <td>-1.727</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-1.367</td>\n",
       "      <td>0.109</td>\n",
       "      <td>1.416</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1.458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target      0      1      2      3      4      5      6      7  ...    \\\n",
       "0   0     1.0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276  ...     \n",
       "1   1     0.0  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  ...     \n",
       "2   2     1.0 -0.523 -0.089 -0.348  0.148 -0.022  0.404 -0.023 -0.172  ...     \n",
       "3   3     1.0  0.067 -0.021  0.392 -1.637 -0.446 -0.725 -1.035  0.834  ...     \n",
       "4   4     1.0  2.347 -0.831  0.511 -0.021  1.225  1.594  0.585  1.509  ...     \n",
       "5   5     1.0 -0.641 -0.576  2.493  0.317  0.009  0.428 -1.887  2.412  ...     \n",
       "6   6     1.0 -0.490  0.557 -0.881  0.831  0.247  2.316  1.268  1.679  ...     \n",
       "7   7     1.0  1.252 -1.370 -0.196  2.246 -0.617 -0.479 -0.629  1.642  ...     \n",
       "8   8     1.0  1.410 -1.097  1.170 -0.091 -0.102 -0.835 -1.141  0.355  ...     \n",
       "9   9     1.0 -1.811  0.566 -0.406 -0.490 -0.985 -0.303  1.068 -0.038  ...     \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1 -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "2  0.013  0.263 -1.222  0.726  1.444 -1.165 -1.544  0.004  0.800 -1.211  \n",
       "3 -0.404  0.640 -0.595 -0.966  0.900  0.467 -0.562 -0.254 -0.533  0.238  \n",
       "4  0.898  0.134  2.415 -0.996 -1.006  1.378  1.246  1.478  0.428  0.253  \n",
       "5 -0.266  1.548 -0.523  0.923  0.021 -0.909  0.629 -2.386  0.265  0.549  \n",
       "6  1.131  0.808 -1.398  0.053  0.667 -1.175  2.330  2.104  0.007 -1.066  \n",
       "7 -1.978  2.801 -1.643 -0.244 -0.864 -0.022  1.598 -0.693 -0.358 -0.084  \n",
       "8 -1.546 -0.190  1.387  1.021 -0.912  0.094 -0.930  1.931  1.190  0.964  \n",
       "9 -0.705  1.045 -1.281 -1.727 -0.969 -1.367  0.109  1.416  1.472  1.458  \n",
       "\n",
       "[10 rows x 302 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определенной тематики нет, а значит пользуемся строго формальным описанием, фьючер импортанс и тп. \n",
    "# Посмотрим, на распределения, дисперсию, корреляции и далее :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        False\n",
       "target    False\n",
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3         False\n",
       "4         False\n",
       "5         False\n",
       "6         False\n",
       "7         False\n",
       "8         False\n",
       "9         False\n",
       "10        False\n",
       "11        False\n",
       "12        False\n",
       "13        False\n",
       "14        False\n",
       "15        False\n",
       "16        False\n",
       "17        False\n",
       "18        False\n",
       "19        False\n",
       "20        False\n",
       "21        False\n",
       "22        False\n",
       "23        False\n",
       "24        False\n",
       "25        False\n",
       "26        False\n",
       "27        False\n",
       "          ...  \n",
       "270       False\n",
       "271       False\n",
       "272       False\n",
       "273       False\n",
       "274       False\n",
       "275       False\n",
       "276       False\n",
       "277       False\n",
       "278       False\n",
       "279       False\n",
       "280       False\n",
       "281       False\n",
       "282       False\n",
       "283       False\n",
       "284       False\n",
       "285       False\n",
       "286       False\n",
       "287       False\n",
       "288       False\n",
       "289       False\n",
       "290       False\n",
       "291       False\n",
       "292       False\n",
       "293       False\n",
       "294       False\n",
       "295       False\n",
       "296       False\n",
       "297       False\n",
       "298       False\n",
       "299       False\n",
       "Length: 302, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis = 1)\n",
    "y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.609</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.606</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-3.138</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>1.428</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-2.009</td>\n",
       "      <td>-1.378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-1.327</td>\n",
       "      <td>2.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>-1.855</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1.592</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-1.419</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>0.916</td>\n",
       "      <td>2.411</td>\n",
       "      <td>1.053</td>\n",
       "      <td>-1.601</td>\n",
       "      <td>-1.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>1.173</td>\n",
       "      <td>-1.623</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-1.763</td>\n",
       "      <td>-1.432</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184</td>\n",
       "      <td>-1.090</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.186</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-1.153</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      0      1      2      3      4      5      6      7      8  ...    \\\n",
       "0  250  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535 -0.129 -0.687  ...     \n",
       "1  251  0.776  0.914 -0.494  1.347 -0.867  0.480  0.578 -0.313  0.203  ...     \n",
       "2  252  1.750  0.509 -0.057  0.835 -0.476  1.428 -0.701 -2.009 -1.378  ...     \n",
       "3  253 -0.556 -1.855 -0.682  0.578  1.592  0.512 -1.419  0.722  0.511  ...     \n",
       "4  254  0.754 -0.245  1.173 -1.623  0.009  0.370  0.781 -1.763 -1.432  ...     \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0 -0.088 -2.628 -0.845  2.078 -0.277  2.132  0.609 -0.104  0.312  0.979  \n",
       "1 -0.683 -0.066  0.025  0.606 -0.353 -1.133 -3.138  0.281 -0.625 -0.761  \n",
       "2 -0.094  0.351 -0.607 -0.737 -0.031  0.701  0.976  0.135 -1.327  2.463  \n",
       "3 -0.336 -0.787  0.255 -0.031 -0.836  0.916  2.411  1.053 -1.601 -1.529  \n",
       "4  2.184 -1.090  0.216  1.186 -0.143  0.322 -0.068 -0.156 -1.153  0.825  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.std().plot('hist')\n",
    "plt.title('STD for all columns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.mean().plot('hist')\n",
    "\n",
    "plt.title(\"Means for all columns\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    160\n",
       "0.0     90\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90892</th>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>0.246062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90893</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>0.246062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90894</th>\n",
       "      <td>193</td>\n",
       "      <td>101</td>\n",
       "      <td>0.252825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90895</th>\n",
       "      <td>101</td>\n",
       "      <td>193</td>\n",
       "      <td>0.252825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90896</th>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>0.259315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90897</th>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "      <td>0.259315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90898</th>\n",
       "      <td>target</td>\n",
       "      <td>65</td>\n",
       "      <td>0.293846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90899</th>\n",
       "      <td>65</td>\n",
       "      <td>target</td>\n",
       "      <td>0.293846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90900</th>\n",
       "      <td>33</td>\n",
       "      <td>target</td>\n",
       "      <td>0.373608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90901</th>\n",
       "      <td>target</td>\n",
       "      <td>33</td>\n",
       "      <td>0.373608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0 level_1         0\n",
       "90892      22      28  0.246062\n",
       "90893      28      22  0.246062\n",
       "90894     193     101  0.252825\n",
       "90895     101     193  0.252825\n",
       "90896      75      32  0.259315\n",
       "90897      32      75  0.259315\n",
       "90898  target      65  0.293846\n",
       "90899      65  target  0.293846\n",
       "90900      33  target  0.373608\n",
       "90901  target      33  0.373608"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs = train.corr().abs().unstack().sort_values(ascending=True).reset_index()\n",
    "corrs = corrs[corrs['level_0'] != corrs['level_1']]\n",
    "corrs.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# корреляции между признаками маленькие с самой большой в 0.374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 20\n",
    "SKfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "repeated_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models with strafitied KFold, oof and pred, template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, \n",
    "                X_test, \n",
    "                y, \n",
    "                params, \n",
    "                folds=SKfold, \n",
    "                model_type='lgb', \n",
    "                plot_feature_importance=False, \n",
    "                averaging='usual', \n",
    "                model=None\n",
    "                ):\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train)\n",
    "            valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "            \n",
    "            model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=2000,\n",
    "                    valid_sets = [train_data, valid_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_train.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X_train.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=20000,  eval_metric='AUC', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            # print(f'Fold {fold_n}. AUC: {score:.4f}.')\n",
    "            # print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "        if model_type == 'glm':\n",
    "            model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "            model_results = model.fit()\n",
    "            model_results.predict(X_test)\n",
    "            y_pred_valid = model_results.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            \n",
    "            y_pred = model_results.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "        if averaging == 'usual':\n",
    "            prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            prediction += pd.Series(y_pred).rank().values  \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_folds\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction, scores\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# очевидно, что логрег тут должен справиться хорошо, посмотрим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score :0.8169\n",
      "Best parameters :{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hq/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning:\n",
      "\n",
      "The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression(solver='liblinear', max_iter=10000)\n",
    "param_grid = {\"class_weight\" : ['balanced', None], \n",
    "              \"penalty\" : ['l1', \"l2\"],\n",
    "              'C' : [0.001, 0.01, 0.08, 0.1, 0.15, 1.0, 10.0, 100.0]\n",
    "              }\n",
    "CV = GridSearchCV(LR, param_grid = param_grid, cv = n_folds, scoring= 'roc_auc')\n",
    "CV.fit(X_train, y_train)\n",
    "print ('Best score :{}'.format(CV.best_score_))\n",
    "print ('Best parameters :{}'.format(CV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7063, std: 0.1132.\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(max_iter=10000, \n",
    "                                        class_weight=CV.best_params_['class_weight'],\n",
    "                                        penalty=CV.best_params_['penalty'], \n",
    "                                        C=CV.best_params_[\"C\"]\n",
    "                                        )\n",
    "\n",
    "oof_lr, prediction_lr, scores = train_model(X_train_scaled, X_test_scaled, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь взглянем на другие классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7549\n",
      "Best parameters: {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier()\n",
    "params = {'n_estimators' : [10, 50, 100, 1000],\n",
    "           'max_depth' : [None, 2, 3, 5, 10], # not really needed \n",
    "           'max_features' : ['sqrt', 'log2']\n",
    "          }\n",
    "CV = GridSearchCV(RF, param_grid = params, cv = n_folds, n_jobs = -1, scoring = 'roc_auc')\n",
    "CV.fit(X_train, y_train)\n",
    "print (\"Best score: {}\".format(CV.best_score_))\n",
    "print (\"Best parameters: {}\".format(CV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.5750, std: 0.0913.\n"
     ]
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(**CV.best_params_)\n",
    "oof_RF, prediction_RF, scores_RF = train_model(X_train_scaled, X_test_scaled, y_train, params = None, model_type = 'sklearn', model = RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7723000000000001\n",
      "Best parameters: {'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(probability = True, gamma = 'scale')\n",
    "params = {'C' : [0.001, 0.01, 0.1, 1, 10],\n",
    "          'kernel' : ['linear','poly', 'rbf']\n",
    "         }\n",
    "CV = GridSearchCV(svc, param_grid = params, cv = n_folds, scoring = 'roc_auc', n_jobs = -1)\n",
    "CV.fit(X_train, y_train)\n",
    "print ('Best score: {}'.format(CV.best_score_))\n",
    "print ('Best parameters: {}'.format(CV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.6750, std: 0.1399.\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability = True, gamma = 'scale', **CV.best_params_)\n",
    "oof_svc, prediction_svc, scores_svc = train_model(X_train_scaled, X_test_scaled, y_train, params = None, model_type = 'sklearn', model = svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC тоже справился хорошо, в любом случае позже сравним всех с логрегрессией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6427999999999999\n",
      "Best parameters: {'leaf_size': 5, 'n_neighbors': 10, 'weights': 'distance'}\n",
      "CV mean score: 0.5981, std: 0.1391.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "params = {'n_neighbors': [2, 3, 5, 10, 20],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'leaf_size': [5, 10, 30]\n",
    "                 }\n",
    "\n",
    "CV = GridSearchCV(knc, param_grid=params, cv=n_folds, scoring='roc_auc', n_jobs=-1)\n",
    "CV.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(CV.best_score_))\n",
    "print('Best parameters: {}'.format(CV.best_params_))\n",
    "knc = KNeighborsClassifier(**CV.best_params_)\n",
    "oof_knc, prediction_knc, scores_knc = train_model(X_train_scaled, X_test_scaled, y_train, params=None, model_type='sklearn', model=knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6477999999999999\n",
      "Best parameters: {'alpha': 0.0001}\n",
      "CV mean score: 0.5950, std: 0.1049.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "params = {'alpha': [0.0001, 1, 2, 10]\n",
    "                 }\n",
    "\n",
    "CV = GridSearchCV(bnb, param_grid=params, cv=n_folds, scoring='roc_auc', n_jobs=-1)\n",
    "CV.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(CV.best_score_))\n",
    "print('Best parameters: {}'.format(CV.best_params_))\n",
    "bnb = BernoulliNB(**CV.best_params_)\n",
    "oof_bnb, prediction_bnb, scores_bnb = train_model(X_train_scaled, X_test_scaled, y_train, params=None, model_type='sklearn', model=bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8341000000000001\n",
      "Best parameters: {'alpha': 0.05, 'l1_ratio': 0, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}\n",
      "CV mean score: 0.6750, std: 0.0855.\n"
     ]
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier(eta0=1, max_iter=1000, tol=0.0001)\n",
    "\n",
    "params = {'loss': ['log', 'modified_huber'],\n",
    "                  'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                  'alpha': [0.001, 0.01, 0.05],\n",
    "                  'l1_ratio': [0, 0.15, 0.5, 1.0],\n",
    "                  'learning_rate': ['optimal', 'invscaling', 'adaptive']\n",
    "                 }\n",
    "\n",
    "CV = GridSearchCV(sgd, param_grid=params, cv=n_folds, scoring='roc_auc', n_jobs=-1)\n",
    "CV.fit(X_train_scaled, y_train)\n",
    "print('Best score: {}'.format(CV.best_score_))\n",
    "print('Best parameters: {}'.format(CV.best_params_))\n",
    "sgd = linear_model.SGDClassifier(eta0=1, tol=0.0001, **CV.best_params_)\n",
    "oof_sgd, prediction_sgd, scores_sgd = train_model(X_train_scaled, X_test_scaled, y_train, params=None, model_type='sklearn', model=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.5819, std: 0.1431.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "gpc = GaussianProcessClassifier()\n",
    "oof_gpc, prediction_gpc, scores_gpc = train_model(X_train_scaled, X_test_scaled, y_train, params=None, model_type='sklearn', model=gpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7552000000000001\n",
      "Best parameters: {'max_depth': 5, 'n_estimators': 1000}\n",
      "CV mean score: 0.5000, std: 0.0000.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier()\n",
    "\n",
    "params = {'n_estimators': [10, 50, 100, 1000],\n",
    "                  'max_depth': [None, 3, 5, 15]\n",
    "                 }\n",
    "\n",
    "CV = GridSearchCV(etc, param_grid=params, cv=n_folds, scoring='roc_auc', n_jobs=-1)\n",
    "CV.fit(X_train_scaled, y_train)\n",
    "print('Best score: {}'.format(CV.best_score_))\n",
    "print('Best parameters: {}'.format(CV.best_params_))\n",
    "etc = ExtraTreesClassifier(**CV.best_params_)\n",
    "oof_etc, prediction_etc, scores_etc = train_model(X_train_scaled, X_test_scaled, y_train, params=None, model_type='sklearn', model=etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7109500000000001\n",
      "Best parameters: {'learning_rate': 0.01, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "params = {'n_estimators': [5, 10, 20, 50, 100],\n",
    "                  'learning_rate': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "                 }\n",
    "\n",
    "CV = GridSearchCV(abc, param_grid=params, cv=n_folds, scoring='roc_auc')\n",
    "CV.fit(X_train_scaled, y_train)\n",
    "print('Best score: {}'.format(CV.best_score_))\n",
    "print('Best parameters: {}'.format(CV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.5406, std: 0.0755.\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(**CV.best_params_)\n",
    "oof_abc, prediction_abc, scores_abc = train_model(X_train_scaled, X_test_scaled, y_train, params=None, model_type='sklearn', model=abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8));\n",
    "scores_df = pd.DataFrame({'LogisticRegression': scores})\n",
    "scores_df['AdaBoostClassifier'] = scores_abc\n",
    "scores_df['ExtraTreesClassifier'] = scores_etc\n",
    "scores_df['GaussianProcessClassifier'] = scores_gpc\n",
    "scores_df['SVC'] = scores_svc\n",
    "scores_df['KNeighborsClassifier'] = scores_knc\n",
    "scores_df['BernoulliNB'] = scores_bnb\n",
    "scores_df['SGDClassifier'] = scores_sgd\n",
    "scores_df['RandomForestClassifier'] = scores_RF\n",
    "sns.boxplot(data=scores_df);\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтд LR и SVC выделяются. Блендим, смотрим гистограмму распределения oof предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7112, std: 0.1198.\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.555294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.396965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.572044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.843185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.472588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.555294\n",
       "1  251  0.396965\n",
       "2  252  0.572044\n",
       "3  253  0.843185\n",
       "4  254  0.472588"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = (prediction_lr + prediction_svc) / 2\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAHiCAYAAAAXqCHCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xucl3Wd///HSyCwIESZWhUVVExFiAzJ067sWoCHsnZ1PWSieajbatpBfkK5aW1ulpVutelSklit5NcO8lXXQ5qHWjxAjQgeAhV1hBJFSTT9Cb6+f3wuaMCBec8wM58Zedxvt7nN5/O+3td1va65AJ++5/15X5GZSJIkSWrdFvUuQJIkSeopDM+SJElSIcOzJEmSVMjwLEmSJBUyPEuSJEmFDM+SJElSIcOzpB4vIi6LiH/toGPtGBErI6JX9f72iDilI45dHe9/ImJSRx2vDef9SkQ8GxF/7OpzV+fPiNi1et3u+1Xdm507tjpJKheu8yypO4uIxcA7gVXAauBB4EpgWma+3o5jnZKZv2rDPrcDP87MH7TlXNW+5wO7Zubxbd23I0XEDsAfgJ0y85k61ZDA8Mxc1IZ9bqedP3tJ6iyOPEvqCT6YmQOAnYALgXOAyzv6JBHRu6OP2U3sBDzXUcF5zai8JG2ODM+SeozMXJGZs4CjgUkRsRdARFwREV+pXg+OiOsi4oWIWB4Rd0XEFhHxI2BH4P9Wv/r//yJiaDWd4OSIeBK4rVlb8yC9S0TcGxErIuLaiNi6Ote4iGhqXmNELI6I90fERODzwNHV+e6vtq+dBlLVdW5EPBERz0TElRExsNq2po5JEfFkNeXiCxv62UTEwGr/ZdXxzq2O/37gFmC7qo4rWth3XEQ0RcTnq/MsjoiPNtt+RURcGhE3RMRLwN9HRN+I+EZV25+qqRhbNttnckQsjYglEfHx9c639n5V74+IiMaI+HNEPBoREyPiAuBvge9WdX+36tt8+keL11xtOzEiflPV+HxEPB4RhzQ754kR8VhEvFht+yiSVMDwLKnHycx7gSZq4Wp9n6u2NVCb7vH52i75MeBJaqPY/TPz6832OQjYA5iwgVOeAHwc2I7a9JFvF9R4I/DvwE+r8727hW4nVl9/D+wM9Ae+u16fA4F3AQcDX4yIPTZwyu8AA6vjHFTVfFI1ReUQYElVx4kb2P9vgMHA9sAkYFpEvKvZ9uOAC4ABwG+ArwG7AaOBXav9vghQ/Y/D2cAHgOHA+zdwTiJiLLVpOJOBrYC/AxZn5heAu4AzqrrPKL3mZtvfBzxSXdfXgcuj5m3U7uEh1W809gcaN1SjJDVneJbUUy0Btm6h/TVgW2rze1/LzLuy9Q93nJ+ZL2XmXzaw/UeZOT8zXwL+FfjnDpq68FHgW5n5WGauBKYCx6w36v2lzPxLZt4P3A+8IYRXtRwNTM3MFzNzMfBN4GNtrOdfM/PVzLwDuB7452bbrs3M31bzzF8FTgU+k5nLM/NFav+jcEzV95+BHzb7mZ2/kXOeDEzPzFsy8/XMfDozH26t0MJrfiIzv5+Zq4EZ1P5cvLPa9jqwV0RsmZlLM3NBa+eUJDA8S+q5tgeWt9B+EbAIuLn6tfyUgmM91YbtTwB9qI1mbqrtquM1P3Zv/hrwAJqvjvEytdHp9Q0G3tLCsbZvQy3PV0G3+f7bNXvf/GfQALwVmFtNj3kBuLFqp9pv/Z/ZhuwAPNqGOtcouea1P7vMfLl62b+6zqOBTwJLI+L6iNi9HTVI2gwZniX1OBGxD7WQ9Jv1t1WjkJ/LzJ2BDwKfjYiD12zewCFbG5neodnrHamNbj8LvEQtRK6pqxd/DZAlx11C7cN8zY+9CvhTK/ut79mqpvWP9XQbjjGoms7QfP8lzd43v5Zngb8AIzJzq+prYGauCfZLeePPbEOeAnbZwLaN/fw26Zoz86bM/AC10eiHge+X7CdJhmdJPUZEvD0iDgdmUlvC7IEW+hweEbtGRAB/pra83epq85+ozY9tq+MjYs+IeCvwZeCaairAH4B+EXFYRPQBzgX6NtvvT8DQNR9ia8FVwGciYlhE9Oevc6RXtaW4qpargQsiYkBE7AR8FvhxW44DfCki3hIRfwscDvyfDZzvdWph8+KIeAdARGwfEWvmjF8NnNjsZ3beRs55OXBSRBxcfcBx+2ajwBu8X5tyzRHxzoj4UPU/C68CK/nrnxFJ2ijDs6Se4P9GxIvURim/AHyLdT8Y1txw4FfUAtFs4HuZeXu17avAudVUg7PbcP4fAVdQmwbQDzgTaqt/AP8C/IDaiOdL1D6suMaa8PlcRPyuheNOr459J/A48ArwqTbU1dynqvM/Rm1E/r+r45f6I/A8tdHmnwCfbGXu8TnUpsfcHRF/pvYzfxdAZv4PcAlwW9Xntg0dpPrw50nAxcAK4A7+Opr8H8CR1WoZLX1Is73XvAW1D5YuoTb15yBq91GSWuVDUiRpMxcR46iN5A+pdy2S1N058ixJkiQVMjxLkiRJhZy2IUmSJBVy5FmSJEkqZHiWJEmSCvVuvUv9DB48OIcOHVrvMiRJkvQmN3fu3Gczs6G1ft06PA8dOpQ5c+bUuwxJkiS9yUXEEyX9nLYhSZIkFTI8S5IkSYUMz5IkSVKhbj3nuSWvvfYaTU1NvPLKK/UuRd1Av379GDJkCH369Kl3KZIkaTPQ48JzU1MTAwYMYOjQoUREvctRHWUmzz33HE1NTQwbNqze5UiSpM1Aj5u28corr7DNNtsYnEVEsM022/hbCEmS1GV6XHgGDM5ayz8LkiSpK/XI8Fxv/fv33+RjLFmyhCOPPHKD21944QW+973vFfdf34knnsiwYcMYPXo07373u7n11ls3qd6Odtlll3HllVfWuwxJkqQ2icysdw0bNGbMmFz/ISkPPfQQe+yxx9r3Q6dc36HnXHzhYa326d+/PytXruzQ876hjsWLOfzww5k/f3679j/xxBM5/PDDOfLII/n1r3/NaaedxsKFCze5rlWrVtG7d/eaKr/+nwlJkqS2ioi5mTmmtX6OPHeQJ554goMPPphRo0Zx8MEH8+STTwLw6KOPsu+++7LPPvvwxS9+ce2o9eLFi9lrr70AWLBgAWPHjmX06NGMGjWKhQsXMmXKFB599FFGjx7N5MmT1+m/evVqzj77bEaOHMmoUaP4zne+s9Ha9ttvP55++um17+fOnctBBx3Ee9/7XiZMmMDSpUsBuO+++xg1ahT77bcfkydPXnu+K664gqOOOooPfvCDjB8/HoCLLrqIffbZh1GjRnHeeecB8NJLL3HYYYfx7ne/m7322ouf/vSnAEyZMoU999yTUaNGcfbZZwNw/vnn841vfAOAxsZG9t13X0aNGsVHPvIRnn/+eQDGjRvHOeecw9ixY9ltt9246667NuUWSZIkbTLDcwc544wzOOGEE5g3bx4f/ehHOfPMMwE466yzOOuss7jvvvvYbrvtWtz3sssu46yzzqKxsZE5c+YwZMgQLrzwQnbZZRcaGxu56KKL1uk/bdo0Hn/8cX7/+9+vPd/G3HjjjXz4wx8Gakv9fepTn+Kaa65h7ty5fPzjH+cLX/gCACeddBKXXXYZs2fPplevXuscY/bs2cyYMYPbbruNm2++mYULF3LvvffS2NjI3LlzufPOO7nxxhvZbrvtuP/++5k/fz4TJ05k+fLl/OIXv2DBggXMmzePc8899w31nXDCCXzta19j3rx5jBw5ki996Utrt61atYp7772XSy65ZJ12SZKkejA8d5DZs2dz3HHHAfCxj32M3/zmN2vbjzrqKIC129e333778e///u987Wtf44knnmDLLbfc6Ll+9atf8clPfnLt9Imtt966xX6TJ09m55135vjjj+fzn/88AI888gjz58/nAx/4AKNHj+YrX/kKTU1NvPDCC7z44ovsv//+Ldb6gQ98YO15br75Zm6++Wbe8573sPfee/Pwww+zcOFCRo4cya9+9SvOOecc7rrrLgYOHMjb3/52+vXrxymnnMLPf/5z3vrWt65z3BUrVvDCCy9w0EEHATBp0iTuvPPOtdv/8R//EYD3vve9LF68eKM/F0mSpM5meO4kbVkF4rjjjmPWrFlsueWWTJgwgdtuu22j/TOz6PgXXXQRixYt4itf+QqTJk1au++IESNobGyksbGRBx54gJtvvpnW5r6/7W1vW+f8U6dOXXuMRYsWcfLJJ7Pbbrsxd+5cRo4cydSpU/nyl79M7969uffee/mnf/onfvnLXzJx4sSCn8hf9e3bF4BevXqxatWqNu0rSZLU0QzPHWT//fdn5syZAPzkJz/hwAMPBGDfffflZz/7GcDa7et77LHH2HnnnTnzzDP50Ic+xLx58xgwYAAvvvhii/3Hjx/PZZddtjZMLl++fIN1bbHFFpx11lm8/vrr3HTTTbzrXe9i2bJlzJ49G6hN41iwYAGDBg1iwIAB3H333RutFWDChAlMnz597Ycmn376aZ555hmWLFnCW9/6Vo4//njOPvtsfve737Fy5UpWrFjBoYceyiWXXEJjY+M6xxo4cCCDBg1aO5/5Rz/60dpRaEmSpO6mey2b0EO8/PLLDBkyZO37z372s3z729/m4x//OBdddBENDQ388Ic/BOCSSy7h+OOP55vf/CaHHXYYAwcOfMPxfvrTn/LjH/+YPn368Dd/8zd88YtfZOutt+aAAw5gr7324pBDDuH0009f2/+UU07hD3/4A6NGjaJPnz6ceuqpnHHGGRusNyI499xz+frXv86ECRO45pprOPPMM1mxYgWrVq3i05/+NCNGjODyyy/n1FNP5W1vexvjxo1rsVaohfeHHnqI/fbbD6itPvLjH/+YRYsWMXnyZLbYYgv69OnDpZdeyosvvsgRRxzBK6+8QmZy8cUXv+F4M2bM4JOf/CQvv/wyO++889qfnSRJUnfT45eq6+5efvllttxySyKCmTNnctVVV3HttdfWu6wWrVy5cu1qIBdeeCFLly7lP/7jP+pcVet62p8JSZLU/ZQuVefIcyebO3cuZ5xxBpnJVlttxfTp0+td0gZdf/31fPWrX2XVqlXstNNOXHHFFfUuSZIkqVsxPHeyv/3bv+X++++vdxlFjj76aI4++uh6lyFJktRt+YFBSZIkqZAjz5KkN5WRM0bWu4Qu8cCkB+pdgrRZcuRZkiRJKmR4liRJkgoZntvpggsuYMSIEYwaNYrRo0dzyCGHMHXq1HX6NDY2rl1CbeXKlXziE59gl112YcSIEfzd3/0d99xzTz1KlyRJUjv1/DnP57f8II/2H29Fq11mz57Nddddx+9+9zv69u3Ls88+y4IFCzjppJP46le/urbfzJkzOe6444Dag02GDRvGwoUL2WKLLXjsscd46KGHOrZ2SdLmqaP/W9jdFfy3WuosPT8818HSpUsZPHgwffv2BWDw4MEcdNBBbLXVVtxzzz28733vA+Dqq6/mpptu4tFHH+Wee+7hJz/5CVtsURvs33nnndl5553rdg2SJElqO6dttMP48eN56qmn2G233fiXf/kX7rjjDgCOPfZYZs6cCcDdd9/NNttsw/Dhw1mwYAGjR4+mV69e9SxbkiRJm8jw3A79+/dn7ty5TJs2jYaGBo4++miuuOIKjjnmGK655hpef/11Zs6cybHHHlvvUiVJktSBnLbRTr169WLcuHGMGzeOkSNHMmPGDE488USGDh3KHXfcwc9+9jNmz54NwIgRI7j//vt5/fXX107bkCRJUs9jkmuHRx55hIULF65939jYyE477QTUpm585jOfYZdddmHIkCEA7LLLLowZM4bzzjuPzARg4cKFXHvttV1fvCRJktqt1fAcEf0i4t6IuD8iFkTEl6r2KyLi8YhorL5GV+0REd+OiEURMS8i9m52rEkRsbD6mtR5l9W5Vq5cyaRJk9hzzz0ZNWoUDz74IOeffz4ARx11FAsWLOCYY45ZZ58f/OAH/PGPf2TXXXdl5MiRnHrqqWy33XZ1qF6SJEntVTJt41XgHzJzZUT0AX4TEf9TbZucmdes1/8QYHj19T7gUuB9EbE1cB4wBkhgbkTMysznN+kK6rBczXvf+17+93//t8VtDQ0NvPbaa29of/vb3873v//9zi5NkiRJnajVkeesWVm97VN95UZ2OQK4strvbmCriNgWmADckpnLq8B8CzBx08qXJEmSuk7RnOeI6BURjcAz1ALwmkfjXVBNzbg4IvpWbdsDTzXbvalq21C7JEmS1CMUhefMXJ2Zo4EhwNiI2AuYCuwO7ANsDZxTdY+WDrGR9nVExGkRMSci5ixbtqykPEmSJKlLtGm1jcx8AbgdmJiZS6upGa8CPwTGVt2agB2a7TYEWLKR9vXPMS0zx2TmmIaGhraUJ0mSJHWqktU2GiJiq+r1lsD7gYerecxERAAfBuZXu8wCTqhW3dgXWJGZS4GbgPERMSgiBgHjqzZJkiSpRyhZbWNbYEZE9KIWtq/OzOsi4raIaKA2HaMR+GTV/wbgUGAR8DJwEkBmLo+IfwPuq/p9OTOXd9ylSJIkSZ2r1fCcmfOA97TQ/g8b6J/A6RvYNh2Y3sYau51evXoxcuRIMpNevXrx3e9+l/3335/Fixdz+OGHM3/+/NYP0orbb7+db3zjG1x33XUdULEk1YycMbLeJUhSj9bjH8/d0f8heGDSA6322XLLLWlsbATgpptuYurUqdxxxx0dWockSZK6Hx/PvYn+/Oc/M2jQoDe0r169msmTJ7PPPvswatQo/uu//guojSiPGzeOI488kt13352PfvSjax/ZfeONN7L77rtz4IEH8vOf/7xLr0OSJEmt6/Ejz/Xwl7/8hdGjR/PKK6+wdOlSbrvttjf0ufzyyxk4cCD33Xcfr776KgcccADjx48H4Pe//z0LFixgu+2244ADDuC3v/0tY8aM4dRTT+W2225j11135eijj+7qy5IkSVIrDM/t0HzaxuzZsznhhBPeMM/55ptvZt68eVxzTe3p5StWrGDhwoW85S1vYezYsQwZMgSA0aNHs3jxYvr378+wYcMYPnw4AMcffzzTpk3rwquSJElSawzPm2i//fbj2WefZf0HumQm3/nOd5gwYcI67bfffjt9+/Zd+75Xr16sWrUKgNqqf5IkSequnPO8iR5++GFWr17NNttss077hAkTuPTSS3nttdcA+MMf/sBLL720wePsvvvuPP744zz66KMAXHXVVZ1XtCRJktrFked2WDPnGWojzDNmzKBXr17r9DnllFNYvHgxe++9N5lJQ0MDv/zlLzd4zH79+jFt2jQOO+wwBg8ezIEHHtghS95JkvSmc/7AelfQtc5fUe8K1EysWemhOxozZkzOmTNnnbaHHnqIPfbYo04VqTvyz4RUznWe3zzWWVp1cwuTmxvDc5eIiLmZOaa1fk7bkCRJkgoZniVJkqRChmdJkiSpUI8Mz915nra6ln8WJElSV+px4blfv34899xzhiaRmTz33HP069ev3qVIkqTNRI9bqm7IkCE0NTW94aEk2jz169dv7dMaJUmSOluPC899+vRh2LBh9S5DkiRJm6EeN21DkiRJqhfDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUiHDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUiHDsyRJklTI8CxJkiQV6l3vAiRJUjucP7DeFUibJUeeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkq1LveBUiSpLYbOWzHepfQ6R54/Ml6lyC9gSPPkiRJUiHDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUiHDsyRJklTIpeok6U1i6JTrW+0zYI8uKESS3sQceZYkSZIKGZ4lSZKkQq2G54joFxH3RsT9EbEgIr5UtQ+LiHsiYmFE/DQi3lK1963eL6q2D212rKlV+yMRMaGzLkqSJEnqDCUjz68C/5CZ7wZGAxMjYl/ga8DFmTkceB44uep/MvB8Zu4KXFz1IyL2BI4BRgATge9FRK+OvBhJkiSpM7UanrNmZfW2T/WVwD8A11TtM4APV6+PqN5TbT84IqJqn5mZr2bm48AiYGyHXIUkSZLUBYrmPEdEr4hoBJ4BbgEeBV7IzFVVlyZg++r19sBTANX2FcA2zdtb2EeSJEnq9orCc2auzszRwBBqo8UtLXaU1ffYwLYNta8jIk6LiDkRMWfZsmUl5UmSJEldok2rbWTmC8DtwL7AVhGxZp3oIcCS6nUTsANAtX0gsLx5ewv7ND/HtMwck5ljGhoa2lKeJEmS1KlafUhKRDQAr2XmCxGxJfB+ah8C/DVwJDATmARcW+0yq3o/u9p+W2ZmRMwC/jsivgVsBwwH7u3g65EkoOyBIZIktVXJEwa3BWZUK2NsAVydmddFxIPAzIj4CvB74PKq/+XAjyJiEbUR52MAMnNBRFwNPAisAk7PzNUdezmSJElS52k1PGfmPOA9LbQ/RgurZWTmK8BRGzjWBcAFbS9TkiRJqj+fMChJkiQVKpm2IUlvegP2mFLvEiRJPYAjz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYV617sASV1j6JTr612CJEk9niPPkiRJUiHDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUqFWw3NE7BARv46IhyJiQUScVbWfHxFPR0Rj9XVos32mRsSiiHgkIiY0a59YtS2KiCmdc0mSJElS5yhZqm4V8LnM/F1EDADmRsQt1baLM/MbzTtHxJ7AMcAIYDvgVxGxW7X5P4EPAE3AfRExKzMf7IgLkSRJkjpbq+E5M5cCS6vXL0bEQ8D2G9nlCGBmZr4KPB4Ri4Cx1bZFmfkYQETMrPoaniVJktQjtGnOc0QMBd4D3FM1nRER8yJiekQMqtq2B55qtltT1bahdkmSJKlHKA7PEdEf+Bnw6cz8M3ApsAswmtrI9DfXdG1h99xI+/rnOS0i5kTEnGXLlpWWJ0mSJHW6ovAcEX2oBeefZObPATLzT5m5OjNfB77PX6dmNAE7NNt9CLBkI+3ryMxpmTkmM8c0NDS09XokSZKkTlOy2kYAlwMPZea3mrVv26zbR4D51etZwDER0TcihgHDgXuB+4DhETEsIt5C7UOFszrmMiRJkqTOV7LaxgHAx4AHIqKxavs8cGxEjKY29WIx8AmAzFwQEVdT+yDgKuD0zFwNEBFnADcBvYDpmbmgA69FkiRJ6lQlq238hpbnK9+wkX0uAC5oof2Gje0nSZIkdWc+YVCSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSCvWudwGSVA+L+x23zvuR7FinSiRJPYkjz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhV9uQ1KoBe0ypdwkdztU1JEntYXjWZmvolOvrXYIkSephnLYhSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYVaDc8RsUNE/DoiHoqIBRFxVtW+dUTcEhELq++DqvaIiG9HxKKImBcRezc71qSq/8KImNR5lyVJkiR1vJKR51XA5zJzD2Bf4PSI2BOYAtyamcOBW6v3AIcAw6uv04BLoRa2gfOA9wFjgfPWBG5JkiSpJ2g1PGfm0sz8XfX6ReAhYHvgCGBG1W0G8OHq9RHAlVlzN7BVRGwLTABuyczlmfk8cAswsUOvRpIkSepEbZrzHBFDgfcA9wDvzMylUAvYwDuqbtsDTzXbralq21C7JEmS1CMUh+eI6A/8DPh0Zv55Y11baMuNtK9/ntMiYk5EzFm2bFlpeZIkSVKnKwrPEdGHWnD+SWb+vGr+UzUdg+r7M1V7E7BDs92HAEs20r6OzJyWmWMyc0xDQ0NbrkWSJEnqVCWrbQRwOfBQZn6r2aZZwJoVMyYB1zZrP6FadWNfYEU1reMmYHxEDKo+KDi+apMkSZJ6hN4FfQ4APgY8EBGNVdvngQuBqyPiZOBJ4Khq2w3AocAi4GXgJIDMXB4R/wbcV/X7cmYu75CrkCRJkrpAq+E5M39Dy/OVAQ5uoX8Cp2/gWNOB6W0pUJIkSeoufMKgJEmSVMjwLEmSJBUyPEuSJEmFDM+SJElSIcOzJEmSVMjwLEmSJBUyPEuSJEmFDM+SJElSoZInDEqSJHW5kcN2rHcJXeKBx5+sdwlqA0eeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkq1LveBUjqHhb3O26IBgljAAAN0ElEQVSD20ayYxdWIklS9+XIsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUiHDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUqFWw3NETI+IZyJifrO28yPi6YhorL4ObbZtakQsiohHImJCs/aJVduiiJjS8ZciSZIkda6SkecrgIkttF+cmaOrrxsAImJP4BhgRLXP9yKiV0T0Av4TOATYEzi26itJkiT1GK0+njsz74yIoYXHOwKYmZmvAo9HxCJgbLVtUWY+BhARM6u+D7a5YkmSJKlONmXO8xkRMa+a1jGoatseeKpZn6aqbUPtbxARp0XEnIiYs2zZsk0oT5IkSepY7Q3PlwK7AKOBpcA3q/ZooW9upP2NjZnTMnNMZo5paGhoZ3mSJElSx2t12kZLMvNPa15HxPeB66q3TcAOzboOAZZUrzfULkmSJPUI7Rp5johtm739CLBmJY5ZwDER0TcihgHDgXuB+4DhETEsIt5C7UOFs9pftiRJktT1Wh15joirgHHA4IhoAs4DxkXEaGpTLxYDnwDIzAURcTW1DwKuAk7PzNXVcc4AbgJ6AdMzc0GHX40kSZLUiUpW2zi2hebLN9L/AuCCFtpvAG5oU3WSJElSN+ITBiVJkqRChmdJkiSpkOFZkiRJKmR4liRJkgoZniVJkqRChmdJkiSpkOFZkiRJKtSux3NLqhmwx5R6l9BhRrJjvUuQJKnbMzxLkiR1Z+cPrHcFXev8FfWuYKOctiFJkiQVMjxLkiRJhQzPkiRJUiHDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUiHDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUiHDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUqHe9S5A3cPQKdfXuwRJkqRuz5FnSZIkqZDhWZIkSSpkeJYkSZIKGZ4lSZKkQoZnSZIkqZDhWZIkSSpkeJYkSZIKGZ4lSZKkQoZnSZIkqZDhWZIkSSpkeJYkSZIKGZ4lSZKkQoZnSZIkqZDhWZIkSSpkeJYkSZIKGZ4lSZKkQoZnSZIkqZDhWZIkSSpkeJYkSZIKGZ4lSZKkQoZnSZIkqZDhWZIkSSpkeJYkSZIKtRqeI2J6RDwTEfObtW0dEbdExMLq+6CqPSLi2xGxKCLmRcTezfaZVPVfGBGTOudyJEmSpM5TMvJ8BTBxvbYpwK2ZORy4tXoPcAgwvPo6DbgUamEbOA94HzAWOG9N4JYkSZJ6it6tdcjMOyNi6HrNRwDjqtczgNuBc6r2KzMzgbsjYquI2Lbqe0tmLgeIiFuoBfKrNvkKpE6yuN9xrfYZyY5dUIkkSeou2jvn+Z2ZuRSg+v6Oqn174Klm/Zqqtg21v0FEnBYRcyJizrJly9pZniRJktTxOvoDg9FCW26k/Y2NmdMyc0xmjmloaOjQ4iRJkqRN0d7w/KdqOgbV92eq9iZgh2b9hgBLNtIuSZIk9RjtDc+zgDUrZkwCrm3WfkK16sa+wIpqWsdNwPiIGFR9UHB81SZJkiT1GK1+YDAirqL2gb/BEdFEbdWMC4GrI+Jk4EngqKr7DcChwCLgZeAkgMxcHhH/BtxX9fvymg8PSpIkST1FyWobx25g08Et9E3g9A0cZzowvU3VSZIkSd2ITxiUJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSCvWudwF68xqwx5R6l7BJRrJjvUuQJEndjCPPkiRJUiHDsyRJklTI8CxJkiQVMjxLkiRJhQzPkiRJUiHDsyRJklTIpepUbHG/49rU36XeJEnSm40jz5IkSVIhw7MkSZJUyPAsSZIkFdqk8BwRiyPigYhojIg5VdvWEXFLRCysvg+q2iMivh0RiyJiXkTs3REXIEmSJHWVjhh5/vvMHJ2ZY6r3U4BbM3M4cGv1HuAQYHj1dRpwaQecW5IkSeoynTFt4whgRvV6BvDhZu1XZs3dwFYRsW0nnF+SJEnqFJsanhO4OSLmRsRpVds7M3MpQPX9HVX79sBTzfZtqtokSZKkHmFT13k+IDOXRMQ7gFsi4uGN9I0W2vINnWoh/DSAHXd0nWBJkiR1H5s08pyZS6rvzwC/AMYCf1ozHaP6/kzVvQnYodnuQ4AlLRxzWmaOycwxDQ0Nm1KeJEmS1KHaHZ4j4m0RMWDNa2A8MB+YBUyquk0Crq1ezwJOqFbd2BdYsWZ6hyRJktQTbMq0jXcCv4iINcf578y8MSLuA66OiJOBJ4Gjqv43AIcCi4CXgZM24dySJElSl2t3eM7Mx4B3t9D+HHBwC+0JnN7e80mSJEn15hMGJUmSpEKGZ0mSJKnQpi5VJ0mSpE0wctjmsTTvA48/We8SOoQjz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYUMz5IkSVIhw7MkSZJUyPAsSZIkFTI8S5IkSYV617uA7mrolOvrXYIkSZK6GUeeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSCvWudwE92eJ+x7Vrv5HDduzgSrrGSHpm3ZIkSR3FkWdJkiSpkOFZkiRJKmR4liRJkgoZniVJkqRChmdJkiSpkOFZkiRJKmR4liRJkgoZniVJkqRChmdJkiSpkOFZkiRJKmR4liRJkgp1eXiOiIkR8UhELIqIKV19fkmSJKm9ujQ8R0Qv4D+BQ4A9gWMjYs+urEGSJElqr64eeR4LLMrMxzLz/wdmAkd0cQ2SJElSu3R1eN4eeKrZ+6aqTZIkSer2enfx+aKFtlynQ8RpwGnV25UR8UgbzzEYeLYdtbVZSxdTZn4HVqFKl913dTve+82T933z5H3vwYpz05fe0LOr7vtOJZ26Ojw3ATs0ez8EWNK8Q2ZOA6a19wQRMSczx7R3f/VM3vfNl/d+8+R93zx53zdP3e2+d/W0jfuA4RExLCLeAhwDzOriGiRJkqR26dKR58xcFRFnADcBvYDpmbmgK2uQJEmS2qurp22QmTcAN3TiKdo95UM9mvd98+W93zx53zdP3vfNU7e675GZrfeSJEmS5OO5JUmSpFI9Njy39pjviOgbET+ttt8TEUO7vkp1tIL7/tmIeDAi5kXErRFRtOyMurfW7nuzfkdGREZEt/lUttqv5L5HxD9Xf+cXRMR/d3WN6hwF/9bvGBG/jojfV//eH1qPOtVxImJ6RDwTES2u5xs1367+TMyLiL27usY1emR4LnzM98nA85m5K3Ax8LWurVIdrfC+/x4Yk5mjgGuAr3dtlepohfediBgAnAnc07UVqjOU3PeIGA5MBQ7IzBHAp7u8UHW4wr/z5wJXZ+Z7qK3c9b2urVKd4Apg4ka2HwIMr75OAy7tgppa1CPDM2WP+T4CmFG9vgY4OCLa/1wTdQet3vfM/HVmvly9vZvaWuLq2Ur+vgP8G7X/WXqlK4tTpym576cC/5mZzwNk5jNdXKM6R8m9T+Dt1euBrPfMCPU8mXknsHwjXY4Arsyau4GtImLbrqluXT01PJc85nttn8xcBawAtumS6tRZ2vp495OB/+nUitQVWr3vEfEeYIfMvK4rC1OnKvn7vhuwW0T8NiLujoiNjVqp5yi59+cDx0dEE7UVvD7VNaWpjtqaATpNly9V10Fafcx3YR/1LMX3NCKOB8YAB3VqReoKG73vEbEFtalZJ3ZVQeoSJX/fe1P7Fe44ar9luisi9srMFzq5NnWuknt/LHBFZn4zIvYDflTd+9c7vzzVSbfJdT115LnVx3w37xMRvan9Wmdjvw5Q91dy34mI9wNfAD6Uma92UW3qPK3d9wHAXsDtEbEY2BeY5YcGe7zSf+evzczXMvNx4BFqYVo9W8m9Pxm4GiAzZwP9gMFdUp3qpSgDdIWeGp5LHvM9C5hUvT4SuC1d1Lqna/W+V7++/y9qwdn5j28OG73vmbkiMwdn5tDMHEptrvuHMnNOfcpVByn5d/6XwN8DRMRgatM4HuvSKtUZSu79k8DBABGxB7XwvKxLq1RXmwWcUK26sS+wIjOX1qOQHjltY0OP+Y6ILwNzMnMWcDm1X+MsojbifEz9KlZHKLzvFwH9gf9TfT70ycz8UN2K1iYrvO96kym87zcB4yPiQWA1MDkzn6tf1eoIhff+c8D3I+Iz1H51f6IDZD1bRFxFbQrW4Gou+3lAH4DMvIza3PZDgUXAy8BJ9anUJwxKkiRJxXrqtA1JkiSpyxmeJUmSpEKGZ0mSJKmQ4VmSJEkqZHiWJEmSChmeJUmSpEKGZ0mSJKmQ4VmSJEkq9P8A1uVFAUtIe38AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.hist (prediction_lr, label = 'Logistic Regression')\n",
    "plt.hist (prediction_svc, label = 'SVC')\n",
    "plt.hist ((prediction_lr+prediction_svc) / 2, label = 'Blend')\n",
    "plt.title ('Distribution of predictions')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.669671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.487245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.515429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.760070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.445292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.669671\n",
       "1  251  0.487245\n",
       "2  252  0.515429\n",
       "3  253  0.760070\n",
       "4  254  0.445292"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = prediction_lr\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просто logreg дает больший скор на LB. Пробуем lgbm, \n",
    "# далее варианты - distance-based признаки, полиномиальные признаки, теоретический анализ (не годится), \n",
    "# отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_010_decay_power_099(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.99, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def learning_rate_010_decay_power_0995(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.995, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def learning_rate_005_decay_power_099(current_iter):\n",
    "    base_learning_rate = 0.05\n",
    "    lr = base_learning_rate  * np.power(.99, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_sp, X_test_sp, y_train_sp, y_test_sp = train_test_split(X_train_scaled, y_train, test_size=0.20, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\"early_stopping_rounds\":30, \n",
    "            \"eval_metric\" : 'auc', \n",
    "            \"eval_set\" : [(X_test_sp,y_test_sp)],\n",
    "            'eval_names': ['valid'],\n",
    "            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 100 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7814\n",
      "Best parameters: {'colsample_bytree': 0.523027197103915, 'min_child_samples': 100, 'min_child_weight': 0.01, 'num_leaves': 18, 'reg_alpha': 2, 'reg_lambda': 20, 'subsample': 0.9025765339833538}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "params = {'num_leaves': sp_randint(6, 50), \n",
    "          'min_child_samples': sp_randint(100, 500), \n",
    "          'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "          'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "          'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "          'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "          'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]\n",
    "          }\n",
    "\n",
    "n_HP_points_to_test = 100\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth = -1, random_state = 42, silent = True, metric = 'None', n_jobs = -1, n_estimators = 5000)\n",
    "CV = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=params, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=n_folds,\n",
    "    refit=True,\n",
    "    random_state=42,\n",
    "    verbose=True)\n",
    "CV.fit(X_train_scaled, y_train)\n",
    "print (\"Best score: {}\".format(CV.best_score_))\n",
    "print (\"Best parameters: {}\".format(CV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 45451)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of polynomial features is ~45k which is too much. \n",
    "# We need some way to select some of them. Let's try use correlations with target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = pd.DataFrame(X_train_poly).corrwith(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.8087, std: 0.1248.\n",
      "CV mean score: 0.8231, std: 0.1030.\n",
      "CV mean score: 0.8488, std: 0.0963.\n",
      "CV mean score: 0.8250, std: 0.0744.\n",
      "CV mean score: 0.8375, std: 0.0887.\n",
      "CV mean score: 0.8294, std: 0.1057.\n",
      "CV mean score: 0.8406, std: 0.0961.\n",
      "CV mean score: 0.8500, std: 0.1188.\n",
      "CV mean score: 0.8394, std: 0.1063.\n",
      "CV mean score: 0.8231, std: 0.1115.\n",
      "CV mean score: 0.8363, std: 0.0919.\n",
      "CV mean score: 0.8438, std: 0.0977.\n",
      "CV mean score: 0.8281, std: 0.1247.\n",
      "CV mean score: 0.8250, std: 0.1274.\n",
      "CV mean score: 0.8356, std: 0.1354.\n",
      "CV mean score: 0.8456, std: 0.1149.\n",
      "CV mean score: 0.8425, std: 0.1089.\n",
      "CV mean score: 0.8488, std: 0.1049.\n",
      "CV mean score: 0.8381, std: 0.0953.\n",
      "CV mean score: 0.8113, std: 0.0929.\n",
      "CV mean score: 0.8306, std: 0.0796.\n",
      "CV mean score: 0.8306, std: 0.0771.\n",
      "CV mean score: 0.8387, std: 0.0818.\n",
      "CV mean score: 0.8262, std: 0.0810.\n",
      "CV mean score: 0.8025, std: 0.0788.\n",
      "CV mean score: 0.8012, std: 0.0874.\n",
      "CV mean score: 0.8044, std: 0.0853.\n",
      "CV mean score: 0.7975, std: 0.0852.\n",
      "CV mean score: 0.7925, std: 0.0834.\n",
      "CV mean score: 0.7863, std: 0.0949.\n",
      "CV mean score: 0.7831, std: 0.0945.\n",
      "CV mean score: 0.7737, std: 0.0983.\n",
      "CV mean score: 0.7850, std: 0.0884.\n",
      "CV mean score: 0.7819, std: 0.0882.\n",
      "CV mean score: 0.7769, std: 0.0890.\n",
      "CV mean score: 0.7694, std: 0.1096.\n",
      "CV mean score: 0.7431, std: 0.1170.\n",
      "CV mean score: 0.7400, std: 0.1228.\n",
      "CV mean score: 0.7469, std: 0.1145.\n",
      "CV mean score: 0.7419, std: 0.1132.\n",
      "CV mean score: 0.7213, std: 0.1138.\n",
      "CV mean score: 0.7275, std: 0.1017.\n",
      "CV mean score: 0.7213, std: 0.0989.\n",
      "CV mean score: 0.7213, std: 0.0989.\n",
      "CV mean score: 0.7213, std: 0.0989.\n",
      "CV mean score: 0.7213, std: 0.0989.\n",
      "CV mean score: 0.7213, std: 0.0989.\n",
      "CV mean score: 0.7213, std: 0.0989.\n",
      "CV mean score: 0.7306, std: 0.1184.\n",
      "CV mean score: 0.7150, std: 0.1296.\n",
      "CV mean score: 0.7131, std: 0.1308.\n",
      "CV mean score: 0.7069, std: 0.1362.\n",
      "CV mean score: 0.7006, std: 0.1453.\n",
      "CV mean score: 0.7006, std: 0.1453.\n",
      "CV mean score: 0.7006, std: 0.1453.\n",
      "CV mean score: 0.7006, std: 0.1453.\n",
      "CV mean score: 0.6944, std: 0.1510.\n",
      "CV mean score: 0.6850, std: 0.1438.\n",
      "CV mean score: 0.6900, std: 0.1438.\n",
      "CV mean score: 0.6975, std: 0.1435.\n",
      "CV mean score: 0.6944, std: 0.1483.\n",
      "CV mean score: 0.6944, std: 0.1483.\n",
      "CV mean score: 0.6975, std: 0.1345.\n",
      "CV mean score: 0.7169, std: 0.1361.\n",
      "CV mean score: 0.7087, std: 0.1361.\n",
      "CV mean score: 0.7056, std: 0.1401.\n",
      "CV mean score: 0.6975, std: 0.1322.\n",
      "CV mean score: 0.6975, std: 0.1322.\n",
      "CV mean score: 0.6894, std: 0.1461.\n",
      "CV mean score: 0.6925, std: 0.1413.\n",
      "CV mean score: 0.6687, std: 0.1429.\n",
      "CV mean score: 0.6669, std: 0.1364.\n",
      "CV mean score: 0.6669, std: 0.1364.\n",
      "CV mean score: 0.6719, std: 0.1385.\n",
      "CV mean score: 0.6687, std: 0.1368.\n",
      "CV mean score: 0.6763, std: 0.1464.\n",
      "CV mean score: 0.6744, std: 0.1450.\n",
      "CV mean score: 0.6831, std: 0.1420.\n",
      "CV mean score: 0.6813, std: 0.1324.\n",
      "CV mean score: 0.6763, std: 0.1367.\n",
      "CV mean score: 0.6763, std: 0.1367.\n",
      "CV mean score: 0.6769, std: 0.1431.\n",
      "CV mean score: 0.6769, std: 0.1431.\n",
      "CV mean score: 0.6769, std: 0.1431.\n",
      "CV mean score: 0.6769, std: 0.1431.\n",
      "CV mean score: 0.6738, std: 0.1379.\n",
      "CV mean score: 0.6687, std: 0.1410.\n",
      "CV mean score: 0.6687, std: 0.1410.\n",
      "CV mean score: 0.6638, std: 0.1424.\n",
      "CV mean score: 0.6481, std: 0.1424.\n",
      "CV mean score: 0.6481, std: 0.1424.\n",
      "CV mean score: 0.6481, std: 0.1424.\n",
      "CV mean score: 0.6512, std: 0.1397.\n",
      "CV mean score: 0.6512, std: 0.1397.\n",
      "CV mean score: 0.6512, std: 0.1397.\n",
      "CV mean score: 0.6450, std: 0.1435.\n",
      "CV mean score: 0.6450, std: 0.1435.\n",
      "CV mean score: 0.6606, std: 0.1443.\n",
      "CV mean score: 0.6606, std: 0.1443.\n",
      "CV mean score: 0.6669, std: 0.1483.\n"
     ]
    }
   ],
   "source": [
    "sc = []\n",
    "for i in range(10, 510, 5):\n",
    "    top_corr_cols = list(cor.abs().sort_values().tail(i).reset_index()['index'].values)\n",
    "    X_train_poly1 = X_train_poly[:, top_corr_cols]\n",
    "    X_test_poly1 = X_test_poly[:, top_corr_cols]\n",
    "    oof_lr_poly, prediction_lr_poly, scores = train_model(X_train_poly1, X_test_poly1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    sc.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "responsive": true,
        "showLink": false
       },
       "data": [
        {
         "name": "CV scores",
         "type": "scatter",
         "uid": "8ca53a2f-341c-4143-99f3-9294fe1a3499",
         "x": [
          10,
          15,
          20,
          25,
          30,
          35,
          40,
          45,
          50,
          55,
          60,
          65,
          70,
          75,
          80,
          85,
          90,
          95,
          100,
          105,
          110,
          115,
          120,
          125,
          130,
          135,
          140,
          145,
          150,
          155,
          160,
          165,
          170,
          175,
          180,
          185,
          190,
          195,
          200,
          205,
          210,
          215,
          220,
          225,
          230,
          235,
          240,
          245,
          250,
          255,
          260,
          265,
          270,
          275,
          280,
          285,
          290,
          295,
          300,
          305,
          310,
          315,
          320,
          325,
          330,
          335,
          340,
          345,
          350,
          355,
          360,
          365,
          370,
          375,
          380,
          385,
          390,
          395,
          400,
          405,
          410,
          415,
          420,
          425,
          430,
          435,
          440,
          445,
          450,
          455,
          460,
          465,
          470,
          475,
          480,
          485,
          490,
          495,
          500,
          505
         ],
         "y": [
          0.8087,
          0.8231,
          0.8488,
          0.825,
          0.8375,
          0.8294,
          0.8406,
          0.85,
          0.8394,
          0.8231,
          0.8362,
          0.8438,
          0.8281,
          0.825,
          0.8356,
          0.8456,
          0.8425,
          0.8488,
          0.8381,
          0.8112,
          0.8306,
          0.8306,
          0.8387,
          0.8262,
          0.8025,
          0.8012,
          0.8044,
          0.7975,
          0.7925,
          0.7862,
          0.7831,
          0.7737,
          0.785,
          0.7819,
          0.7769,
          0.7694,
          0.7431,
          0.74,
          0.7469,
          0.7419,
          0.7213,
          0.7275,
          0.7213,
          0.7213,
          0.7213,
          0.7213,
          0.7213,
          0.7213,
          0.7306,
          0.715,
          0.7131,
          0.7069,
          0.7006,
          0.7006,
          0.7006,
          0.7006,
          0.6944,
          0.685,
          0.69,
          0.6975,
          0.6944,
          0.6944,
          0.6975,
          0.7169,
          0.7088,
          0.7056,
          0.6975,
          0.6975,
          0.6894,
          0.6925,
          0.6688,
          0.6669,
          0.6669,
          0.6719,
          0.6688,
          0.6762,
          0.6744,
          0.6831,
          0.6812,
          0.6762,
          0.6762,
          0.6769,
          0.6769,
          0.6769,
          0.6769,
          0.6738,
          0.6688,
          0.6688,
          0.6638,
          0.6481,
          0.6481,
          0.6481,
          0.6512,
          0.6512,
          0.6512,
          0.645,
          0.645,
          0.6606,
          0.6606,
          0.6669
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Top N poly features vs CV"
        },
        "xaxis": {
         "title": {
          "text": "Top N features"
         }
        },
        "yaxis": {
         "title": {
          "text": "CV score"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"efc54dd4-3b20-41c1-8e84-af6dcaaf4aeb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"efc54dd4-3b20-41c1-8e84-af6dcaaf4aeb\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'efc54dd4-3b20-41c1-8e84-af6dcaaf4aeb',\n",
       "                        [{\"name\": \"CV scores\", \"type\": \"scatter\", \"uid\": \"147f33a0-9e44-4a61-8528-580e2f99ce2d\", \"x\": [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320, 325, 330, 335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385, 390, 395, 400, 405, 410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470, 475, 480, 485, 490, 495, 500, 505], \"y\": [0.8087, 0.8231, 0.8488, 0.825, 0.8375, 0.8294, 0.8406, 0.85, 0.8394, 0.8231, 0.8362, 0.8438, 0.8281, 0.825, 0.8356, 0.8456, 0.8425, 0.8488, 0.8381, 0.8112, 0.8306, 0.8306, 0.8387, 0.8262, 0.8025, 0.8012, 0.8044, 0.7975, 0.7925, 0.7862, 0.7831, 0.7737, 0.785, 0.7819, 0.7769, 0.7694, 0.7431, 0.74, 0.7469, 0.7419, 0.7213, 0.7275, 0.7213, 0.7213, 0.7213, 0.7213, 0.7213, 0.7213, 0.7306, 0.715, 0.7131, 0.7069, 0.7006, 0.7006, 0.7006, 0.7006, 0.6944, 0.685, 0.69, 0.6975, 0.6944, 0.6944, 0.6975, 0.7169, 0.7088, 0.7056, 0.6975, 0.6975, 0.6894, 0.6925, 0.6688, 0.6669, 0.6669, 0.6719, 0.6688, 0.6762, 0.6744, 0.6831, 0.6812, 0.6762, 0.6762, 0.6769, 0.6769, 0.6769, 0.6769, 0.6738, 0.6688, 0.6688, 0.6638, 0.6481, 0.6481, 0.6481, 0.6512, 0.6512, 0.6512, 0.645, 0.645, 0.6606, 0.6606, 0.6669]}],\n",
       "                        {\"title\": {\"text\": \"Top N poly features vs CV\"}, \"xaxis\": {\"title\": {\"text\": \"Top N features\"}}, \"yaxis\": {\"title\": {\"text\": \"CV score\"}}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('efc54dd4-3b20-41c1-8e84-af6dcaaf4aeb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(10, 510, 5)),\n",
    "        y = [np.round(np.mean(i), 4) for i in sc],\n",
    "        name = 'CV scores'\n",
    "    )]\n",
    "layout = go.Layout(dict(title = \"Top N poly features vs CV\",\n",
    "                  xaxis = dict(title = 'Top N features'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# видно было и без графика, что мы overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7112, std: 0.1198.\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "X_train['300'] = X_train.std(1)\n",
    "X_test['300'] = X_test.std(1)\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr_1, prediction_lr_1, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.670752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.488925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.517128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.761163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.446570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.670752\n",
       "1  251  0.488925\n",
       "2  252  0.517128\n",
       "3  253  0.761163\n",
       "4  254  0.446570"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr_1\n",
    "submission.to_csv('fold_stats.csv', index = False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7134, std: 0.1215.\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['id', 'target'], axis = 1)\n",
    "X_test = test.drop(['id'], axis = 1)\n",
    "X_train['300'] = X_train.std(1)\n",
    "X_test['300'] = X_test.std(1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_test.columns[:-1]] = scaler.transform(X_test[X_test.columns[:-1]])\n",
    "model = linear_model.LogisticRegression(class_weight = 'balanced',\n",
    "                                        penalty = 'l1',\n",
    "                                        C = 0.1,\n",
    "                                        solver = 'liblinear'\n",
    "                                        )\n",
    "oof_lr_1, prediction_lr_1_repeated, scores = train_model(X_train.values, X_test.values, y_train, params = None, model_type = \"sklearn\", model = model, folds = repeated_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>13.431655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>9.751141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>10.359576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>15.158517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>8.883491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     target\n",
       "0  250  13.431655\n",
       "1  251   9.751141\n",
       "2  252  10.359576\n",
       "3  253  15.158517\n",
       "4  254   8.883491"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr_1_repeated\n",
    "submission.to_csv('repeated_fold_stats.csv', index = False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "\n",
    "NN = NearestNeighbors(n_neighbors = 5, n_jobs = -1)\n",
    "NN.fit(X_train)\n",
    "\n",
    "dists, _ = NN.kneighbors(X_train, n_neighbors = 5)\n",
    "mean_distance = dists.mean(axis =1)\n",
    "max_distance = dists.max(axis = 1)\n",
    "min_distance = dists.min(axis = 1)\n",
    "\n",
    "X_train['300'] = X_train.std(1)\n",
    "\n",
    "X_train = np.hstack((X_train, mean_distance.reshape(-1, 1), max_distance.reshape(-1, 1), min_distance.reshape(-1, 1)))\n",
    "\n",
    "test_dists, _ = NN.kneighbors(X_test, n_neighbors = 5)\n",
    "\n",
    "test_mean_distance = test_dists.mean(axis =1)\n",
    "test_max_distance = test_dists.max(axis = 1)\n",
    "test_min_distance = test_dists.min(axis = 1)\n",
    "\n",
    "X_test['300'] = X_test.std(1)\n",
    "X_test = np.hstack((X_test, test_mean_distance.reshape(-1, 1), test_max_distance.reshape(-1, 1), test_min_distance.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train+test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7463, std: 0.1261.\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(class_weight = 'balanced',\n",
    "                                        C = 0.1,\n",
    "                                        penalty = 'l1',\n",
    "                                        solver = 'liblinear'\n",
    "                                        )\n",
    "oof_lr_2, prediction_lr_2, scores = train_model(X_train, X_test, y_train, params = None, model_type = 'sklearn', model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr_2\n",
    "submission.to_csv('nn_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.724953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.561495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.603113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.798494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.482473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.724953\n",
       "1  251  0.561495\n",
       "2  252  0.603113\n",
       "3  253  0.798494\n",
       "4  254  0.482473"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.697853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.525210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.560120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.779828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.464522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.697853\n",
       "1  251  0.525210\n",
       "2  252  0.560120\n",
       "3  253  0.779828\n",
       "4  254  0.464522"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = (prediction_lr_1 + prediction_lr_2) / 2\n",
    "submission.to_csv('blend_lrs.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь попробуем что-то из sklearn feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7112, std: 0.1198.\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model = linear_model.LogisticRegression(class_weight = 'balanced', \n",
    "                                        C = 0.1,\n",
    "                                        penalty = 'l1',\n",
    "                                        solver = 'liblinear'\n",
    "                                        )\n",
    "oof_lr_1, prediction_lr_1, scores = train_model(X_train, X_test, y_train, params = None, model_type = 'sklearn', model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7650, std: 0.0850.\n",
      "CV mean score: 0.6850, std: 0.1286.\n",
      "CV mean score: 0.7525, std: 0.1102.\n",
      "CV mean score: 0.7269, std: 0.1088.\n",
      "CV mean score: 0.7338, std: 0.1159.\n",
      "CV mean score: 0.7444, std: 0.0952.\n",
      "CV mean score: 0.7144, std: 0.1232.\n",
      "CV mean score: 0.7431, std: 0.0966.\n",
      "CV mean score: 0.7175, std: 0.1239.\n",
      "CV mean score: 0.7338, std: 0.0945.\n",
      "CV mean score: 0.7175, std: 0.1239.\n",
      "CV mean score: 0.7475, std: 0.0805.\n",
      "CV mean score: 0.7175, std: 0.1248.\n",
      "CV mean score: 0.7637, std: 0.0794.\n",
      "CV mean score: 0.7175, std: 0.1248.\n",
      "CV mean score: 0.7637, std: 0.0794.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7606, std: 0.0762.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7363, std: 0.0854.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7537, std: 0.0835.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7556, std: 0.1180.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7444, std: 0.1158.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7381, std: 0.0986.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7288, std: 0.1100.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7156, std: 0.1182.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7175, std: 0.1066.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7206, std: 0.1318.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7175, std: 0.1248.\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {'f_classif' : [], 'mutual_info_classif' : []}\n",
    "for i in range(5, 100, 5):\n",
    "    s1 = SelectPercentile(f_classif, percentile = i)\n",
    "    X_train1 = s1.fit_transform(X_train, y_train)\n",
    "    X_test1 = s1.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model (X_train1, X_test1, y_train, params = None, model_type = 'sklearn', model = model)\n",
    "    scores_dict['f_classif'].append(np.mean(scores))\n",
    "    \n",
    "    s2 = SelectPercentile(mutual_info_classif, percentile = i)\n",
    "    X_train1 = s2.fit_transform(X_train, y_train)\n",
    "    X_test1 = s2.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params = None, model_type = 'sklearn', model = model)\n",
    "    scores_dict['mutual_info_classif'].append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "responsive": true,
        "showLink": false
       },
       "data": [
        {
         "name": "CV scores f_classif",
         "type": "scatter",
         "uid": "f4fad731-8f1d-4b00-a4a5-b33fdb1da2ff",
         "x": [
          5,
          10,
          15,
          20,
          25,
          30,
          35,
          40,
          45,
          50,
          55,
          60,
          65,
          70,
          75,
          80,
          85,
          90,
          95
         ],
         "y": [
          0.765,
          0.7525000000000001,
          0.73375,
          0.714375,
          0.7175,
          0.7175,
          0.7175,
          0.7175,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999
         ]
        },
        {
         "name": "CV scores mutual_info_classif",
         "type": "scatter",
         "uid": "8860e513-b921-410a-83db-84c1b8f38186",
         "x": [
          5,
          10,
          15,
          20,
          25,
          30,
          35,
          40,
          45,
          50,
          55,
          60,
          65,
          70,
          75,
          80,
          85,
          90,
          95
         ],
         "y": [
          0.6849999999999999,
          0.7268749999999999,
          0.744375,
          0.743125,
          0.73375,
          0.7474999999999999,
          0.7637499999999999,
          0.7637499999999999,
          0.7606249999999999,
          0.7362500000000001,
          0.7537499999999999,
          0.755625,
          0.744375,
          0.738125,
          0.72875,
          0.715625,
          0.7175,
          0.7206250000000001,
          0.7175
         ]
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Top N features by percentile vs CV"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Top N features by percentile"
         }
        },
        "yaxis": {
         "title": {
          "text": "CV score"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"3ef22f73-7e2d-45f3-aa07-2332ddc8b1a0\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"3ef22f73-7e2d-45f3-aa07-2332ddc8b1a0\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '3ef22f73-7e2d-45f3-aa07-2332ddc8b1a0',\n",
       "                        [{\"name\": \"CV scores f_classif\", \"type\": \"scatter\", \"uid\": \"1f2f499f-616b-45c2-980d-40be7abaefe9\", \"x\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95], \"y\": [0.765, 0.7525000000000001, 0.73375, 0.714375, 0.7175, 0.7175, 0.7175, 0.7175, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999]}, {\"name\": \"CV scores mutual_info_classif\", \"type\": \"scatter\", \"uid\": \"48383b41-56f4-4fb8-b42e-ad2119731bb1\", \"x\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95], \"y\": [0.6849999999999999, 0.7268749999999999, 0.744375, 0.743125, 0.73375, 0.7474999999999999, 0.7637499999999999, 0.7637499999999999, 0.7606249999999999, 0.7362500000000001, 0.7537499999999999, 0.755625, 0.744375, 0.738125, 0.72875, 0.715625, 0.7175, 0.7206250000000001, 0.7175]}],\n",
       "                        {\"height\": 500, \"title\": {\"text\": \"Top N features by percentile vs CV\"}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Top N features by percentile\"}}, \"yaxis\": {\"title\": {\"text\": \"CV score\"}}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3ef22f73-7e2d-45f3-aa07-2332ddc8b1a0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [go.Scatter(x = list(range(5, 100, 5)),\n",
    "                   y = scores_dict['f_classif'],\n",
    "                   name = 'CV scores f_classif'\n",
    "                   ),\n",
    "        go.Scatter(x = list(range(5, 100, 5)),\n",
    "                   y = scores_dict['mutual_info_classif'],\n",
    "                   name = 'CV scores mutual_info_classif'\n",
    "                   )\n",
    "        ]\n",
    "layout = go.Layout(dict(title = \"Top N features by percentile vs CV\",\n",
    "                   xaxis = dict(title = 'Top N features by percentile'),\n",
    "                   yaxis = dict(title = 'CV score'),\n",
    "                   width=800,\n",
    "                   height=500,\n",
    "                  ))\n",
    "py.iplot(dict(data = data, layout = layout), filename = 'basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7838, std: 0.1011.\n",
      "CV mean score: 0.6931, std: 0.1356.\n",
      "CV mean score: 0.7731, std: 0.0808.\n",
      "CV mean score: 0.7381, std: 0.0934.\n",
      "CV mean score: 0.7525, std: 0.1102.\n",
      "CV mean score: 0.7219, std: 0.1100.\n",
      "CV mean score: 0.7463, std: 0.1153.\n",
      "CV mean score: 0.7206, std: 0.1096.\n",
      "CV mean score: 0.7288, std: 0.1146.\n",
      "CV mean score: 0.7525, std: 0.0908.\n",
      "CV mean score: 0.7144, std: 0.1232.\n",
      "CV mean score: 0.7431, std: 0.0966.\n",
      "CV mean score: 0.7175, std: 0.1239.\n",
      "CV mean score: 0.7431, std: 0.0966.\n",
      "CV mean score: 0.7175, std: 0.1239.\n",
      "CV mean score: 0.7338, std: 0.0945.\n",
      "CV mean score: 0.7175, std: 0.1239.\n",
      "CV mean score: 0.7256, std: 0.0888.\n",
      "CV mean score: 0.7175, std: 0.1248.\n",
      "CV mean score: 0.7431, std: 0.0803.\n",
      "CV mean score: 0.7175, std: 0.1248.\n",
      "CV mean score: 0.7637, std: 0.0794.\n",
      "CV mean score: 0.7175, std: 0.1248.\n",
      "CV mean score: 0.7606, std: 0.0762.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7606, std: 0.0762.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7569, std: 0.0873.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7588, std: 0.0658.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7219, std: 0.0758.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7612, std: 0.0692.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7219, std: 0.0659.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7331, std: 0.0617.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7238, std: 0.0718.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7188, std: 0.0689.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7188, std: 0.0769.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7156, std: 0.0798.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7219, std: 0.0832.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7300, std: 0.0904.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7225, std: 0.0972.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7100, std: 0.1200.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7238, std: 0.1180.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7238, std: 0.1190.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7112, std: 0.1198.\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {'f_classif': [], 'mutual_info_classif': []}\n",
    "for i in range(10, 301, 10):\n",
    "    s1 = SelectKBest(f_classif, k=i)\n",
    "    X_train1 = s1.fit_transform(X_train, y_train.values.astype(int))\n",
    "    X_test1 = s1.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['f_classif'].append(np.mean(scores))\n",
    "    \n",
    "    s2 = SelectKBest(mutual_info_classif, k=i)\n",
    "    X_train1 = s2.fit_transform(X_train, y_train.values.astype(int))\n",
    "    X_test1 = s2.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['mutual_info_classif'].append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "responsive": true,
        "showLink": false
       },
       "data": [
        {
         "name": "CV scores f_classif",
         "type": "scatter",
         "uid": "66ed6354-478d-4eea-b3a1-abf04332148f",
         "x": [
          10,
          20,
          30,
          40,
          50,
          60,
          70,
          80,
          90,
          100,
          110,
          120,
          130,
          140,
          150,
          160,
          170,
          180,
          190,
          200,
          210,
          220,
          230,
          240,
          250,
          260,
          270,
          280,
          290,
          300
         ],
         "y": [
          0.7837500000000001,
          0.7731250000000001,
          0.7525000000000001,
          0.7462500000000001,
          0.72875,
          0.714375,
          0.7175,
          0.7175,
          0.7175,
          0.7175,
          0.7175,
          0.7175,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999
         ]
        },
        {
         "name": "CV scores mutual_info_classsif",
         "type": "scatter",
         "uid": "a0212147-19f4-4a3a-a6d3-c416f0bd3005",
         "x": [
          10,
          20,
          30,
          40,
          50,
          60,
          70,
          80,
          90,
          100,
          110,
          120,
          130,
          140,
          150,
          160,
          170,
          180,
          190,
          200,
          210,
          220,
          230,
          240,
          250,
          260,
          270,
          280,
          290,
          300
         ],
         "y": [
          0.693125,
          0.7381249999999999,
          0.721875,
          0.7206250000000001,
          0.7525000000000001,
          0.743125,
          0.743125,
          0.73375,
          0.725625,
          0.743125,
          0.7637499999999999,
          0.7606249999999999,
          0.7606249999999999,
          0.756875,
          0.75875,
          0.721875,
          0.76125,
          0.721875,
          0.733125,
          0.7237500000000001,
          0.71875,
          0.71875,
          0.715625,
          0.721875,
          0.7300000000000001,
          0.7224999999999999,
          0.71,
          0.72375,
          0.72375,
          0.7112499999999999
         ]
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Top N features by SelectKBest vs CV"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Top N features by SelectKBest"
         }
        },
        "yaxis": {
         "title": {
          "text": "CV scores"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"19461937-2e4e-438d-9771-b87cce20d3d6\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"19461937-2e4e-438d-9771-b87cce20d3d6\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '19461937-2e4e-438d-9771-b87cce20d3d6',\n",
       "                        [{\"name\": \"CV scores f_classif\", \"type\": \"scatter\", \"uid\": \"93e8a7a2-a024-4732-9a61-415a6f247dcd\", \"x\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300], \"y\": [0.7837500000000001, 0.7731250000000001, 0.7525000000000001, 0.7462500000000001, 0.72875, 0.714375, 0.7175, 0.7175, 0.7175, 0.7175, 0.7175, 0.7175, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999]}, {\"name\": \"CV scores mutual_info_classsif\", \"type\": \"scatter\", \"uid\": \"e9931cc5-282c-420c-9482-aca2a99e741f\", \"x\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300], \"y\": [0.693125, 0.7381249999999999, 0.721875, 0.7206250000000001, 0.7525000000000001, 0.743125, 0.743125, 0.73375, 0.725625, 0.743125, 0.7637499999999999, 0.7606249999999999, 0.7606249999999999, 0.756875, 0.75875, 0.721875, 0.76125, 0.721875, 0.733125, 0.7237500000000001, 0.71875, 0.71875, 0.715625, 0.721875, 0.7300000000000001, 0.7224999999999999, 0.71, 0.72375, 0.72375, 0.7112499999999999]}],\n",
       "                        {\"height\": 500, \"title\": {\"text\": \"Top N features by SelectKBest vs CV\"}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Top N features by SelectKBest\"}}, \"yaxis\": {\"title\": {\"text\": \"CV scores\"}}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('19461937-2e4e-438d-9771-b87cce20d3d6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [go.Scatter(x = list(range(10, 301, 10)),\n",
    "                   y = scores_dict['f_classif'],\n",
    "                   name = \"CV scores f_classif\"\n",
    "                   ),\n",
    "        go.Scatter(x = list(range(10, 301, 10)),\n",
    "                   y = scores_dict['mutual_info_classif'],\n",
    "                   name = 'CV scores mutual_info_classsif'\n",
    "                   )\n",
    "       ]\n",
    "layout = go.Layout(dict(title = 'Top N features by SelectKBest vs CV',\n",
    "                        xaxis = dict(title = 'Top N features by SelectKBest'),\n",
    "                        yaxis = dict(title = 'CV scores'),\n",
    "                        width = 800,\n",
    "                        height = 500\n",
    "                   ))\n",
    "py.iplot(dict(data = data, layout = layout), filename = 'basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7288, std: 0.1146.\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k = 50)\n",
    "X_trainK = selector.fit_transform(X_train, y_train.values.astype(int))\n",
    "X_testK = selector.transform(X_test)\n",
    "oof_lr_1, prediction_lr_1, scores = train_model (X_trainK, X_testK, y_train, params = None, model_type = 'sklearn', model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.666819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.480487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.518379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.756674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.440701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.666819\n",
       "1  251  0.480487\n",
       "2  252  0.518379\n",
       "3  253  0.756674\n",
       "4  254  0.440701"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr_1\n",
    "submission.to_csv('top_n_features.csv', index = False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7662, std: 0.0736.\n",
      "CV mean score: 0.7762, std: 0.1012.\n",
      "CV mean score: 0.7775, std: 0.1018.\n",
      "CV mean score: 0.7631, std: 0.1392.\n",
      "CV mean score: 0.7525, std: 0.1177.\n",
      "CV mean score: 0.7412, std: 0.1142.\n",
      "CV mean score: 0.7319, std: 0.1122.\n",
      "CV mean score: 0.7319, std: 0.1132.\n",
      "CV mean score: 0.7319, std: 0.1132.\n",
      "CV mean score: 0.7319, std: 0.1132.\n",
      "CV mean score: 0.7319, std: 0.1132.\n",
      "CV mean score: 0.7319, std: 0.1132.\n",
      "CV mean score: 0.7319, std: 0.1132.\n",
      "CV mean score: 0.7256, std: 0.1085.\n",
      "CV mean score: 0.7256, std: 0.1085.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7225, std: 0.1104.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7194, std: 0.1140.\n",
      "CV mean score: 0.7144, std: 0.1163.\n",
      "CV mean score: 0.7144, std: 0.1163.\n",
      "CV mean score: 0.7144, std: 0.1163.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7112, std: 0.1198.\n",
      "CV mean score: 0.7112, std: 0.1198.\n"
     ]
    }
   ],
   "source": [
    "scores_list = []\n",
    "for i in range (10, 301, 5):\n",
    "    s = RFE(model, i, step = 1)\n",
    "    X_train1 = s.fit_transform(X_train, y_train.values.astype(int))\n",
    "    X_test1 = s.transform(X_test)\n",
    "    oof_lr_1, prediction_lr_1, scores = train_model(X_train1, X_test1, y_train, params = None, model_type = 'sklearn', model = model)\n",
    "    scores_list.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "responsive": true,
        "showLink": false
       },
       "data": [
        {
         "name": "CV scores RFE",
         "type": "scatter",
         "uid": "f08299b9-72f2-4534-ae8c-083481077752",
         "x": [
          10,
          15,
          20,
          25,
          30,
          35,
          40,
          45,
          50,
          55,
          60,
          65,
          70,
          75,
          80,
          85,
          90,
          95,
          100,
          105,
          110,
          115,
          120,
          125,
          130,
          135,
          140,
          145,
          150,
          155,
          160,
          165,
          170,
          175,
          180,
          185,
          190,
          195,
          200,
          205,
          210,
          215,
          220,
          225,
          230,
          235,
          240,
          245,
          250,
          255,
          260,
          265,
          270,
          275,
          280,
          285,
          290,
          295,
          300
         ],
         "y": [
          0.76625,
          0.7762499999999999,
          0.7775000000000001,
          0.7631249999999999,
          0.7525000000000001,
          0.74125,
          0.7318749999999999,
          0.7318749999999999,
          0.7318749999999999,
          0.7318749999999999,
          0.7318749999999999,
          0.7318749999999999,
          0.7318749999999999,
          0.725625,
          0.725625,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.7224999999999999,
          0.719375,
          0.719375,
          0.719375,
          0.719375,
          0.719375,
          0.719375,
          0.719375,
          0.719375,
          0.719375,
          0.714375,
          0.714375,
          0.714375,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999,
          0.7112499999999999
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Top N features by RFE vs CV"
        },
        "xaxis": {
         "title": {
          "text": "Top N features by RFE"
         }
        },
        "yaxis": {
         "title": {
          "text": "CV score"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"18c04c75-1035-42e0-af64-482ac7ff5567\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"18c04c75-1035-42e0-af64-482ac7ff5567\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '18c04c75-1035-42e0-af64-482ac7ff5567',\n",
       "                        [{\"name\": \"CV scores RFE\", \"type\": \"scatter\", \"uid\": \"8fd9909d-1779-4485-994a-b316421de136\", \"x\": [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295, 300], \"y\": [0.76625, 0.7762499999999999, 0.7775000000000001, 0.7631249999999999, 0.7525000000000001, 0.74125, 0.7318749999999999, 0.7318749999999999, 0.7318749999999999, 0.7318749999999999, 0.7318749999999999, 0.7318749999999999, 0.7318749999999999, 0.725625, 0.725625, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.7224999999999999, 0.719375, 0.719375, 0.719375, 0.719375, 0.719375, 0.719375, 0.719375, 0.719375, 0.719375, 0.714375, 0.714375, 0.714375, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999, 0.7112499999999999]}],\n",
       "                        {\"title\": {\"text\": \"Top N features by RFE vs CV\"}, \"xaxis\": {\"title\": {\"text\": \"Top N features by RFE\"}}, \"yaxis\": {\"title\": {\"text\": \"CV score\"}}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('18c04c75-1035-42e0-af64-482ac7ff5567');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(10, 301, 5)),\n",
    "        y = scores_list,\n",
    "        name = 'CV scores RFE'\n",
    "    )]\n",
    "layout = go.Layout(dict(title = \"Top N features by RFE vs CV\",\n",
    "                  xaxis = dict(title = 'Top N features by RFE'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7775, std: 0.1018.\n"
     ]
    }
   ],
   "source": [
    "selector = RFE(model, 20, step=1)\n",
    "X_trainK = selector.fit_transform(X_train, y_train.values.astype(int))\n",
    "X_testK = selector.transform(X_test)\n",
    "oof_lr_1, prediction_lr_rfe_20, scores = train_model(X_trainK, X_testK, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.650028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.519985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.761023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.412848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.650028\n",
       "1  251  0.456404\n",
       "2  252  0.519985\n",
       "3  253  0.761023\n",
       "4  254  0.412848"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr_rfe_20\n",
    "submission.to_csv('rfe.csv', index = False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.9109, std: 0.0957.\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k=20)\n",
    "X_trainK = selector.fit_transform(X_train, y_train.values.astype(int))\n",
    "X_testK = selector.transform(X_test)\n",
    "oof_glm, prediction_glm, scores = train_model(X_trainK, X_testK, y_train, params=None, model_type='glm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.396784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.195177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.616769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.765820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.100507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.396784\n",
       "1  251  0.195177\n",
       "2  252  0.616769\n",
       "3  253  0.765820\n",
       "4  254  0.100507"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_glm\n",
    "submission.to_csv('glm.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# градиентные бустинги не используем, т.к. признаков много, значений не много"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x33</td>\n",
       "      <td>0.818184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x65</td>\n",
       "      <td>0.506175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x217</td>\n",
       "      <td>0.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x91</td>\n",
       "      <td>0.210270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x73</td>\n",
       "      <td>0.171763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x199</td>\n",
       "      <td>0.136656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x117</td>\n",
       "      <td>0.130616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x258</td>\n",
       "      <td>0.123193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x133</td>\n",
       "      <td>0.117116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x295</td>\n",
       "      <td>0.094789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x189</td>\n",
       "      <td>0.081205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x298</td>\n",
       "      <td>0.051133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x129</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x226</td>\n",
       "      <td>0.050011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x108</td>\n",
       "      <td>0.032111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x82</td>\n",
       "      <td>0.023817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x63</td>\n",
       "      <td>0.020853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x80</td>\n",
       "      <td>0.015294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x252</td>\n",
       "      <td>0.014061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x134</td>\n",
       "      <td>0.006815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target feature    weight\n",
       "0      1.0     x33  0.818184\n",
       "1      1.0     x65  0.506175\n",
       "19     1.0    x217  0.288800\n",
       "18     1.0     x91  0.210270\n",
       "17     1.0     x73  0.171763\n",
       "2      1.0    x199  0.136656\n",
       "16     1.0    x117  0.130616\n",
       "15     1.0    x258  0.123193\n",
       "14     1.0    x133  0.117116\n",
       "13     1.0    x295  0.094789\n",
       "12     1.0    x189  0.081205\n",
       "11     1.0    x298  0.051133\n",
       "10     1.0    x129  0.050678\n",
       "3      1.0    x226  0.050011\n",
       "9      1.0    x108  0.032111\n",
       "8      1.0     x82  0.023817\n",
       "7      1.0     x63  0.020853\n",
       "6      1.0     x80  0.015294\n",
       "5      1.0    x252  0.014061\n",
       "4      1.0    x134  0.006815"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5_weights = eli5.formatters.as_dataframe.explain_weights_df(model)\n",
    "eli5_weights['weight'] = eli5_weights['weight'].abs()\n",
    "eli5_weights = eli5_weights.sort_values('weight', ascending=False)\n",
    "eli5_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.6756, std: 0.1044.\n",
      "CV mean score: 0.6756, std: 0.1044.\n",
      "CV mean score: 0.6650, std: 0.1068.\n",
      "CV mean score: 0.7412, std: 0.1134.\n",
      "CV mean score: 0.7412, std: 0.1134.\n",
      "CV mean score: 0.7256, std: 0.1084.\n",
      "CV mean score: 0.7356, std: 0.0915.\n",
      "CV mean score: 0.7356, std: 0.0915.\n",
      "CV mean score: 0.7356, std: 0.0915.\n",
      "CV mean score: 0.7431, std: 0.0985.\n",
      "CV mean score: 0.7431, std: 0.0985.\n",
      "CV mean score: 0.7400, std: 0.0992.\n",
      "CV mean score: 0.7488, std: 0.0955.\n",
      "CV mean score: 0.7488, std: 0.0955.\n",
      "CV mean score: 0.7488, std: 0.0955.\n",
      "CV mean score: 0.7400, std: 0.1132.\n",
      "CV mean score: 0.7400, std: 0.1132.\n",
      "CV mean score: 0.7400, std: 0.1132.\n",
      "CV mean score: 0.7400, std: 0.0974.\n",
      "CV mean score: 0.7400, std: 0.0974.\n",
      "CV mean score: 0.7400, std: 0.0974.\n",
      "CV mean score: 0.7856, std: 0.1066.\n",
      "CV mean score: 0.7856, std: 0.1066.\n",
      "CV mean score: 0.7856, std: 0.1066.\n",
      "CV mean score: 0.7738, std: 0.0795.\n",
      "CV mean score: 0.7738, std: 0.0795.\n",
      "CV mean score: 0.7675, std: 0.0903.\n",
      "CV mean score: 0.7744, std: 0.0778.\n",
      "CV mean score: 0.7744, std: 0.0778.\n",
      "CV mean score: 0.7681, std: 0.0843.\n",
      "CV mean score: 0.7500, std: 0.0940.\n",
      "CV mean score: 0.7500, std: 0.0940.\n",
      "CV mean score: 0.7500, std: 0.0940.\n",
      "CV mean score: 0.7381, std: 0.1054.\n",
      "CV mean score: 0.7381, std: 0.1054.\n",
      "CV mean score: 0.7381, std: 0.1054.\n",
      "CV mean score: 0.7631, std: 0.0848.\n",
      "CV mean score: 0.7631, std: 0.0848.\n",
      "CV mean score: 0.7569, std: 0.0942.\n",
      "CV mean score: 0.7556, std: 0.0917.\n",
      "CV mean score: 0.7556, std: 0.0917.\n",
      "CV mean score: 0.7556, std: 0.0917.\n",
      "CV mean score: 0.7731, std: 0.0931.\n",
      "CV mean score: 0.7731, std: 0.0931.\n",
      "CV mean score: 0.7669, std: 0.1061.\n",
      "CV mean score: 0.7744, std: 0.0907.\n",
      "CV mean score: 0.7744, std: 0.0907.\n",
      "CV mean score: 0.7744, std: 0.0907.\n",
      "CV mean score: 0.7900, std: 0.0800.\n",
      "CV mean score: 0.7900, std: 0.0800.\n",
      "CV mean score: 0.7838, std: 0.0874.\n",
      "CV mean score: 0.7994, std: 0.0874.\n",
      "CV mean score: 0.7994, std: 0.0874.\n",
      "CV mean score: 0.7994, std: 0.0874.\n",
      "CV mean score: 0.7744, std: 0.1032.\n",
      "CV mean score: 0.7744, std: 0.1032.\n",
      "CV mean score: 0.7744, std: 0.1032.\n",
      "CV mean score: 0.7744, std: 0.0993.\n",
      "CV mean score: 0.7744, std: 0.0993.\n",
      "CV mean score: 0.7744, std: 0.0993.\n",
      "CV mean score: 0.7681, std: 0.0926.\n",
      "CV mean score: 0.7681, std: 0.0926.\n",
      "CV mean score: 0.7681, std: 0.0926.\n",
      "CV mean score: 0.7681, std: 0.0926.\n",
      "CV mean score: 0.7681, std: 0.0926.\n",
      "CV mean score: 0.7681, std: 0.0926.\n",
      "CV mean score: 0.7650, std: 0.0942.\n",
      "CV mean score: 0.7650, std: 0.0942.\n",
      "CV mean score: 0.7588, std: 0.1102.\n",
      "CV mean score: 0.7681, std: 0.0987.\n",
      "CV mean score: 0.7681, std: 0.0987.\n",
      "CV mean score: 0.7681, std: 0.1134.\n",
      "CV mean score: 0.7619, std: 0.1143.\n",
      "CV mean score: 0.7619, std: 0.1143.\n",
      "CV mean score: 0.7619, std: 0.1143.\n",
      "CV mean score: 0.7650, std: 0.1164.\n",
      "CV mean score: 0.7650, std: 0.1164.\n",
      "CV mean score: 0.7681, std: 0.1185.\n",
      "CV mean score: 0.7444, std: 0.1233.\n",
      "CV mean score: 0.7444, std: 0.1233.\n",
      "CV mean score: 0.7494, std: 0.1199.\n",
      "CV mean score: 0.7444, std: 0.1185.\n",
      "CV mean score: 0.7444, std: 0.1185.\n",
      "CV mean score: 0.7494, std: 0.1149.\n",
      "CV mean score: 0.7444, std: 0.1185.\n",
      "CV mean score: 0.7444, std: 0.1185.\n",
      "CV mean score: 0.7494, std: 0.1149.\n",
      "CV mean score: 0.7444, std: 0.1185.\n",
      "CV mean score: 0.7444, std: 0.1185.\n",
      "CV mean score: 0.7494, std: 0.1149.\n",
      "CV mean score: 0.7394, std: 0.1149.\n",
      "CV mean score: 0.7394, std: 0.1149.\n",
      "CV mean score: 0.7444, std: 0.1114.\n",
      "CV mean score: 0.7525, std: 0.0933.\n",
      "CV mean score: 0.7525, std: 0.0933.\n",
      "CV mean score: 0.7463, std: 0.1122.\n",
      "CV mean score: 0.7463, std: 0.1122.\n",
      "CV mean score: 0.7463, std: 0.1122.\n",
      "CV mean score: 0.7463, std: 0.1122.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7381, std: 0.1123.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7381, std: 0.1123.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n",
      "CV mean score: 0.7350, std: 0.1093.\n"
     ]
    }
   ],
   "source": [
    "train['mean'] = train.mean(1)\n",
    "train['std'] = train.std(1)\n",
    "test['mean'] = test.mean(1)\n",
    "test['std'] = test.std(1)\n",
    "\n",
    "scores_dict = {'simple': [], 'with_std': [], 'with_mean': []}\n",
    "for i in range(1, eli5_weights.shape[0] + 1):\n",
    "    top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:i]\n",
    "    \n",
    "    X_train = train[top_features]\n",
    "    X_test = test[top_features]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['simple'].append(np.mean(scores))\n",
    "    \n",
    "    X_train = train[top_features + ['mean']]\n",
    "    X_test = test[top_features + ['mean']]\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "    X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['with_mean'].append(np.mean(scores))\n",
    "    \n",
    "    X_train = train[top_features + ['std']]\n",
    "    X_test = test[top_features + ['std']]\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "    X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model)\n",
    "    scores_dict['with_std'].append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "responsive": true,
        "showLink": false
       },
       "data": [
        {
         "name": "Simple CV scores",
         "type": "scatter",
         "uid": "061188e6-f12e-40d0-abb0-7a7b389314ff",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
         ],
         "y": [
          0.6756249999999999,
          0.74125,
          0.735625,
          0.743125,
          0.74875,
          0.74,
          0.74,
          0.7856249999999999,
          0.77375,
          0.774375,
          0.75,
          0.7381249999999999,
          0.7631249999999999,
          0.755625,
          0.7731250000000001,
          0.774375,
          0.79,
          0.7993750000000001,
          0.774375,
          0.774375,
          0.7681250000000001,
          0.7681250000000001,
          0.765,
          0.7681250000000001,
          0.7618750000000001,
          0.765,
          0.744375,
          0.744375,
          0.744375,
          0.744375,
          0.739375,
          0.7525000000000001,
          0.7462500000000001,
          0.735,
          0.735,
          0.735,
          0.735,
          0.735,
          0.735,
          0.735
         ]
        },
        {
         "name": "With mean CV scores",
         "type": "scatter",
         "uid": "cc50aad7-78e5-409f-a746-842a5911c011",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
         ],
         "y": [
          0.6756249999999999,
          0.74125,
          0.735625,
          0.743125,
          0.74875,
          0.74,
          0.74,
          0.7856249999999999,
          0.77375,
          0.774375,
          0.75,
          0.7381249999999999,
          0.7631249999999999,
          0.755625,
          0.7731250000000001,
          0.774375,
          0.79,
          0.7993750000000001,
          0.774375,
          0.774375,
          0.7681250000000001,
          0.7681250000000001,
          0.765,
          0.7681250000000001,
          0.7618750000000001,
          0.765,
          0.744375,
          0.744375,
          0.744375,
          0.744375,
          0.739375,
          0.7525000000000001,
          0.7462500000000001,
          0.735,
          0.735,
          0.735,
          0.735,
          0.735,
          0.735,
          0.735
         ]
        },
        {
         "name": "With std CV scores",
         "type": "scatter",
         "uid": "c63ce8dd-b4a8-4f4d-8bdc-6b1411d11f5a",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
         ],
         "y": [
          0.665,
          0.725625,
          0.735625,
          0.74,
          0.74875,
          0.74,
          0.74,
          0.7856249999999999,
          0.7675000000000001,
          0.7681250000000001,
          0.75,
          0.7381249999999999,
          0.756875,
          0.755625,
          0.766875,
          0.774375,
          0.7837500000000001,
          0.7993750000000001,
          0.774375,
          0.774375,
          0.7681250000000001,
          0.7681250000000001,
          0.75875,
          0.7681250000000001,
          0.7618750000000001,
          0.7681250000000001,
          0.749375,
          0.749375,
          0.749375,
          0.749375,
          0.744375,
          0.7462500000000001,
          0.7462500000000001,
          0.735,
          0.735,
          0.7381249999999999,
          0.7381249999999999,
          0.735,
          0.735,
          0.735
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Top N features vs CV"
        },
        "xaxis": {
         "title": {
          "text": "Top N features"
         }
        },
        "yaxis": {
         "title": {
          "text": "CV score"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"cbeea4b7-f0d5-4599-b580-5e43af8e7e13\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"cbeea4b7-f0d5-4599-b580-5e43af8e7e13\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'cbeea4b7-f0d5-4599-b580-5e43af8e7e13',\n",
       "                        [{\"name\": \"Simple CV scores\", \"type\": \"scatter\", \"uid\": \"ae3606da-152d-4e6d-9212-4e5c00bd673c\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], \"y\": [0.6756249999999999, 0.74125, 0.735625, 0.743125, 0.74875, 0.74, 0.74, 0.7856249999999999, 0.77375, 0.774375, 0.75, 0.7381249999999999, 0.7631249999999999, 0.755625, 0.7731250000000001, 0.774375, 0.79, 0.7993750000000001, 0.774375, 0.774375, 0.7681250000000001, 0.7681250000000001, 0.765, 0.7681250000000001, 0.7618750000000001, 0.765, 0.744375, 0.744375, 0.744375, 0.744375, 0.739375, 0.7525000000000001, 0.7462500000000001, 0.735, 0.735, 0.735, 0.735, 0.735, 0.735, 0.735]}, {\"name\": \"With mean CV scores\", \"type\": \"scatter\", \"uid\": \"725ca617-369f-4849-a5d8-b0e9b3392dab\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], \"y\": [0.6756249999999999, 0.74125, 0.735625, 0.743125, 0.74875, 0.74, 0.74, 0.7856249999999999, 0.77375, 0.774375, 0.75, 0.7381249999999999, 0.7631249999999999, 0.755625, 0.7731250000000001, 0.774375, 0.79, 0.7993750000000001, 0.774375, 0.774375, 0.7681250000000001, 0.7681250000000001, 0.765, 0.7681250000000001, 0.7618750000000001, 0.765, 0.744375, 0.744375, 0.744375, 0.744375, 0.739375, 0.7525000000000001, 0.7462500000000001, 0.735, 0.735, 0.735, 0.735, 0.735, 0.735, 0.735]}, {\"name\": \"With std CV scores\", \"type\": \"scatter\", \"uid\": \"fd58191a-42c9-4892-9159-b19342a24324\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], \"y\": [0.665, 0.725625, 0.735625, 0.74, 0.74875, 0.74, 0.74, 0.7856249999999999, 0.7675000000000001, 0.7681250000000001, 0.75, 0.7381249999999999, 0.756875, 0.755625, 0.766875, 0.774375, 0.7837500000000001, 0.7993750000000001, 0.774375, 0.774375, 0.7681250000000001, 0.7681250000000001, 0.75875, 0.7681250000000001, 0.7618750000000001, 0.7681250000000001, 0.749375, 0.749375, 0.749375, 0.749375, 0.744375, 0.7462500000000001, 0.7462500000000001, 0.735, 0.735, 0.7381249999999999, 0.7381249999999999, 0.735, 0.735, 0.735]}],\n",
       "                        {\"title\": {\"text\": \"Top N features vs CV\"}, \"xaxis\": {\"title\": {\"text\": \"Top N features\"}}, \"yaxis\": {\"title\": {\"text\": \"CV score\"}}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('cbeea4b7-f0d5-4599-b580-5e43af8e7e13');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['simple'],\n",
    "        name = 'Simple CV scores'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['with_mean'],\n",
    "        name = 'With mean CV scores'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['with_std'],\n",
    "        name = 'With std CV scores'\n",
    "    )]\n",
    "layout = go.Layout(dict(title = \"Top N features vs CV\",\n",
    "                  xaxis = dict(title = 'Top N features'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eli5_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fc7081d392de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscores_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'simple'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'with_std'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'with_mean'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meli5_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtop_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meli5_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'BIAS'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eli5_weights' is not defined"
     ]
    }
   ],
   "source": [
    "train['mean'] = train.mean(1)\n",
    "train['std'] = train.std(1)\n",
    "test['mean'] = test.mean(1)\n",
    "test['std'] = test.std(1)\n",
    "\n",
    "scores_dict = {'simple': [], 'with_std': [], 'with_mean': []}\n",
    "for i in range(1, eli5_weights.shape[0] + 1):\n",
    "    top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:i]\n",
    "    \n",
    "    X_train = train[top_features]\n",
    "    X_test = test[top_features]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model, folds=repeated_fold)\n",
    "    scores_dict['simple'].append(np.mean(scores))\n",
    "    \n",
    "    X_train = train[top_features + ['mean']]\n",
    "    X_test = test[top_features + ['mean']]\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "    X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_fold)\n",
    "    scores_dict['with_mean'].append(np.mean(scores))\n",
    "    \n",
    "    X_train = train[top_features + ['std']]\n",
    "    X_test = test[top_features + ['std']]\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "    X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "    oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_fold)\n",
    "    scores_dict['with_std'].append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "responsive": true,
        "showLink": false
       },
       "data": [
        {
         "name": "Simple CV scores",
         "type": "scatter",
         "uid": "68d79d61-5afd-4487-b882-c49e03382760",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
         ],
         "y": [
          0.6814375000000001,
          0.7364375,
          0.7336562500000001,
          0.7421875,
          0.7447812500000001,
          0.746375,
          0.74984375,
          0.77003125,
          0.7723125000000001,
          0.7760625,
          0.7588749999999999,
          0.75,
          0.7528125,
          0.75859375,
          0.76515625,
          0.7696875,
          0.78071875,
          0.7761875,
          0.7735625,
          0.77140625,
          0.77278125,
          0.7720625000000001,
          0.7687812500000001,
          0.7682187500000001,
          0.7635937500000002,
          0.7615625,
          0.7625624999999999,
          0.7571875,
          0.75640625,
          0.7531562500000001,
          0.7499687500000002,
          0.7502500000000001,
          0.7489687500000001,
          0.74796875,
          0.746375,
          0.7437812500000001,
          0.7436250000000001,
          0.7396250000000001,
          0.7387500000000001,
          0.7387500000000001
         ]
        },
        {
         "name": "With mean CV scores",
         "type": "scatter",
         "uid": "acf0031d-62c2-45bd-9d49-7215dba25079",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
         ],
         "y": [
          0.6814375000000001,
          0.7364375,
          0.7336562500000001,
          0.7421875,
          0.7447812500000001,
          0.746375,
          0.74984375,
          0.77003125,
          0.7723125000000001,
          0.7760625,
          0.7588749999999999,
          0.75,
          0.7528125,
          0.75859375,
          0.76515625,
          0.7696875,
          0.78071875,
          0.7761875,
          0.7735625,
          0.77140625,
          0.77278125,
          0.7720625000000001,
          0.7687812500000001,
          0.7682187500000001,
          0.7633437500000001,
          0.76140625,
          0.7625624999999999,
          0.7574375000000001,
          0.75640625,
          0.7531562500000001,
          0.7499687500000002,
          0.7502500000000001,
          0.7489687500000001,
          0.74796875,
          0.746375,
          0.7437812500000001,
          0.7436250000000001,
          0.7396250000000001,
          0.7387500000000001,
          0.7387500000000001
         ]
        },
        {
         "name": "With std CV scores",
         "type": "scatter",
         "uid": "c58f4ba3-9276-488a-986a-d93e20ca8d40",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
         ],
         "y": [
          0.6755937500000002,
          0.7338125,
          0.73165625,
          0.7403437500000001,
          0.7436875000000001,
          0.7461250000000001,
          0.7494375000000001,
          0.7671875000000001,
          0.77228125,
          0.7759687500000001,
          0.75859375,
          0.7499687499999999,
          0.7513749999999999,
          0.757875,
          0.76403125,
          0.7677812500000001,
          0.77965625,
          0.7740312500000001,
          0.77153125,
          0.76975,
          0.7712187500000001,
          0.7703749999999999,
          0.76665625,
          0.7646562500000001,
          0.7614375000000001,
          0.75921875,
          0.75925,
          0.7536562499999999,
          0.753125,
          0.7498750000000001,
          0.74740625,
          0.7470625,
          0.74546875,
          0.7449375,
          0.7425625000000001,
          0.7394062500000002,
          0.7394062500000002,
          0.736,
          0.73478125,
          0.73478125
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Top N features vs repeated folds CV"
        },
        "xaxis": {
         "title": {
          "text": "Top N features"
         }
        },
        "yaxis": {
         "title": {
          "text": "CV score"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"f9cfb5c1-c457-45f7-a148-efb5144e2854\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"f9cfb5c1-c457-45f7-a148-efb5144e2854\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'f9cfb5c1-c457-45f7-a148-efb5144e2854',\n",
       "                        [{\"name\": \"Simple CV scores\", \"type\": \"scatter\", \"uid\": \"f8352f45-39dc-4859-b605-5cfb77295836\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], \"y\": [0.6814375000000001, 0.7364375, 0.7336562500000001, 0.7421875, 0.7447812500000001, 0.746375, 0.74984375, 0.77003125, 0.7723125000000001, 0.7760625, 0.7588749999999999, 0.75, 0.7528125, 0.75859375, 0.76515625, 0.7696875, 0.78071875, 0.7761875, 0.7735625, 0.77140625, 0.77278125, 0.7720625000000001, 0.7687812500000001, 0.7682187500000001, 0.7635937500000002, 0.7615625, 0.7625624999999999, 0.7571875, 0.75640625, 0.7531562500000001, 0.7499687500000002, 0.7502500000000001, 0.7489687500000001, 0.74796875, 0.746375, 0.7437812500000001, 0.7436250000000001, 0.7396250000000001, 0.7387500000000001, 0.7387500000000001]}, {\"name\": \"With mean CV scores\", \"type\": \"scatter\", \"uid\": \"1a41d27a-6af6-4344-b222-967c717f2800\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], \"y\": [0.6814375000000001, 0.7364375, 0.7336562500000001, 0.7421875, 0.7447812500000001, 0.746375, 0.74984375, 0.77003125, 0.7723125000000001, 0.7760625, 0.7588749999999999, 0.75, 0.7528125, 0.75859375, 0.76515625, 0.7696875, 0.78071875, 0.7761875, 0.7735625, 0.77140625, 0.77278125, 0.7720625000000001, 0.7687812500000001, 0.7682187500000001, 0.7633437500000001, 0.76140625, 0.7625624999999999, 0.7574375000000001, 0.75640625, 0.7531562500000001, 0.7499687500000002, 0.7502500000000001, 0.7489687500000001, 0.74796875, 0.746375, 0.7437812500000001, 0.7436250000000001, 0.7396250000000001, 0.7387500000000001, 0.7387500000000001]}, {\"name\": \"With std CV scores\", \"type\": \"scatter\", \"uid\": \"7816402c-0089-4dd5-b396-01933e9ec97c\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], \"y\": [0.6755937500000002, 0.7338125, 0.73165625, 0.7403437500000001, 0.7436875000000001, 0.7461250000000001, 0.7494375000000001, 0.7671875000000001, 0.77228125, 0.7759687500000001, 0.75859375, 0.7499687499999999, 0.7513749999999999, 0.757875, 0.76403125, 0.7677812500000001, 0.77965625, 0.7740312500000001, 0.77153125, 0.76975, 0.7712187500000001, 0.7703749999999999, 0.76665625, 0.7646562500000001, 0.7614375000000001, 0.75921875, 0.75925, 0.7536562499999999, 0.753125, 0.7498750000000001, 0.74740625, 0.7470625, 0.74546875, 0.7449375, 0.7425625000000001, 0.7394062500000002, 0.7394062500000002, 0.736, 0.73478125, 0.73478125]}],\n",
       "                        {\"title\": {\"text\": \"Top N features vs repeated folds CV\"}, \"xaxis\": {\"title\": {\"text\": \"Top N features\"}}, \"yaxis\": {\"title\": {\"text\": \"CV score\"}}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f9cfb5c1-c457-45f7-a148-efb5144e2854');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['simple'],\n",
    "        name = 'Simple CV scores'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['with_mean'],\n",
    "        name = 'With mean CV scores'\n",
    "    ), go.Scatter(\n",
    "        x = list(range(1, eli5_weights.shape[0] + 1)),\n",
    "        y = scores_dict['with_std'],\n",
    "        name = 'With std CV scores'\n",
    "    )]\n",
    "layout = go.Layout(dict(title = \"Top N features vs repeated folds CV\",\n",
    "                  xaxis = dict(title = 'Top N features'),\n",
    "                  yaxis = dict(title = 'CV score'),\n",
    "                  ))\n",
    "py.iplot(dict(data=data, layout=layout), filename='basic-line') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7667, std: 0.1230.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>13.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>10.684953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>11.294881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>13.357516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>7.197818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     target\n",
       "0  250  13.761194\n",
       "1  251  10.684953\n",
       "2  252  11.294881\n",
       "3  253  13.357516\n",
       "4  254   7.197818"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:8]\n",
    "\n",
    "X_train = train[top_features + ['mean']]\n",
    "X_test = test[top_features + ['mean']]\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_fold)\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr\n",
    "submission.to_csv('submission_top8.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7208, std: 0.1234.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>13.625223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>10.331347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>11.236356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>15.183014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>8.862334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     target\n",
       "0  250  13.625223\n",
       "1  251  10.331347\n",
       "2  252  11.236356\n",
       "3  253  15.183014\n",
       "4  254   8.862334"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = train.drop(['id','target'], axis=1).values\n",
    "X_test = test.drop(['id'], axis=1).values\n",
    "data = scaler.fit_transform(np.concatenate((X_train, X_test), axis=0))\n",
    "X_train = data[:250]\n",
    "X_test = data[250:]\n",
    "oof_lr, prediction_lr, scores = train_model(X_train, X_test, y_train, params=None, model_type='sklearn', model=model, folds=repeated_fold)\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr\n",
    "submission.to_csv('submission_concat_lr.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7577, std: 0.1228.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>14.144198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>10.347306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>10.246703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>13.420152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>9.266086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     target\n",
       "0  250  14.144198\n",
       "1  251  10.347306\n",
       "2  252  10.246703\n",
       "3  253  13.420152\n",
       "4  254   9.266086"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:8]\n",
    "\n",
    "X_train = train[top_features + ['mean']]\n",
    "X_test = test[top_features + ['mean']]\n",
    "scaler = RobustScaler()\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_fold)\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr\n",
    "submission.to_csv('submission_top8.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7541, std: 0.1199.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>13.289019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>10.404187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>9.931023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>14.220073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>6.612833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     target\n",
       "0  250  13.289019\n",
       "1  251  10.404187\n",
       "2  252   9.931023\n",
       "3  253  14.220073\n",
       "4  254   6.612833"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features = [i[1:] for i in eli5_weights.feature if 'BIAS' not in i][:17]\n",
    "\n",
    "X_train = train[top_features + ['mean']]\n",
    "X_test = test[top_features + ['mean']]\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns[:-1]] = scaler.fit_transform(X_train[X_train.columns[:-1]])\n",
    "X_test[X_train.columns[:-1]] = scaler.transform(X_test[X_train.columns[:-1]])\n",
    "oof_lr, prediction_lr, scores = train_model(X_train.values, X_test.values, y_train, params=None, model_type='sklearn', model=model, folds=repeated_fold)\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr\n",
    "submission.to_csv('submission_top17.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 302)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 principal components explain 94.23% of variance\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(n_components = 160, svd_solver = 'full', random_state = 42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "print('%d principal components explain %.2f%% of variance' %\n",
    "      (pca.n_components_, 100 * np.cumsum(pca.explained_variance_ratio_)[-1]))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), lw=2, color='k')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')\n",
    "plt.xlim(0, 160)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93572399, 0.93741059, 0.93906464, 0.94070562, 0.94230172])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.6669, std: 0.1573.\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(X_train_pca, X_test_pca, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.508921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.607448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.413165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.740920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.392283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.508921\n",
       "1  251  0.607448\n",
       "2  252  0.413165\n",
       "3  253  0.740920\n",
       "4  254  0.392283"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr\n",
    "submission.to_csv('submission_pca.csv', index = False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7250, std: 0.0889.\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "X_test = test.drop(['id'], axis = 1)\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model = linear_model.LogisticRegression(class_weight = 'balanced', \n",
    "                                        C = 0.1,\n",
    "                                        penalty = 'l1',\n",
    "                                        solver = 'liblinear'\n",
    "                                        )\n",
    "oof_lr_1, prediction_lr_1, scores = train_model(X_train, X_test, y_train, params = None, model_type = 'sklearn', model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.666838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.509515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.498082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.690974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.493148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.666838\n",
       "1  251  0.509515\n",
       "2  252  0.498082\n",
       "3  253  0.690974\n",
       "4  254  0.493148"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = prediction_lr_1\n",
    "submission.to_csv('robust_lr.csv', index = False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
