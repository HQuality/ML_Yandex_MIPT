{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, LinearRegression, LogisticRegressionCV, PassiveAggressiveClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Импортирую библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'products_sentiment_train.tsv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7bea5ee82bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproducts_sentiment_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'products_sentiment_train.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mproducts_sentiment_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts_sentiment_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts_sentiment_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'products_sentiment_train.tsv' does not exist"
     ]
    }
   ],
   "source": [
    "products_sentiment_train = pd.read_csv('products_sentiment_train.tsv', sep='\\t', header=None, names=['text','class'])\n",
    "products_sentiment_train.head()\n",
    "\n",
    "labels = list(products_sentiment_train['class'])\n",
    "texts = list(products_sentiment_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "1 / 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 360\n",
      "3 / 360\n",
      "4 / 360\n",
      "5 / 360\n",
      "6 / 360\n",
      "7 / 360\n",
      "8 / 360\n",
      "9 / 360\n",
      "10 / 360\n",
      "11 / 360\n",
      "12 / 360\n",
      "13 / 360\n",
      "14 / 360\n",
      "15 / 360\n",
      "16 / 360\n",
      "17 / 360\n",
      "18 / 360\n",
      "19 / 360\n",
      "20 / 360\n",
      "21 / 360\n",
      "22 / 360\n",
      "23 / 360\n",
      "24 / 360\n",
      "25 / 360\n",
      "26 / 360\n",
      "27 / 360\n",
      "28 / 360\n",
      "29 / 360\n",
      "30 / 360\n",
      "31 / 360\n",
      "32 / 360\n",
      "33 / 360\n",
      "34 / 360\n",
      "35 / 360\n",
      "36 / 360\n",
      "37 / 360\n",
      "38 / 360\n",
      "39 / 360\n",
      "40 / 360\n",
      "41 / 360\n",
      "42 / 360\n",
      "43 / 360\n",
      "44 / 360\n",
      "45 / 360\n",
      "46 / 360\n",
      "47 / 360\n",
      "48 / 360\n",
      "49 / 360\n",
      "50 / 360\n",
      "51 / 360\n",
      "52 / 360\n",
      "53 / 360\n",
      "54 / 360\n",
      "55 / 360\n",
      "56 / 360\n",
      "57 / 360\n",
      "58 / 360\n",
      "0.787 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (1, 6) char 0.4\n",
      "0.79250507993\n",
      "0.791008073942\n",
      "0.796501591412\n",
      "0.788499577422\n",
      "0.790500080919\n",
      "mean= 0.791802880725\n",
      "59 / 360\n",
      "0.7835 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (1, 6) char 0.5\n",
      "0.788998579418\n",
      "0.786496076915\n",
      "0.789502076927\n",
      "0.78999658341\n",
      "0.792502082921\n",
      "mean= 0.789499079918\n",
      "60 / 360\n",
      "0.7805 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (1, 6) char 0.6\n",
      "0.790500080919\n",
      "0.789995084905\n",
      "0.78800207393\n",
      "0.789003074931\n",
      "0.79049708391\n",
      "mean= 0.789599479719\n",
      "61 / 360\n",
      "62 / 360\n",
      "0.783 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (1, 6) char 0.8\n",
      "0.789995084905\n",
      "0.790498582415\n",
      "0.790501579424\n",
      "0.788496580413\n",
      "0.790002577428\n",
      "mean= 0.789898880917\n",
      "63 / 360\n",
      "0.782 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (1, 6) char 0.9\n",
      "0.791499583416\n",
      "0.790503077928\n",
      "0.7939960919\n",
      "0.790498582415\n",
      "0.790004075932\n",
      "mean= 0.791300282318\n",
      "64 / 360\n",
      "65 / 360\n",
      "66 / 360\n",
      "67 / 360\n",
      "68 / 360\n",
      "69 / 360\n",
      "70 / 360\n",
      "71 / 360\n",
      "72 / 360\n",
      "73 / 360\n",
      "74 / 360\n",
      "75 / 360\n",
      "76 / 360\n",
      "77 / 360\n",
      "78 / 360\n",
      "79 / 360\n",
      "80 / 360\n",
      "81 / 360\n",
      "0.781 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 7) char 0.3\n",
      "0.794502586419\n",
      "0.789992087896\n",
      "0.792999586413\n",
      "0.792500584417\n",
      "0.792003080925\n",
      "mean= 0.792399585214\n",
      "82 / 360\n",
      "0.7815 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 7) char 0.4\n",
      "0.792001582421\n",
      "0.790501579424\n",
      "0.786000071928\n",
      "0.790500080919\n",
      "0.793002583422\n",
      "mean= 0.790401179623\n",
      "83 / 360\n",
      "84 / 360\n",
      "0.782 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 7) char 0.6\n",
      "0.791009572447\n",
      "0.790997584411\n",
      "0.79200457943\n",
      "0.792001582421\n",
      "0.790001078923\n",
      "mean= 0.791202879526\n",
      "85 / 360\n",
      "0.7815 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 7) char 0.7\n",
      "0.788502574431\n",
      "0.790999082915\n",
      "0.795003086919\n",
      "0.795999592407\n",
      "0.790997584411\n",
      "mean= 0.792300384217\n",
      "86 / 360\n",
      "0.7845 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 7) char 0.8\n",
      "0.794998591406\n",
      "0.794003584423\n",
      "0.792996589404\n",
      "0.790008571446\n",
      "0.792506578435\n",
      "mean= 0.792902783023\n",
      "87 / 360\n",
      "0.7835 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 7) char 0.9\n",
      "0.794003584423\n",
      "0.797005088921\n",
      "0.787507567448\n",
      "0.790504576433\n",
      "0.795004585424\n",
      "mean= 0.79280508053\n",
      "88 / 360\n",
      "89 / 360\n",
      "90 / 360\n",
      "91 / 360\n",
      "92 / 360\n",
      "93 / 360\n",
      "94 / 360\n",
      "95 / 360\n",
      "96 / 360\n",
      "97 / 360\n",
      "98 / 360\n",
      "99 / 360\n",
      "100 / 360\n",
      "101 / 360\n",
      "102 / 360\n",
      "103 / 360\n",
      "104 / 360\n",
      "105 / 360\n",
      "0.7805 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 6) char 0.3\n",
      "0.793500086913\n",
      "0.79049708391\n",
      "0.788998579418\n",
      "0.790506074937\n",
      "0.789503575432\n",
      "mean= 0.790601080122\n",
      "106 / 360\n",
      "0.784 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 6) char 0.4\n",
      "0.789998081914\n",
      "0.789000077922\n",
      "0.792503581426\n",
      "0.790498582415\n",
      "0.788995582409\n",
      "mean= 0.790199181217\n",
      "107 / 360\n",
      "108 / 360\n",
      "0.7845 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 6) char 0.6\n",
      "0.793501585418\n",
      "0.7894930859\n",
      "0.79449958941\n",
      "0.791002079924\n",
      "0.791498084911\n",
      "mean= 0.791998885113\n",
      "109 / 360\n",
      "0.7885 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 6) char 0.7\n",
      "0.792998087908\n",
      "0.789500578423\n",
      "0.791490592389\n",
      "0.79049708391\n",
      "0.787492582403\n",
      "mean= 0.790395785007\n",
      "110 / 360\n",
      "0.7845 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 6) char 0.8\n",
      "0.792499085912\n",
      "0.796497095898\n",
      "0.793994593396\n",
      "0.792999586413\n",
      "0.790996085906\n",
      "mean= 0.793397289505\n",
      "111 / 360\n",
      "0.7845 <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> (2, 6) char 0.9\n",
      "0.785002067936\n",
      "0.789999580419\n",
      "0.790494086901\n",
      "0.788997080913\n",
      "0.790503077928\n",
      "mean= 0.78899917882\n",
      "112 / 360\n",
      "113 / 360\n",
      "114 / 360\n",
      "115 / 360\n",
      "116 / 360\n",
      "117 / 360\n",
      "118 / 360\n",
      "119 / 360\n",
      "120 / 360\n",
      "121 / 360\n",
      "122 / 360\n",
      "123 / 360\n",
      "124 / 360\n",
      "125 / 360\n",
      "126 / 360\n",
      "127 / 360\n",
      "128 / 360\n",
      "129 / 360\n",
      "130 / 360\n",
      "131 / 360\n",
      "132 / 360\n",
      "133 / 360\n",
      "134 / 360\n",
      "135 / 360\n",
      "136 / 360\n",
      "137 / 360\n",
      "138 / 360\n",
      "139 / 360\n",
      "140 / 360\n",
      "141 / 360\n",
      "142 / 360\n",
      "143 / 360\n",
      "144 / 360\n",
      "145 / 360\n",
      "146 / 360\n",
      "147 / 360\n",
      "148 / 360\n",
      "149 / 360\n",
      "150 / 360\n",
      "151 / 360\n",
      "152 / 360\n",
      "153 / 360\n",
      "154 / 360\n",
      "155 / 360\n",
      "156 / 360\n",
      "157 / 360\n",
      "158 / 360\n",
      "159 / 360\n",
      "160 / 360\n",
      "161 / 360\n",
      "162 / 360\n",
      "163 / 360\n",
      "164 / 360\n",
      "165 / 360\n",
      "166 / 360\n",
      "167 / 360\n",
      "168 / 360\n",
      "169 / 360\n",
      "170 / 360\n",
      "171 / 360\n",
      "172 / 360\n",
      "173 / 360\n",
      "174 / 360\n",
      "175 / 360\n",
      "176 / 360\n",
      "177 / 360\n",
      "0.7845 <class 'sklearn.linear_model.logistic.LogisticRegression'> (1, 6) char 0.3\n",
      "0.789993586401\n",
      "0.793503083922\n",
      "0.790999082915\n",
      "0.7934955914\n",
      "0.789500578423\n",
      "mean= 0.791498384612\n",
      "178 / 360\n",
      "179 / 360\n",
      "180 / 360\n",
      "0.781 <class 'sklearn.linear_model.logistic.LogisticRegression'> (1, 6) char 0.6\n",
      "0.788006569444\n",
      "0.79449958941\n",
      "0.794003584423\n",
      "0.791005076933\n",
      "0.793503083922\n",
      "mean= 0.792203580826\n",
      "181 / 360\n",
      "0.783 <class 'sklearn.linear_model.logistic.LogisticRegression'> (1, 6) char 0.7\n",
      "0.789499079918\n",
      "0.793005580431\n",
      "0.78750157343\n",
      "0.788495081908\n",
      "0.788493583404\n",
      "mean= 0.789398979818\n",
      "182 / 360\n",
      "0.783 <class 'sklearn.linear_model.logistic.LogisticRegression'> (1, 6) char 0.8\n",
      "0.788998579418\n",
      "0.791997086907\n",
      "0.789491587396\n",
      "0.790996085906\n",
      "0.794507081932\n",
      "mean= 0.791198084312\n",
      "183 / 360\n",
      "0.784 <class 'sklearn.linear_model.logistic.LogisticRegression'> (1, 6) char 0.9\n",
      "0.794495093896\n",
      "0.788499577422\n",
      "0.786500572429\n",
      "0.787503071934\n",
      "0.792003080925\n",
      "mean= 0.789800279321\n",
      "184 / 360\n",
      "185 / 360\n",
      "186 / 360\n",
      "187 / 360\n",
      "188 / 360\n",
      "189 / 360\n",
      "190 / 360\n",
      "191 / 360\n",
      "192 / 360\n",
      "193 / 360\n",
      "194 / 360\n",
      "195 / 360\n",
      "196 / 360\n",
      "197 / 360\n",
      "198 / 360\n",
      "199 / 360\n",
      "200 / 360\n",
      "201 / 360\n",
      "202 / 360\n",
      "0.781 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 7) char 0.4\n",
      "0.790001078923\n",
      "0.792003080925\n",
      "0.790997584411\n",
      "0.790002577428\n",
      "0.793007078935\n",
      "mean= 0.791202280124\n",
      "203 / 360\n",
      "0.7825 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 7) char 0.5\n",
      "0.791499583416\n",
      "0.794496592401\n",
      "0.79049708391\n",
      "0.793001084917\n",
      "0.792996589404\n",
      "mean= 0.79249818681\n",
      "204 / 360\n",
      "0.785 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 7) char 0.6\n",
      "0.789001576427\n",
      "0.791499583416\n",
      "0.789001576427\n",
      "0.789004573436\n",
      "0.791507075938\n",
      "mean= 0.790002877129\n",
      "205 / 360\n",
      "0.781 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 7) char 0.7\n",
      "0.795502088915\n",
      "0.79100058142\n",
      "0.793005580431\n",
      "0.790999082915\n",
      "0.79300857744\n",
      "mean= 0.792703182224\n",
      "206 / 360\n",
      "207 / 360\n",
      "0.782 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 7) char 0.9\n",
      "0.792001582421\n",
      "0.789502076927\n",
      "0.787001072929\n",
      "0.790503077928\n",
      "0.790997584411\n",
      "mean= 0.790001078923\n",
      "208 / 360\n",
      "209 / 360\n",
      "210 / 360\n",
      "211 / 360\n",
      "212 / 360\n",
      "213 / 360\n",
      "214 / 360\n",
      "215 / 360\n",
      "216 / 360\n",
      "217 / 360\n",
      "218 / 360\n",
      "219 / 360\n",
      "220 / 360\n",
      "221 / 360\n",
      "222 / 360\n",
      "223 / 360\n",
      "224 / 360\n",
      "225 / 360\n",
      "0.7835 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 6) char 0.3\n",
      "0.790997584411\n",
      "0.792502082921\n",
      "0.793999088909\n",
      "0.792001582421\n",
      "0.79200457943\n",
      "mean= 0.792300983618\n",
      "226 / 360\n",
      "0.787 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 6) char 0.4\n",
      "0.791002079924\n",
      "0.790506074937\n",
      "0.792499085912\n",
      "0.794002085918\n",
      "0.791498084911\n",
      "mean= 0.791901482321\n",
      "227 / 360\n",
      "0.782 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 6) char 0.5\n",
      "0.793997590405\n",
      "0.792996589404\n",
      "0.789497581414\n",
      "0.792500584417\n",
      "0.78699807592\n",
      "mean= 0.791198084312\n",
      "228 / 360\n",
      "0.785 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 6) char 0.6\n",
      "0.785492078905\n",
      "0.786490082897\n",
      "0.789500578423\n",
      "0.789999580419\n",
      "0.785998573424\n",
      "mean= 0.787496178814\n",
      "229 / 360\n",
      "0.781 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 6) char 0.7\n",
      "0.791005076933\n",
      "0.792502082921\n",
      "0.793999088909\n",
      "0.788997080913\n",
      "0.791495087902\n",
      "mean= 0.791599683516\n",
      "230 / 360\n",
      "0.7845 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 6) char 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796495597394\n",
      "0.791495087902\n",
      "0.788003572435\n",
      "0.786995078911\n",
      "0.791498084911\n",
      "mean= 0.790897484311\n",
      "231 / 360\n",
      "0.787 <class 'sklearn.linear_model.logistic.LogisticRegression'> (2, 6) char 0.9\n",
      "0.795996595398\n",
      "0.790996085906\n",
      "0.792995090899\n",
      "0.781996067924\n",
      "0.790991590393\n",
      "mean= 0.790595086104\n",
      "232 / 360\n",
      "233 / 360\n",
      "234 / 360\n",
      "235 / 360\n",
      "236 / 360\n",
      "237 / 360\n",
      "238 / 360\n",
      "239 / 360\n",
      "240 / 360\n",
      "241 / 360\n",
      "242 / 360\n",
      "243 / 360\n",
      "244 / 360\n",
      "245 / 360\n",
      "246 / 360\n",
      "247 / 360\n",
      "248 / 360\n",
      "249 / 360\n",
      "250 / 360\n",
      "251 / 360\n",
      "252 / 360\n",
      "253 / 360\n",
      "254 / 360\n",
      "255 / 360\n",
      "256 / 360\n",
      "257 / 360\n",
      "258 / 360\n",
      "259 / 360\n",
      "260 / 360\n",
      "261 / 360\n",
      "262 / 360\n",
      "263 / 360\n",
      "264 / 360\n",
      "265 / 360\n",
      "266 / 360\n",
      "267 / 360\n",
      "268 / 360\n",
      "269 / 360\n",
      "270 / 360\n",
      "271 / 360\n",
      "272 / 360\n",
      "273 / 360\n",
      "274 / 360\n",
      "275 / 360\n",
      "276 / 360\n",
      "277 / 360\n",
      "278 / 360\n",
      "279 / 360\n",
      "280 / 360\n",
      "281 / 360\n",
      "282 / 360\n",
      "283 / 360\n",
      "284 / 360\n",
      "285 / 360\n",
      "286 / 360\n",
      "287 / 360\n",
      "288 / 360\n",
      "289 / 360\n",
      "290 / 360\n",
      "291 / 360\n",
      "292 / 360\n",
      "293 / 360\n",
      "294 / 360\n",
      "295 / 360\n",
      "296 / 360\n",
      "297 / 360\n",
      "0.7805 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (1, 6) char 0.3\n",
      "0.789500578423\n",
      "0.79100058142\n",
      "0.792506578435\n",
      "0.791998585412\n",
      "0.78900607194\n",
      "mean= 0.790802479126\n",
      "298 / 360\n",
      "0.781 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (1, 6) char 0.4\n",
      "0.791998585412\n",
      "0.787492582403\n",
      "0.795007582433\n",
      "0.789001576427\n",
      "0.794003584423\n",
      "mean= 0.791500782219\n",
      "299 / 360\n",
      "0.7845 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (1, 6) char 0.5\n",
      "0.794995594397\n",
      "0.796500092907\n",
      "0.78950956945\n",
      "0.788501075926\n",
      "0.787999076921\n",
      "mean= 0.79150108192\n",
      "300 / 360\n",
      "0.7825 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (1, 6) char 0.6\n",
      "0.790500080919\n",
      "0.792998087908\n",
      "0.796005586425\n",
      "0.788502574431\n",
      "0.788994083904\n",
      "mean= 0.791400082717\n",
      "301 / 360\n",
      "0.783 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (1, 6) char 0.7\n",
      "0.789502076927\n",
      "0.787999076921\n",
      "0.788507069944\n",
      "0.789000077922\n",
      "0.789500578423\n",
      "mean= 0.788901776028\n",
      "302 / 360\n",
      "303 / 360\n",
      "0.783 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (1, 6) char 0.9\n",
      "0.790997584411\n",
      "0.790001078923\n",
      "0.789003074931\n",
      "0.790506074937\n",
      "0.789500578423\n",
      "mean= 0.790001678325\n",
      "304 / 360\n",
      "305 / 360\n",
      "306 / 360\n",
      "307 / 360\n",
      "308 / 360\n",
      "309 / 360\n",
      "310 / 360\n",
      "311 / 360\n",
      "312 / 360\n",
      "313 / 360\n",
      "314 / 360\n",
      "315 / 360\n",
      "316 / 360\n",
      "317 / 360\n",
      "318 / 360\n",
      "319 / 360\n",
      "320 / 360\n",
      "321 / 360\n",
      "0.7815 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 7) char 0.3\n",
      "0.791002079924\n",
      "0.797003590417\n",
      "0.792502082921\n",
      "0.790005574437\n",
      "0.79500008991\n",
      "mean= 0.793102683522\n",
      "322 / 360\n",
      "0.784 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 7) char 0.4\n",
      "0.794002085918\n",
      "0.791006575438\n",
      "0.78699807592\n",
      "0.79200457943\n",
      "0.792001582421\n",
      "mean= 0.791202579825\n",
      "323 / 360\n",
      "0.7815 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 7) char 0.5\n",
      "0.791005076933\n",
      "0.788499577422\n",
      "0.786001570433\n",
      "0.79449958941\n",
      "0.794006581432\n",
      "mean= 0.790802479126\n",
      "324 / 360\n",
      "325 / 360\n",
      "0.7845 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 7) char 0.7\n",
      "0.794005082927\n",
      "0.79100058142\n",
      "0.796503089916\n",
      "0.790504576433\n",
      "0.790494086901\n",
      "mean= 0.792501483519\n",
      "326 / 360\n",
      "0.784 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 7) char 0.8\n",
      "0.791504078929\n",
      "0.79449958941\n",
      "0.79200457943\n",
      "0.7979985974\n",
      "0.794005082927\n",
      "mean= 0.794002385619\n",
      "327 / 360\n",
      "328 / 360\n",
      "329 / 360\n",
      "330 / 360\n",
      "331 / 360\n",
      "332 / 360\n",
      "333 / 360\n",
      "334 / 360\n",
      "335 / 360\n",
      "336 / 360\n",
      "337 / 360\n",
      "338 / 360\n",
      "339 / 360\n",
      "340 / 360\n",
      "341 / 360\n",
      "342 / 360\n",
      "343 / 360\n",
      "344 / 360\n",
      "345 / 360\n",
      "0.7845 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 6) char 0.3\n",
      "0.791495087902\n",
      "0.789496082909\n",
      "0.790512068955\n",
      "0.786499073924\n",
      "0.792497587408\n",
      "mean= 0.79009998022\n",
      "346 / 360\n",
      "0.7815 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 6) char 0.4\n",
      "0.792500584417\n",
      "0.791006575438\n",
      "0.792003080925\n",
      "0.787500074925\n",
      "0.787001072929\n",
      "mean= 0.790002277727\n",
      "347 / 360\n",
      "0.788 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 6) char 0.5\n",
      "0.787997578417\n",
      "0.793997590405\n",
      "0.786000071928\n",
      "0.789999580419\n",
      "0.791496586407\n",
      "mean= 0.789898281515\n",
      "348 / 360\n",
      "0.781 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 6) char 0.6\n",
      "0.792995090899\n",
      "0.790999082915\n",
      "0.787999076921\n",
      "0.785499571428\n",
      "0.788499577422\n",
      "mean= 0.789198479917\n",
      "349 / 360\n",
      "0.788 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 6) char 0.7\n",
      "0.785997074919\n",
      "0.790503077928\n",
      "0.790997584411\n",
      "0.791991092889\n",
      "0.79049708391\n",
      "mean= 0.789997182812\n",
      "350 / 360\n",
      "0.783 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 6) char 0.8\n",
      "0.785002067936\n",
      "0.787495579412\n",
      "0.78750157343\n",
      "0.788997080913\n",
      "0.789000077922\n",
      "mean= 0.787599275923\n",
      "351 / 360\n",
      "0.782 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 6) char 0.9\n",
      "0.792001582421\n",
      "0.791499583416\n",
      "0.789995084905\n",
      "0.788997080913\n",
      "0.789499079918\n",
      "mean= 0.790398482315\n",
      "352 / 360\n",
      "353 / 360\n",
      "354 / 360\n",
      "355 / 360\n",
      "356 / 360\n",
      "357 / 360\n",
      "358 / 360\n",
      "359 / 360\n",
      "360 / 360\n"
     ]
    }
   ],
   "source": [
    "# Загружаю train\n",
    "\n",
    "\n",
    "#Подбирать параметры модели буду, ниже списки параметров\n",
    "classifiers=[PassiveAggressiveClassifier, LogisticRegression, SGDClassifier]\n",
    "ngrams2 = [(1,8),(1,9),(2,10)]\n",
    "ngrams = [(1,3),(1,4),(1,6),(2,7),(2,6)]\n",
    "analyzers = ['word','char','char_wb']\n",
    "max_dfs = [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "vectorizers= [TfidfVectorizer]\n",
    "summa = len(classifiers)*len(ngrams)*len(analyzers)*len(max_dfs)*len(vectorizers)\n",
    "count=1\n",
    "print summa\n",
    "best_mean = 0\n",
    "for classifier in classifiers:\n",
    "    for ngram in ngrams:\n",
    "        for an in analyzers:\n",
    "            for mdf in max_dfs:\n",
    "                for v in vectorizers:\n",
    "#Сделаю вывод, чтобы следить за процессом\n",
    "                    print count,'/',summa\n",
    "                    vectorizer = v(ngram_range=ngram,analyzer=an, max_df=mdf)\n",
    "                    X = vectorizer.fit_transform(texts, labels)\n",
    "                    transformer = TfidfTransformer()\n",
    "                    X2 = transformer.fit_transform(X, labels)\n",
    "                    LR = PassiveAggressiveClassifier()\n",
    "                    LR.fit(X2, labels)\n",
    "                    res = cross_val_score(LR, X2, labels, cv=2).mean()\n",
    "#Основную массу параметров буду тестировать кросс-валидацией на 2 фолда, параметров много, так будет быстрее\n",
    "#Удачные параметры проверю более пристально\n",
    "                    if res > 0.78:\n",
    "                        print res, classifier, ngram, an, mdf\n",
    "                        c1=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c1\n",
    "                        c2=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c2\n",
    "                        c3=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c3\n",
    "                        c4=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c4\n",
    "                        c5=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c5\n",
    "                        now_mean= float(c1+c2+c3+c4+c5)/5\n",
    "                        print 'mean=',now_mean\n",
    "#Параметры лучше модели сохраняю\n",
    "                        if now_mean>best_mean:\n",
    "                            best_mean = now_mean\n",
    "                            best_classifier = classifier\n",
    "                            best_ngram=ngram\n",
    "                            best_analyzer=an\n",
    "                            best_max_df=mdf\n",
    "                            best_vectorizer=v\n",
    "                    count = count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 / 1\n",
      "0.7825 <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> (2, 7) char 0.8\n",
      "0.792503581426\n",
      "0.791998585412\n",
      "0.791504078929\n",
      "0.793999088909\n",
      "0.789999580419\n",
      "mean= 0.792000983019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Теперь выполню тотже код, но вместо списков парамертов, возьму параметры лучшей модели\n",
    "classifiers=[best_classifier]\n",
    "ngrams = [best_ngram]\n",
    "analyzers = [best_analyzer]\n",
    "max_dfs = [best_max_df]\n",
    "vectorizers= [best_vectorizer]\n",
    "summa = len(classifiers)*len(ngrams)*len(analyzers)*len(max_dfs)*len(vectorizers)\n",
    "count=1\n",
    "print summa\n",
    "\n",
    "#best_classifier\n",
    "#best_ngram\n",
    "#best_analyzer\n",
    "#best_max_df\n",
    "#best_vectorizer\n",
    "best_mean = 0\n",
    "for classifier in classifiers:\n",
    "    for ngram in ngrams:\n",
    "        for an in analyzers:\n",
    "            for mdf in max_dfs:\n",
    "                for v in vectorizers:\n",
    "                    print count,'/',summa\n",
    "                    vectorizer = v(ngram_range=ngram,analyzer=an, max_df=mdf)\n",
    "                    X = vectorizer.fit_transform(texts, labels)\n",
    "                    transformer = TfidfTransformer()\n",
    "                    X2 = transformer.fit_transform(X, labels)\n",
    "                    LR = PassiveAggressiveClassifier()\n",
    "                    LR.fit(X2, labels)\n",
    "                    res = cross_val_score(LR, X2, labels, cv=2).mean()\n",
    "                    if res > 0.78:\n",
    "                        print res, classifier, ngram, an, mdf\n",
    "                        c1=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c1\n",
    "                        c2=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c2\n",
    "                        c3=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c3\n",
    "                        c4=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c4\n",
    "                        c5=cross_val_score(LR, X2, labels, cv=6).mean()\n",
    "                        print c5\n",
    "                        now_mean= float(c1+c2+c3+c4+c5)/5\n",
    "                        print 'mean=',now_mean\n",
    "                        if now_mean>best_mean:\n",
    "                            best_mean = now_mean\n",
    "                            best_classifier = classifier\n",
    "                            best_ngram=ngram\n",
    "                            best_analyzer=an\n",
    "                            best_max_df=mdf\n",
    "                            best_vectorizer=v\n",
    "                    count = count+1\n",
    "\n",
    "#Загружаю выборку без ответов, делаю предсказания, сохраняю CSV\n",
    "\n",
    "products_sentiment_test = pd.read_csv('products_sentiment_test.tsv', sep='\\t')\n",
    "products_sentiment_test.head()\n",
    "\n",
    "texts_test = list(products_sentiment_test['text'])\n",
    "predict = LR.predict(vectorizer.transform(texts_test))\n",
    "\n",
    "products_sentiment_test['y']= predict\n",
    "products_sentiment_test.head()\n",
    "del products_sentiment_test['text']\n",
    "products_sentiment_test.to_csv('kaggle.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
