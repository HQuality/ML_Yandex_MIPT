{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "negfeats = [movie_reviews.words(fileids=[f]) for f in negids]\n",
    "posfeats = [movie_reviews.words(fileids=[f]) for f in posids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [list(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['plot',\n",
       "  ':',\n",
       "  'two',\n",
       "  'teen',\n",
       "  'couples',\n",
       "  'go',\n",
       "  'to',\n",
       "  'a',\n",
       "  'church',\n",
       "  'party',\n",
       "  ',',\n",
       "  'drink',\n",
       "  'and',\n",
       "  'then',\n",
       "  'drive',\n",
       "  '.',\n",
       "  'they',\n",
       "  'get',\n",
       "  'into',\n",
       "  'an',\n",
       "  'accident',\n",
       "  '.',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'guys',\n",
       "  'dies',\n",
       "  ',',\n",
       "  'but',\n",
       "  'his',\n",
       "  'girlfriend',\n",
       "  'continues',\n",
       "  'to',\n",
       "  'see',\n",
       "  'him',\n",
       "  'in',\n",
       "  'her',\n",
       "  'life',\n",
       "  ',',\n",
       "  'and',\n",
       "  'has',\n",
       "  'nightmares',\n",
       "  '.',\n",
       "  'what',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'the',\n",
       "  'deal',\n",
       "  '?',\n",
       "  'watch',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'and',\n",
       "  '\"',\n",
       "  'sorta',\n",
       "  '\"',\n",
       "  'find',\n",
       "  'out',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'critique',\n",
       "  ':',\n",
       "  'a',\n",
       "  'mind',\n",
       "  '-',\n",
       "  'fuck',\n",
       "  'movie',\n",
       "  'for',\n",
       "  'the',\n",
       "  'teen',\n",
       "  'generation',\n",
       "  'that',\n",
       "  'touches',\n",
       "  'on',\n",
       "  'a',\n",
       "  'very',\n",
       "  'cool',\n",
       "  'idea',\n",
       "  ',',\n",
       "  'but',\n",
       "  'presents',\n",
       "  'it',\n",
       "  'in',\n",
       "  'a',\n",
       "  'very',\n",
       "  'bad',\n",
       "  'package',\n",
       "  '.',\n",
       "  'which',\n",
       "  'is',\n",
       "  'what',\n",
       "  'makes',\n",
       "  'this',\n",
       "  'review',\n",
       "  'an',\n",
       "  'even',\n",
       "  'harder',\n",
       "  'one',\n",
       "  'to',\n",
       "  'write',\n",
       "  ',',\n",
       "  'since',\n",
       "  'i',\n",
       "  'generally',\n",
       "  'applaud',\n",
       "  'films',\n",
       "  'which',\n",
       "  'attempt',\n",
       "  'to',\n",
       "  'break',\n",
       "  'the',\n",
       "  'mold',\n",
       "  ',',\n",
       "  'mess',\n",
       "  'with',\n",
       "  'your',\n",
       "  'head',\n",
       "  'and',\n",
       "  'such',\n",
       "  '(',\n",
       "  'lost',\n",
       "  'highway',\n",
       "  '&',\n",
       "  'memento',\n",
       "  ')',\n",
       "  ',',\n",
       "  'but',\n",
       "  'there',\n",
       "  'are',\n",
       "  'good',\n",
       "  'and',\n",
       "  'bad',\n",
       "  'ways',\n",
       "  'of',\n",
       "  'making',\n",
       "  'all',\n",
       "  'types',\n",
       "  'of',\n",
       "  'films',\n",
       "  ',',\n",
       "  'and',\n",
       "  'these',\n",
       "  'folks',\n",
       "  'just',\n",
       "  'didn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'snag',\n",
       "  'this',\n",
       "  'one',\n",
       "  'correctly',\n",
       "  '.',\n",
       "  'they',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'have',\n",
       "  'taken',\n",
       "  'this',\n",
       "  'pretty',\n",
       "  'neat',\n",
       "  'concept',\n",
       "  ',',\n",
       "  'but',\n",
       "  'executed',\n",
       "  'it',\n",
       "  'terribly',\n",
       "  '.',\n",
       "  'so',\n",
       "  'what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'problems',\n",
       "  'with',\n",
       "  'the',\n",
       "  'movie',\n",
       "  '?',\n",
       "  'well',\n",
       "  ',',\n",
       "  'its',\n",
       "  'main',\n",
       "  'problem',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'simply',\n",
       "  'too',\n",
       "  'jumbled',\n",
       "  '.',\n",
       "  'it',\n",
       "  'starts',\n",
       "  'off',\n",
       "  '\"',\n",
       "  'normal',\n",
       "  '\"',\n",
       "  'but',\n",
       "  'then',\n",
       "  'downshifts',\n",
       "  'into',\n",
       "  'this',\n",
       "  '\"',\n",
       "  'fantasy',\n",
       "  '\"',\n",
       "  'world',\n",
       "  'in',\n",
       "  'which',\n",
       "  'you',\n",
       "  ',',\n",
       "  'as',\n",
       "  'an',\n",
       "  'audience',\n",
       "  'member',\n",
       "  ',',\n",
       "  'have',\n",
       "  'no',\n",
       "  'idea',\n",
       "  'what',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'going',\n",
       "  'on',\n",
       "  '.',\n",
       "  'there',\n",
       "  'are',\n",
       "  'dreams',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'characters',\n",
       "  'coming',\n",
       "  'back',\n",
       "  'from',\n",
       "  'the',\n",
       "  'dead',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'others',\n",
       "  'who',\n",
       "  'look',\n",
       "  'like',\n",
       "  'the',\n",
       "  'dead',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'strange',\n",
       "  'apparitions',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'disappearances',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'looooot',\n",
       "  'of',\n",
       "  'chase',\n",
       "  'scenes',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'tons',\n",
       "  'of',\n",
       "  'weird',\n",
       "  'things',\n",
       "  'that',\n",
       "  'happen',\n",
       "  ',',\n",
       "  'and',\n",
       "  'most',\n",
       "  'of',\n",
       "  'it',\n",
       "  'is',\n",
       "  'simply',\n",
       "  'not',\n",
       "  'explained',\n",
       "  '.',\n",
       "  'now',\n",
       "  'i',\n",
       "  'personally',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'mind',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'unravel',\n",
       "  'a',\n",
       "  'film',\n",
       "  'every',\n",
       "  'now',\n",
       "  'and',\n",
       "  'then',\n",
       "  ',',\n",
       "  'but',\n",
       "  'when',\n",
       "  'all',\n",
       "  'it',\n",
       "  'does',\n",
       "  'is',\n",
       "  'give',\n",
       "  'me',\n",
       "  'the',\n",
       "  'same',\n",
       "  'clue',\n",
       "  'over',\n",
       "  'and',\n",
       "  'over',\n",
       "  'again',\n",
       "  ',',\n",
       "  'i',\n",
       "  'get',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'fed',\n",
       "  'up',\n",
       "  'after',\n",
       "  'a',\n",
       "  'while',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'this',\n",
       "  'film',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'biggest',\n",
       "  'problem',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'obviously',\n",
       "  'got',\n",
       "  'this',\n",
       "  'big',\n",
       "  'secret',\n",
       "  'to',\n",
       "  'hide',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'want',\n",
       "  'to',\n",
       "  'hide',\n",
       "  'it',\n",
       "  'completely',\n",
       "  'until',\n",
       "  'its',\n",
       "  'final',\n",
       "  'five',\n",
       "  'minutes',\n",
       "  '.',\n",
       "  'and',\n",
       "  'do',\n",
       "  'they',\n",
       "  'make',\n",
       "  'things',\n",
       "  'entertaining',\n",
       "  ',',\n",
       "  'thrilling',\n",
       "  'or',\n",
       "  'even',\n",
       "  'engaging',\n",
       "  ',',\n",
       "  'in',\n",
       "  'the',\n",
       "  'meantime',\n",
       "  '?',\n",
       "  'not',\n",
       "  'really',\n",
       "  '.',\n",
       "  'the',\n",
       "  'sad',\n",
       "  'part',\n",
       "  'is',\n",
       "  'that',\n",
       "  'the',\n",
       "  'arrow',\n",
       "  'and',\n",
       "  'i',\n",
       "  'both',\n",
       "  'dig',\n",
       "  'on',\n",
       "  'flicks',\n",
       "  'like',\n",
       "  'this',\n",
       "  ',',\n",
       "  'so',\n",
       "  'we',\n",
       "  'actually',\n",
       "  'figured',\n",
       "  'most',\n",
       "  'of',\n",
       "  'it',\n",
       "  'out',\n",
       "  'by',\n",
       "  'the',\n",
       "  'half',\n",
       "  '-',\n",
       "  'way',\n",
       "  'point',\n",
       "  ',',\n",
       "  'so',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'strangeness',\n",
       "  'after',\n",
       "  'that',\n",
       "  'did',\n",
       "  'start',\n",
       "  'to',\n",
       "  'make',\n",
       "  'a',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'of',\n",
       "  'sense',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  'still',\n",
       "  'didn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'the',\n",
       "  'make',\n",
       "  'the',\n",
       "  'film',\n",
       "  'all',\n",
       "  'that',\n",
       "  'more',\n",
       "  'entertaining',\n",
       "  '.',\n",
       "  'i',\n",
       "  'guess',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  'line',\n",
       "  'with',\n",
       "  'movies',\n",
       "  'like',\n",
       "  'this',\n",
       "  'is',\n",
       "  'that',\n",
       "  'you',\n",
       "  'should',\n",
       "  'always',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'that',\n",
       "  'the',\n",
       "  'audience',\n",
       "  'is',\n",
       "  '\"',\n",
       "  'into',\n",
       "  'it',\n",
       "  '\"',\n",
       "  'even',\n",
       "  'before',\n",
       "  'they',\n",
       "  'are',\n",
       "  'given',\n",
       "  'the',\n",
       "  'secret',\n",
       "  'password',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'your',\n",
       "  'world',\n",
       "  'of',\n",
       "  'understanding',\n",
       "  '.',\n",
       "  'i',\n",
       "  'mean',\n",
       "  ',',\n",
       "  'showing',\n",
       "  'melissa',\n",
       "  'sagemiller',\n",
       "  'running',\n",
       "  'away',\n",
       "  'from',\n",
       "  'visions',\n",
       "  'for',\n",
       "  'about',\n",
       "  '20',\n",
       "  'minutes',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'is',\n",
       "  'just',\n",
       "  'plain',\n",
       "  'lazy',\n",
       "  '!',\n",
       "  '!',\n",
       "  'okay',\n",
       "  ',',\n",
       "  'we',\n",
       "  'get',\n",
       "  'it',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'there',\n",
       "  'are',\n",
       "  'people',\n",
       "  'chasing',\n",
       "  'her',\n",
       "  'and',\n",
       "  'we',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'who',\n",
       "  'they',\n",
       "  'are',\n",
       "  '.',\n",
       "  'do',\n",
       "  'we',\n",
       "  'really',\n",
       "  'need',\n",
       "  'to',\n",
       "  'see',\n",
       "  'it',\n",
       "  'over',\n",
       "  'and',\n",
       "  'over',\n",
       "  'again',\n",
       "  '?',\n",
       "  'how',\n",
       "  'about',\n",
       "  'giving',\n",
       "  'us',\n",
       "  'different',\n",
       "  'scenes',\n",
       "  'offering',\n",
       "  'further',\n",
       "  'insight',\n",
       "  'into',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'strangeness',\n",
       "  'going',\n",
       "  'down',\n",
       "  'in',\n",
       "  'the',\n",
       "  'movie',\n",
       "  '?',\n",
       "  'apparently',\n",
       "  ',',\n",
       "  'the',\n",
       "  'studio',\n",
       "  'took',\n",
       "  'this',\n",
       "  'film',\n",
       "  'away',\n",
       "  'from',\n",
       "  'its',\n",
       "  'director',\n",
       "  'and',\n",
       "  'chopped',\n",
       "  'it',\n",
       "  'up',\n",
       "  'themselves',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  'shows',\n",
       "  '.',\n",
       "  'there',\n",
       "  'might',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'been',\n",
       "  'a',\n",
       "  'pretty',\n",
       "  'decent',\n",
       "  'teen',\n",
       "  'mind',\n",
       "  '-',\n",
       "  'fuck',\n",
       "  'movie',\n",
       "  'in',\n",
       "  'here',\n",
       "  'somewhere',\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  'guess',\n",
       "  '\"',\n",
       "  'the',\n",
       "  'suits',\n",
       "  '\"',\n",
       "  'decided',\n",
       "  'that',\n",
       "  'turning',\n",
       "  'it',\n",
       "  'into',\n",
       "  'a',\n",
       "  'music',\n",
       "  'video',\n",
       "  'with',\n",
       "  'little',\n",
       "  'edge',\n",
       "  ',',\n",
       "  'would',\n",
       "  'make',\n",
       "  'more',\n",
       "  'sense',\n",
       "  '.',\n",
       "  'the',\n",
       "  'actors',\n",
       "  'are',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'for',\n",
       "  'the',\n",
       "  'most',\n",
       "  'part',\n",
       "  ',',\n",
       "  'although',\n",
       "  'wes',\n",
       "  'bentley',\n",
       "  'just',\n",
       "  'seemed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'playing',\n",
       "  'the',\n",
       "  'exact',\n",
       "  'same',\n",
       "  'character',\n",
       "  'that',\n",
       "  'he',\n",
       "  'did',\n",
       "  'in',\n",
       "  'american',\n",
       "  'beauty',\n",
       "  ',',\n",
       "  'only',\n",
       "  'in',\n",
       "  'a',\n",
       "  'new',\n",
       "  'neighborhood',\n",
       "  '.',\n",
       "  'but',\n",
       "  'my',\n",
       "  'biggest',\n",
       "  'kudos',\n",
       "  'go',\n",
       "  'out',\n",
       "  'to',\n",
       "  'sagemiller',\n",
       "  ',',\n",
       "  'who',\n",
       "  'holds',\n",
       "  'her',\n",
       "  'own',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'entire',\n",
       "  'film',\n",
       "  ',',\n",
       "  'and',\n",
       "  'actually',\n",
       "  'has',\n",
       "  'you',\n",
       "  'feeling',\n",
       "  'her',\n",
       "  'character',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'unraveling',\n",
       "  '.',\n",
       "  'overall',\n",
       "  ',',\n",
       "  'the',\n",
       "  'film',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'stick',\n",
       "  'because',\n",
       "  'it',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'entertain',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'confusing',\n",
       "  ',',\n",
       "  'it',\n",
       "  'rarely',\n",
       "  'excites',\n",
       "  'and',\n",
       "  'it',\n",
       "  'feels',\n",
       "  'pretty',\n",
       "  'redundant',\n",
       "  'for',\n",
       "  'most',\n",
       "  'of',\n",
       "  'its',\n",
       "  'runtime',\n",
       "  ',',\n",
       "  'despite',\n",
       "  'a',\n",
       "  'pretty',\n",
       "  'cool',\n",
       "  'ending',\n",
       "  'and',\n",
       "  'explanation',\n",
       "  'to',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'craziness',\n",
       "  'that',\n",
       "  'came',\n",
       "  'before',\n",
       "  'it',\n",
       "  '.',\n",
       "  'oh',\n",
       "  ',',\n",
       "  'and',\n",
       "  'by',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'this',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'horror',\n",
       "  'or',\n",
       "  'teen',\n",
       "  'slasher',\n",
       "  'flick',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'just',\n",
       "  'packaged',\n",
       "  'to',\n",
       "  'look',\n",
       "  'that',\n",
       "  'way',\n",
       "  'because',\n",
       "  'someone',\n",
       "  'is',\n",
       "  'apparently',\n",
       "  'assuming',\n",
       "  'that',\n",
       "  'the',\n",
       "  'genre',\n",
       "  'is',\n",
       "  'still',\n",
       "  'hot',\n",
       "  'with',\n",
       "  'the',\n",
       "  'kids',\n",
       "  '.',\n",
       "  'it',\n",
       "  'also',\n",
       "  'wrapped',\n",
       "  'production',\n",
       "  'two',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'and',\n",
       "  'has',\n",
       "  'been',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'the',\n",
       "  'shelves',\n",
       "  'ever',\n",
       "  'since',\n",
       "  '.',\n",
       "  'whatever',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'skip',\n",
       "  'it',\n",
       "  '!',\n",
       "  'where',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'joblo',\n",
       "  'coming',\n",
       "  'from',\n",
       "  '?',\n",
       "  'a',\n",
       "  'nightmare',\n",
       "  'of',\n",
       "  'elm',\n",
       "  'street',\n",
       "  '3',\n",
       "  '(',\n",
       "  '7',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'blair',\n",
       "  'witch',\n",
       "  '2',\n",
       "  '(',\n",
       "  '7',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'the',\n",
       "  'crow',\n",
       "  '(',\n",
       "  '9',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'the',\n",
       "  'crow',\n",
       "  ':',\n",
       "  'salvation',\n",
       "  '(',\n",
       "  '4',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'lost',\n",
       "  'highway',\n",
       "  '(',\n",
       "  '10',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'memento',\n",
       "  '(',\n",
       "  '10',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'the',\n",
       "  'others',\n",
       "  '(',\n",
       "  '9',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'stir',\n",
       "  'of',\n",
       "  'echoes',\n",
       "  '(',\n",
       "  '8',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')']]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['plot',\n",
       "   ':',\n",
       "   'two',\n",
       "   'teen',\n",
       "   'couples',\n",
       "   'go',\n",
       "   'to',\n",
       "   'a',\n",
       "   'church',\n",
       "   'party',\n",
       "   ',',\n",
       "   'drink',\n",
       "   'and',\n",
       "   'then',\n",
       "   'drive',\n",
       "   '.',\n",
       "   'they',\n",
       "   'get',\n",
       "   'into',\n",
       "   'an',\n",
       "   'accident',\n",
       "   '.',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'guys',\n",
       "   'dies',\n",
       "   ',',\n",
       "   'but',\n",
       "   'his',\n",
       "   'girlfriend',\n",
       "   'continues',\n",
       "   'to',\n",
       "   'see',\n",
       "   'him',\n",
       "   'in',\n",
       "   'her',\n",
       "   'life',\n",
       "   ',',\n",
       "   'and',\n",
       "   'has',\n",
       "   'nightmares',\n",
       "   '.',\n",
       "   'what',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'the',\n",
       "   'deal',\n",
       "   '?',\n",
       "   'watch',\n",
       "   'the',\n",
       "   'movie',\n",
       "   'and',\n",
       "   '\"',\n",
       "   'sorta',\n",
       "   '\"',\n",
       "   'find',\n",
       "   'out',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   'critique',\n",
       "   ':',\n",
       "   'a',\n",
       "   'mind',\n",
       "   '-',\n",
       "   'fuck',\n",
       "   'movie',\n",
       "   'for',\n",
       "   'the',\n",
       "   'teen',\n",
       "   'generation',\n",
       "   'that',\n",
       "   'touches',\n",
       "   'on',\n",
       "   'a',\n",
       "   'very',\n",
       "   'cool',\n",
       "   'idea',\n",
       "   ',',\n",
       "   'but',\n",
       "   'presents',\n",
       "   'it',\n",
       "   'in',\n",
       "   'a',\n",
       "   'very',\n",
       "   'bad',\n",
       "   'package',\n",
       "   '.',\n",
       "   'which',\n",
       "   'is',\n",
       "   'what',\n",
       "   'makes',\n",
       "   'this',\n",
       "   'review',\n",
       "   'an',\n",
       "   'even',\n",
       "   'harder',\n",
       "   'one',\n",
       "   'to',\n",
       "   'write',\n",
       "   ',',\n",
       "   'since',\n",
       "   'i',\n",
       "   'generally',\n",
       "   'applaud',\n",
       "   'films',\n",
       "   'which',\n",
       "   'attempt',\n",
       "   'to',\n",
       "   'break',\n",
       "   'the',\n",
       "   'mold',\n",
       "   ',',\n",
       "   'mess',\n",
       "   'with',\n",
       "   'your',\n",
       "   'head',\n",
       "   'and',\n",
       "   'such',\n",
       "   '(',\n",
       "   'lost',\n",
       "   'highway',\n",
       "   '&',\n",
       "   'memento',\n",
       "   ')',\n",
       "   ',',\n",
       "   'but',\n",
       "   'there',\n",
       "   'are',\n",
       "   'good',\n",
       "   'and',\n",
       "   'bad',\n",
       "   'ways',\n",
       "   'of',\n",
       "   'making',\n",
       "   'all',\n",
       "   'types',\n",
       "   'of',\n",
       "   'films',\n",
       "   ',',\n",
       "   'and',\n",
       "   'these',\n",
       "   'folks',\n",
       "   'just',\n",
       "   'didn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'snag',\n",
       "   'this',\n",
       "   'one',\n",
       "   'correctly',\n",
       "   '.',\n",
       "   'they',\n",
       "   'seem',\n",
       "   'to',\n",
       "   'have',\n",
       "   'taken',\n",
       "   'this',\n",
       "   'pretty',\n",
       "   'neat',\n",
       "   'concept',\n",
       "   ',',\n",
       "   'but',\n",
       "   'executed',\n",
       "   'it',\n",
       "   'terribly',\n",
       "   '.',\n",
       "   'so',\n",
       "   'what',\n",
       "   'are',\n",
       "   'the',\n",
       "   'problems',\n",
       "   'with',\n",
       "   'the',\n",
       "   'movie',\n",
       "   '?',\n",
       "   'well',\n",
       "   ',',\n",
       "   'its',\n",
       "   'main',\n",
       "   'problem',\n",
       "   'is',\n",
       "   'that',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'simply',\n",
       "   'too',\n",
       "   'jumbled',\n",
       "   '.',\n",
       "   'it',\n",
       "   'starts',\n",
       "   'off',\n",
       "   '\"',\n",
       "   'normal',\n",
       "   '\"',\n",
       "   'but',\n",
       "   'then',\n",
       "   'downshifts',\n",
       "   'into',\n",
       "   'this',\n",
       "   '\"',\n",
       "   'fantasy',\n",
       "   '\"',\n",
       "   'world',\n",
       "   'in',\n",
       "   'which',\n",
       "   'you',\n",
       "   ',',\n",
       "   'as',\n",
       "   'an',\n",
       "   'audience',\n",
       "   'member',\n",
       "   ',',\n",
       "   'have',\n",
       "   'no',\n",
       "   'idea',\n",
       "   'what',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'going',\n",
       "   'on',\n",
       "   '.',\n",
       "   'there',\n",
       "   'are',\n",
       "   'dreams',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'characters',\n",
       "   'coming',\n",
       "   'back',\n",
       "   'from',\n",
       "   'the',\n",
       "   'dead',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'others',\n",
       "   'who',\n",
       "   'look',\n",
       "   'like',\n",
       "   'the',\n",
       "   'dead',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'strange',\n",
       "   'apparitions',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'disappearances',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'a',\n",
       "   'looooot',\n",
       "   'of',\n",
       "   'chase',\n",
       "   'scenes',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'tons',\n",
       "   'of',\n",
       "   'weird',\n",
       "   'things',\n",
       "   'that',\n",
       "   'happen',\n",
       "   ',',\n",
       "   'and',\n",
       "   'most',\n",
       "   'of',\n",
       "   'it',\n",
       "   'is',\n",
       "   'simply',\n",
       "   'not',\n",
       "   'explained',\n",
       "   '.',\n",
       "   'now',\n",
       "   'i',\n",
       "   'personally',\n",
       "   'don',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'mind',\n",
       "   'trying',\n",
       "   'to',\n",
       "   'unravel',\n",
       "   'a',\n",
       "   'film',\n",
       "   'every',\n",
       "   'now',\n",
       "   'and',\n",
       "   'then',\n",
       "   ',',\n",
       "   'but',\n",
       "   'when',\n",
       "   'all',\n",
       "   'it',\n",
       "   'does',\n",
       "   'is',\n",
       "   'give',\n",
       "   'me',\n",
       "   'the',\n",
       "   'same',\n",
       "   'clue',\n",
       "   'over',\n",
       "   'and',\n",
       "   'over',\n",
       "   'again',\n",
       "   ',',\n",
       "   'i',\n",
       "   'get',\n",
       "   'kind',\n",
       "   'of',\n",
       "   'fed',\n",
       "   'up',\n",
       "   'after',\n",
       "   'a',\n",
       "   'while',\n",
       "   ',',\n",
       "   'which',\n",
       "   'is',\n",
       "   'this',\n",
       "   'film',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'biggest',\n",
       "   'problem',\n",
       "   '.',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'obviously',\n",
       "   'got',\n",
       "   'this',\n",
       "   'big',\n",
       "   'secret',\n",
       "   'to',\n",
       "   'hide',\n",
       "   ',',\n",
       "   'but',\n",
       "   'it',\n",
       "   'seems',\n",
       "   'to',\n",
       "   'want',\n",
       "   'to',\n",
       "   'hide',\n",
       "   'it',\n",
       "   'completely',\n",
       "   'until',\n",
       "   'its',\n",
       "   'final',\n",
       "   'five',\n",
       "   'minutes',\n",
       "   '.',\n",
       "   'and',\n",
       "   'do',\n",
       "   'they',\n",
       "   'make',\n",
       "   'things',\n",
       "   'entertaining',\n",
       "   ',',\n",
       "   'thrilling',\n",
       "   'or',\n",
       "   'even',\n",
       "   'engaging',\n",
       "   ',',\n",
       "   'in',\n",
       "   'the',\n",
       "   'meantime',\n",
       "   '?',\n",
       "   'not',\n",
       "   'really',\n",
       "   '.',\n",
       "   'the',\n",
       "   'sad',\n",
       "   'part',\n",
       "   'is',\n",
       "   'that',\n",
       "   'the',\n",
       "   'arrow',\n",
       "   'and',\n",
       "   'i',\n",
       "   'both',\n",
       "   'dig',\n",
       "   'on',\n",
       "   'flicks',\n",
       "   'like',\n",
       "   'this',\n",
       "   ',',\n",
       "   'so',\n",
       "   'we',\n",
       "   'actually',\n",
       "   'figured',\n",
       "   'most',\n",
       "   'of',\n",
       "   'it',\n",
       "   'out',\n",
       "   'by',\n",
       "   'the',\n",
       "   'half',\n",
       "   '-',\n",
       "   'way',\n",
       "   'point',\n",
       "   ',',\n",
       "   'so',\n",
       "   'all',\n",
       "   'of',\n",
       "   'the',\n",
       "   'strangeness',\n",
       "   'after',\n",
       "   'that',\n",
       "   'did',\n",
       "   'start',\n",
       "   'to',\n",
       "   'make',\n",
       "   'a',\n",
       "   'little',\n",
       "   'bit',\n",
       "   'of',\n",
       "   'sense',\n",
       "   ',',\n",
       "   'but',\n",
       "   'it',\n",
       "   'still',\n",
       "   'didn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'the',\n",
       "   'make',\n",
       "   'the',\n",
       "   'film',\n",
       "   'all',\n",
       "   'that',\n",
       "   'more',\n",
       "   'entertaining',\n",
       "   '.',\n",
       "   'i',\n",
       "   'guess',\n",
       "   'the',\n",
       "   'bottom',\n",
       "   'line',\n",
       "   'with',\n",
       "   'movies',\n",
       "   'like',\n",
       "   'this',\n",
       "   'is',\n",
       "   'that',\n",
       "   'you',\n",
       "   'should',\n",
       "   'always',\n",
       "   'make',\n",
       "   'sure',\n",
       "   'that',\n",
       "   'the',\n",
       "   'audience',\n",
       "   'is',\n",
       "   '\"',\n",
       "   'into',\n",
       "   'it',\n",
       "   '\"',\n",
       "   'even',\n",
       "   'before',\n",
       "   'they',\n",
       "   'are',\n",
       "   'given',\n",
       "   'the',\n",
       "   'secret',\n",
       "   'password',\n",
       "   'to',\n",
       "   'enter',\n",
       "   'your',\n",
       "   'world',\n",
       "   'of',\n",
       "   'understanding',\n",
       "   '.',\n",
       "   'i',\n",
       "   'mean',\n",
       "   ',',\n",
       "   'showing',\n",
       "   'melissa',\n",
       "   'sagemiller',\n",
       "   'running',\n",
       "   'away',\n",
       "   'from',\n",
       "   'visions',\n",
       "   'for',\n",
       "   'about',\n",
       "   '20',\n",
       "   'minutes',\n",
       "   'throughout',\n",
       "   'the',\n",
       "   'movie',\n",
       "   'is',\n",
       "   'just',\n",
       "   'plain',\n",
       "   'lazy',\n",
       "   '!',\n",
       "   '!',\n",
       "   'okay',\n",
       "   ',',\n",
       "   'we',\n",
       "   'get',\n",
       "   'it',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   'there',\n",
       "   'are',\n",
       "   'people',\n",
       "   'chasing',\n",
       "   'her',\n",
       "   'and',\n",
       "   'we',\n",
       "   'don',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'know',\n",
       "   'who',\n",
       "   'they',\n",
       "   'are',\n",
       "   '.',\n",
       "   'do',\n",
       "   'we',\n",
       "   'really',\n",
       "   'need',\n",
       "   'to',\n",
       "   'see',\n",
       "   'it',\n",
       "   'over',\n",
       "   'and',\n",
       "   'over',\n",
       "   'again',\n",
       "   '?',\n",
       "   'how',\n",
       "   'about',\n",
       "   'giving',\n",
       "   'us',\n",
       "   'different',\n",
       "   'scenes',\n",
       "   'offering',\n",
       "   'further',\n",
       "   'insight',\n",
       "   'into',\n",
       "   'all',\n",
       "   'of',\n",
       "   'the',\n",
       "   'strangeness',\n",
       "   'going',\n",
       "   'down',\n",
       "   'in',\n",
       "   'the',\n",
       "   'movie',\n",
       "   '?',\n",
       "   'apparently',\n",
       "   ',',\n",
       "   'the',\n",
       "   'studio',\n",
       "   'took',\n",
       "   'this',\n",
       "   'film',\n",
       "   'away',\n",
       "   'from',\n",
       "   'its',\n",
       "   'director',\n",
       "   'and',\n",
       "   'chopped',\n",
       "   'it',\n",
       "   'up',\n",
       "   'themselves',\n",
       "   ',',\n",
       "   'and',\n",
       "   'it',\n",
       "   'shows',\n",
       "   '.',\n",
       "   'there',\n",
       "   'might',\n",
       "   \"'\",\n",
       "   've',\n",
       "   'been',\n",
       "   'a',\n",
       "   'pretty',\n",
       "   'decent',\n",
       "   'teen',\n",
       "   'mind',\n",
       "   '-',\n",
       "   'fuck',\n",
       "   'movie',\n",
       "   'in',\n",
       "   'here',\n",
       "   'somewhere',\n",
       "   ',',\n",
       "   'but',\n",
       "   'i',\n",
       "   'guess',\n",
       "   '\"',\n",
       "   'the',\n",
       "   'suits',\n",
       "   '\"',\n",
       "   'decided',\n",
       "   'that',\n",
       "   'turning',\n",
       "   'it',\n",
       "   'into',\n",
       "   'a',\n",
       "   'music',\n",
       "   'video',\n",
       "   'with',\n",
       "   'little',\n",
       "   'edge',\n",
       "   ',',\n",
       "   'would',\n",
       "   'make',\n",
       "   'more',\n",
       "   'sense',\n",
       "   '.',\n",
       "   'the',\n",
       "   'actors',\n",
       "   'are',\n",
       "   'pretty',\n",
       "   'good',\n",
       "   'for',\n",
       "   'the',\n",
       "   'most',\n",
       "   'part',\n",
       "   ',',\n",
       "   'although',\n",
       "   'wes',\n",
       "   'bentley',\n",
       "   'just',\n",
       "   'seemed',\n",
       "   'to',\n",
       "   'be',\n",
       "   'playing',\n",
       "   'the',\n",
       "   'exact',\n",
       "   'same',\n",
       "   'character',\n",
       "   'that',\n",
       "   'he',\n",
       "   'did',\n",
       "   'in',\n",
       "   'american',\n",
       "   'beauty',\n",
       "   ',',\n",
       "   'only',\n",
       "   'in',\n",
       "   'a',\n",
       "   'new',\n",
       "   'neighborhood',\n",
       "   '.',\n",
       "   'but',\n",
       "   'my',\n",
       "   'biggest',\n",
       "   'kudos',\n",
       "   'go',\n",
       "   'out',\n",
       "   'to',\n",
       "   'sagemiller',\n",
       "   ',',\n",
       "   'who',\n",
       "   'holds',\n",
       "   'her',\n",
       "   'own',\n",
       "   'throughout',\n",
       "   'the',\n",
       "   'entire',\n",
       "   'film',\n",
       "   ',',\n",
       "   'and',\n",
       "   'actually',\n",
       "   'has',\n",
       "   'you',\n",
       "   'feeling',\n",
       "   'her',\n",
       "   'character',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'unraveling',\n",
       "   '.',\n",
       "   'overall',\n",
       "   ',',\n",
       "   'the',\n",
       "   'film',\n",
       "   'doesn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'stick',\n",
       "   'because',\n",
       "   'it',\n",
       "   'doesn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'entertain',\n",
       "   ',',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'confusing',\n",
       "   ',',\n",
       "   'it',\n",
       "   'rarely',\n",
       "   'excites',\n",
       "   'and',\n",
       "   'it',\n",
       "   'feels',\n",
       "   'pretty',\n",
       "   'redundant',\n",
       "   'for',\n",
       "   'most',\n",
       "   'of',\n",
       "   'its',\n",
       "   'runtime',\n",
       "   ',',\n",
       "   'despite',\n",
       "   'a',\n",
       "   'pretty',\n",
       "   'cool',\n",
       "   'ending',\n",
       "   'and',\n",
       "   'explanation',\n",
       "   'to',\n",
       "   'all',\n",
       "   'of',\n",
       "   'the',\n",
       "   'craziness',\n",
       "   'that',\n",
       "   'came',\n",
       "   'before',\n",
       "   'it',\n",
       "   '.',\n",
       "   'oh',\n",
       "   ',',\n",
       "   'and',\n",
       "   'by',\n",
       "   'the',\n",
       "   'way',\n",
       "   ',',\n",
       "   'this',\n",
       "   'is',\n",
       "   'not',\n",
       "   'a',\n",
       "   'horror',\n",
       "   'or',\n",
       "   'teen',\n",
       "   'slasher',\n",
       "   'flick',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'just',\n",
       "   'packaged',\n",
       "   'to',\n",
       "   'look',\n",
       "   'that',\n",
       "   'way',\n",
       "   'because',\n",
       "   'someone',\n",
       "   'is',\n",
       "   'apparently',\n",
       "   'assuming',\n",
       "   'that',\n",
       "   'the',\n",
       "   'genre',\n",
       "   'is',\n",
       "   'still',\n",
       "   'hot',\n",
       "   'with',\n",
       "   'the',\n",
       "   'kids',\n",
       "   '.',\n",
       "   'it',\n",
       "   'also',\n",
       "   'wrapped',\n",
       "   'production',\n",
       "   'two',\n",
       "   'years',\n",
       "   'ago',\n",
       "   'and',\n",
       "   'has',\n",
       "   'been',\n",
       "   'sitting',\n",
       "   'on',\n",
       "   'the',\n",
       "   'shelves',\n",
       "   'ever',\n",
       "   'since',\n",
       "   '.',\n",
       "   'whatever',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   'skip',\n",
       "   'it',\n",
       "   '!',\n",
       "   'where',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'joblo',\n",
       "   'coming',\n",
       "   'from',\n",
       "   '?',\n",
       "   'a',\n",
       "   'nightmare',\n",
       "   'of',\n",
       "   'elm',\n",
       "   'street',\n",
       "   '3',\n",
       "   '(',\n",
       "   '7',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'blair',\n",
       "   'witch',\n",
       "   '2',\n",
       "   '(',\n",
       "   '7',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'the',\n",
       "   'crow',\n",
       "   '(',\n",
       "   '9',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'the',\n",
       "   'crow',\n",
       "   ':',\n",
       "   'salvation',\n",
       "   '(',\n",
       "   '4',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'lost',\n",
       "   'highway',\n",
       "   '(',\n",
       "   '10',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'memento',\n",
       "   '(',\n",
       "   '10',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'the',\n",
       "   'others',\n",
       "   '(',\n",
       "   '9',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'stir',\n",
       "   'of',\n",
       "   'echoes',\n",
       "   '(',\n",
       "   '8',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')'],\n",
       "  'neg')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer1.txt', 'w') as f:\n",
    "    f.write(str(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(documents, exclude=['docs'], columns = ['docs' , 'cat']) \n",
    "df.cat = df.cat.map({'neg':0, 'pos':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion: 0.5 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df.cat.value_counts()\n",
    "p = np.round(counts[1] / sum(counts), 2)\n",
    "print('Proportion:', p , ': 1')\n",
    "\n",
    "counts.plot(kind='bar', title='Neg/Pos');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('answer2.txt', 'w') as f:\n",
    "    f.write(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\" \".join(x) for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer=lambda doc: doc, lowercase=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x39659 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 666842 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer3.txt', 'w') as f:\n",
    "    f.write(str(bow.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81437126, 0.84684685, 0.84684685])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LR, bow, df.cat, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360216503929078"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_acc = np.mean(cross_val_score(LR, bow, df.cat, scoring = 'accuracy'))\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer4.txt', 'w') as f:\n",
    "    f.write(str(mean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9107764937833774"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_roc_auc = np.mean(cross_val_score(LR, bow, df.cat, scoring = 'roc_auc'))\n",
    "mean_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer5.txt', 'w') as f:\n",
    "    f.write(str(mean_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-f5f03927ecde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 231\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1058\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                                tokenize)\n\u001b[1;32m    351\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 352\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "mp = make_pipeline(vectorizer, LR)\n",
    "mp.fit(docs, df.cat)\n",
    "fp = mp.predict(docs)\n",
    "cross_val_score(mp, df.cat,scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unfortunately'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[37056]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(bow, df.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.13519839e-02 -1.78935973e-02  2.51622303e-06 ... -7.15497974e-03\n",
      "   3.79020749e-04 -1.40853359e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(LR.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = np.argsort(np.abs(LR.coef_[0]))[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38417, 14159, 39195, 37056,  2954])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = np.array(vectorizer.get_feature_names())[top_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = \" \".join(top5[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unfortunately bad'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer6.txt', 'w') as f:\n",
    "        f.write(top2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_CV_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])\n",
    "pipe_TFIDF_LR = Pipeline([\n",
    "       ('TFIDF', TfidfVectorizer()),\n",
    "       ('LR', linear_model.LogisticRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substract_means(pipeline, X, y):\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, n_jobs=-1)\n",
    "    mean = scores.mean()\n",
    "    std = scores.std()\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('LR',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_CV_LR.fit(docs, df.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_CV_LR = cross_val_score(pipe_CV_LR, docs, df.cat, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = scores_CV_LR.mean()\n",
    "std1 = scores_CV_LR.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_TFIDF_LR = cross_val_score(pipe_TFIDF_LR, docs, df.cat, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean2 = scores_TFIDF_LR.mean()\n",
    "std2 = scores_TFIDF_LR.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer2_1.txt', 'w') as f:\n",
    "    f.write('{:f} {:f} {:0f} {:f}'.format(mean1, std1, mean2, std2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'vectorizer__min_df': 10}, 0.839)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'vectorizer__min_df':[10, 20, 30, 40, 50]}]\n",
    "\n",
    "GS = GridSearchCV(pipe_CV_LR, param_grid = param_grid, cv=5)\n",
    "GS.fit(docs, df.cat)\n",
    "GS.best_params_, GS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_cv = cross_val_score(GS, docs, df.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81287425, 0.83333333, 0.84534535])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_CV10_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(min_df = 10)),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "         ])\n",
    "pipe_CV50_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(min_df = 50)),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_10 = cross_val_score(pipe_CV10_LR, docs, df.cat, cv=5, n_jobs=-1)\n",
    "cv_50 = cross_val_score(pipe_CV50_LR, docs, df.cat, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.82  , 0.85  , 0.8325, 0.8525, 0.84  ]),\n",
       " array([0.7925, 0.825 , 0.8025, 0.8175, 0.8275]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_10, cv_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer2_2.txt', 'w') as f:\n",
    "    f.write('{} {}'.format(cv_10.mean(), cv_50.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
