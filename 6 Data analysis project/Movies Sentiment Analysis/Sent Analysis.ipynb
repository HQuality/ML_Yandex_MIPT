{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "negfeats = [movie_reviews.words(fileids=[f]) for f in negids]\n",
    "posfeats = [movie_reviews.words(fileids=[f]) for f in posids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [list(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['plot',\n",
       "  ':',\n",
       "  'two',\n",
       "  'teen',\n",
       "  'couples',\n",
       "  'go',\n",
       "  'to',\n",
       "  'a',\n",
       "  'church',\n",
       "  'party',\n",
       "  ',',\n",
       "  'drink',\n",
       "  'and',\n",
       "  'then',\n",
       "  'drive',\n",
       "  '.',\n",
       "  'they',\n",
       "  'get',\n",
       "  'into',\n",
       "  'an',\n",
       "  'accident',\n",
       "  '.',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'guys',\n",
       "  'dies',\n",
       "  ',',\n",
       "  'but',\n",
       "  'his',\n",
       "  'girlfriend',\n",
       "  'continues',\n",
       "  'to',\n",
       "  'see',\n",
       "  'him',\n",
       "  'in',\n",
       "  'her',\n",
       "  'life',\n",
       "  ',',\n",
       "  'and',\n",
       "  'has',\n",
       "  'nightmares',\n",
       "  '.',\n",
       "  'what',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'the',\n",
       "  'deal',\n",
       "  '?',\n",
       "  'watch',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'and',\n",
       "  '\"',\n",
       "  'sorta',\n",
       "  '\"',\n",
       "  'find',\n",
       "  'out',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'critique',\n",
       "  ':',\n",
       "  'a',\n",
       "  'mind',\n",
       "  '-',\n",
       "  'fuck',\n",
       "  'movie',\n",
       "  'for',\n",
       "  'the',\n",
       "  'teen',\n",
       "  'generation',\n",
       "  'that',\n",
       "  'touches',\n",
       "  'on',\n",
       "  'a',\n",
       "  'very',\n",
       "  'cool',\n",
       "  'idea',\n",
       "  ',',\n",
       "  'but',\n",
       "  'presents',\n",
       "  'it',\n",
       "  'in',\n",
       "  'a',\n",
       "  'very',\n",
       "  'bad',\n",
       "  'package',\n",
       "  '.',\n",
       "  'which',\n",
       "  'is',\n",
       "  'what',\n",
       "  'makes',\n",
       "  'this',\n",
       "  'review',\n",
       "  'an',\n",
       "  'even',\n",
       "  'harder',\n",
       "  'one',\n",
       "  'to',\n",
       "  'write',\n",
       "  ',',\n",
       "  'since',\n",
       "  'i',\n",
       "  'generally',\n",
       "  'applaud',\n",
       "  'films',\n",
       "  'which',\n",
       "  'attempt',\n",
       "  'to',\n",
       "  'break',\n",
       "  'the',\n",
       "  'mold',\n",
       "  ',',\n",
       "  'mess',\n",
       "  'with',\n",
       "  'your',\n",
       "  'head',\n",
       "  'and',\n",
       "  'such',\n",
       "  '(',\n",
       "  'lost',\n",
       "  'highway',\n",
       "  '&',\n",
       "  'memento',\n",
       "  ')',\n",
       "  ',',\n",
       "  'but',\n",
       "  'there',\n",
       "  'are',\n",
       "  'good',\n",
       "  'and',\n",
       "  'bad',\n",
       "  'ways',\n",
       "  'of',\n",
       "  'making',\n",
       "  'all',\n",
       "  'types',\n",
       "  'of',\n",
       "  'films',\n",
       "  ',',\n",
       "  'and',\n",
       "  'these',\n",
       "  'folks',\n",
       "  'just',\n",
       "  'didn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'snag',\n",
       "  'this',\n",
       "  'one',\n",
       "  'correctly',\n",
       "  '.',\n",
       "  'they',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'have',\n",
       "  'taken',\n",
       "  'this',\n",
       "  'pretty',\n",
       "  'neat',\n",
       "  'concept',\n",
       "  ',',\n",
       "  'but',\n",
       "  'executed',\n",
       "  'it',\n",
       "  'terribly',\n",
       "  '.',\n",
       "  'so',\n",
       "  'what',\n",
       "  'are',\n",
       "  'the',\n",
       "  'problems',\n",
       "  'with',\n",
       "  'the',\n",
       "  'movie',\n",
       "  '?',\n",
       "  'well',\n",
       "  ',',\n",
       "  'its',\n",
       "  'main',\n",
       "  'problem',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'simply',\n",
       "  'too',\n",
       "  'jumbled',\n",
       "  '.',\n",
       "  'it',\n",
       "  'starts',\n",
       "  'off',\n",
       "  '\"',\n",
       "  'normal',\n",
       "  '\"',\n",
       "  'but',\n",
       "  'then',\n",
       "  'downshifts',\n",
       "  'into',\n",
       "  'this',\n",
       "  '\"',\n",
       "  'fantasy',\n",
       "  '\"',\n",
       "  'world',\n",
       "  'in',\n",
       "  'which',\n",
       "  'you',\n",
       "  ',',\n",
       "  'as',\n",
       "  'an',\n",
       "  'audience',\n",
       "  'member',\n",
       "  ',',\n",
       "  'have',\n",
       "  'no',\n",
       "  'idea',\n",
       "  'what',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'going',\n",
       "  'on',\n",
       "  '.',\n",
       "  'there',\n",
       "  'are',\n",
       "  'dreams',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'characters',\n",
       "  'coming',\n",
       "  'back',\n",
       "  'from',\n",
       "  'the',\n",
       "  'dead',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'others',\n",
       "  'who',\n",
       "  'look',\n",
       "  'like',\n",
       "  'the',\n",
       "  'dead',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'strange',\n",
       "  'apparitions',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'disappearances',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'looooot',\n",
       "  'of',\n",
       "  'chase',\n",
       "  'scenes',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'tons',\n",
       "  'of',\n",
       "  'weird',\n",
       "  'things',\n",
       "  'that',\n",
       "  'happen',\n",
       "  ',',\n",
       "  'and',\n",
       "  'most',\n",
       "  'of',\n",
       "  'it',\n",
       "  'is',\n",
       "  'simply',\n",
       "  'not',\n",
       "  'explained',\n",
       "  '.',\n",
       "  'now',\n",
       "  'i',\n",
       "  'personally',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'mind',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'unravel',\n",
       "  'a',\n",
       "  'film',\n",
       "  'every',\n",
       "  'now',\n",
       "  'and',\n",
       "  'then',\n",
       "  ',',\n",
       "  'but',\n",
       "  'when',\n",
       "  'all',\n",
       "  'it',\n",
       "  'does',\n",
       "  'is',\n",
       "  'give',\n",
       "  'me',\n",
       "  'the',\n",
       "  'same',\n",
       "  'clue',\n",
       "  'over',\n",
       "  'and',\n",
       "  'over',\n",
       "  'again',\n",
       "  ',',\n",
       "  'i',\n",
       "  'get',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'fed',\n",
       "  'up',\n",
       "  'after',\n",
       "  'a',\n",
       "  'while',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'this',\n",
       "  'film',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'biggest',\n",
       "  'problem',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'obviously',\n",
       "  'got',\n",
       "  'this',\n",
       "  'big',\n",
       "  'secret',\n",
       "  'to',\n",
       "  'hide',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'want',\n",
       "  'to',\n",
       "  'hide',\n",
       "  'it',\n",
       "  'completely',\n",
       "  'until',\n",
       "  'its',\n",
       "  'final',\n",
       "  'five',\n",
       "  'minutes',\n",
       "  '.',\n",
       "  'and',\n",
       "  'do',\n",
       "  'they',\n",
       "  'make',\n",
       "  'things',\n",
       "  'entertaining',\n",
       "  ',',\n",
       "  'thrilling',\n",
       "  'or',\n",
       "  'even',\n",
       "  'engaging',\n",
       "  ',',\n",
       "  'in',\n",
       "  'the',\n",
       "  'meantime',\n",
       "  '?',\n",
       "  'not',\n",
       "  'really',\n",
       "  '.',\n",
       "  'the',\n",
       "  'sad',\n",
       "  'part',\n",
       "  'is',\n",
       "  'that',\n",
       "  'the',\n",
       "  'arrow',\n",
       "  'and',\n",
       "  'i',\n",
       "  'both',\n",
       "  'dig',\n",
       "  'on',\n",
       "  'flicks',\n",
       "  'like',\n",
       "  'this',\n",
       "  ',',\n",
       "  'so',\n",
       "  'we',\n",
       "  'actually',\n",
       "  'figured',\n",
       "  'most',\n",
       "  'of',\n",
       "  'it',\n",
       "  'out',\n",
       "  'by',\n",
       "  'the',\n",
       "  'half',\n",
       "  '-',\n",
       "  'way',\n",
       "  'point',\n",
       "  ',',\n",
       "  'so',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'strangeness',\n",
       "  'after',\n",
       "  'that',\n",
       "  'did',\n",
       "  'start',\n",
       "  'to',\n",
       "  'make',\n",
       "  'a',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'of',\n",
       "  'sense',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  'still',\n",
       "  'didn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'the',\n",
       "  'make',\n",
       "  'the',\n",
       "  'film',\n",
       "  'all',\n",
       "  'that',\n",
       "  'more',\n",
       "  'entertaining',\n",
       "  '.',\n",
       "  'i',\n",
       "  'guess',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  'line',\n",
       "  'with',\n",
       "  'movies',\n",
       "  'like',\n",
       "  'this',\n",
       "  'is',\n",
       "  'that',\n",
       "  'you',\n",
       "  'should',\n",
       "  'always',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'that',\n",
       "  'the',\n",
       "  'audience',\n",
       "  'is',\n",
       "  '\"',\n",
       "  'into',\n",
       "  'it',\n",
       "  '\"',\n",
       "  'even',\n",
       "  'before',\n",
       "  'they',\n",
       "  'are',\n",
       "  'given',\n",
       "  'the',\n",
       "  'secret',\n",
       "  'password',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'your',\n",
       "  'world',\n",
       "  'of',\n",
       "  'understanding',\n",
       "  '.',\n",
       "  'i',\n",
       "  'mean',\n",
       "  ',',\n",
       "  'showing',\n",
       "  'melissa',\n",
       "  'sagemiller',\n",
       "  'running',\n",
       "  'away',\n",
       "  'from',\n",
       "  'visions',\n",
       "  'for',\n",
       "  'about',\n",
       "  '20',\n",
       "  'minutes',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'is',\n",
       "  'just',\n",
       "  'plain',\n",
       "  'lazy',\n",
       "  '!',\n",
       "  '!',\n",
       "  'okay',\n",
       "  ',',\n",
       "  'we',\n",
       "  'get',\n",
       "  'it',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'there',\n",
       "  'are',\n",
       "  'people',\n",
       "  'chasing',\n",
       "  'her',\n",
       "  'and',\n",
       "  'we',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'who',\n",
       "  'they',\n",
       "  'are',\n",
       "  '.',\n",
       "  'do',\n",
       "  'we',\n",
       "  'really',\n",
       "  'need',\n",
       "  'to',\n",
       "  'see',\n",
       "  'it',\n",
       "  'over',\n",
       "  'and',\n",
       "  'over',\n",
       "  'again',\n",
       "  '?',\n",
       "  'how',\n",
       "  'about',\n",
       "  'giving',\n",
       "  'us',\n",
       "  'different',\n",
       "  'scenes',\n",
       "  'offering',\n",
       "  'further',\n",
       "  'insight',\n",
       "  'into',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'strangeness',\n",
       "  'going',\n",
       "  'down',\n",
       "  'in',\n",
       "  'the',\n",
       "  'movie',\n",
       "  '?',\n",
       "  'apparently',\n",
       "  ',',\n",
       "  'the',\n",
       "  'studio',\n",
       "  'took',\n",
       "  'this',\n",
       "  'film',\n",
       "  'away',\n",
       "  'from',\n",
       "  'its',\n",
       "  'director',\n",
       "  'and',\n",
       "  'chopped',\n",
       "  'it',\n",
       "  'up',\n",
       "  'themselves',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  'shows',\n",
       "  '.',\n",
       "  'there',\n",
       "  'might',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'been',\n",
       "  'a',\n",
       "  'pretty',\n",
       "  'decent',\n",
       "  'teen',\n",
       "  'mind',\n",
       "  '-',\n",
       "  'fuck',\n",
       "  'movie',\n",
       "  'in',\n",
       "  'here',\n",
       "  'somewhere',\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  'guess',\n",
       "  '\"',\n",
       "  'the',\n",
       "  'suits',\n",
       "  '\"',\n",
       "  'decided',\n",
       "  'that',\n",
       "  'turning',\n",
       "  'it',\n",
       "  'into',\n",
       "  'a',\n",
       "  'music',\n",
       "  'video',\n",
       "  'with',\n",
       "  'little',\n",
       "  'edge',\n",
       "  ',',\n",
       "  'would',\n",
       "  'make',\n",
       "  'more',\n",
       "  'sense',\n",
       "  '.',\n",
       "  'the',\n",
       "  'actors',\n",
       "  'are',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'for',\n",
       "  'the',\n",
       "  'most',\n",
       "  'part',\n",
       "  ',',\n",
       "  'although',\n",
       "  'wes',\n",
       "  'bentley',\n",
       "  'just',\n",
       "  'seemed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'playing',\n",
       "  'the',\n",
       "  'exact',\n",
       "  'same',\n",
       "  'character',\n",
       "  'that',\n",
       "  'he',\n",
       "  'did',\n",
       "  'in',\n",
       "  'american',\n",
       "  'beauty',\n",
       "  ',',\n",
       "  'only',\n",
       "  'in',\n",
       "  'a',\n",
       "  'new',\n",
       "  'neighborhood',\n",
       "  '.',\n",
       "  'but',\n",
       "  'my',\n",
       "  'biggest',\n",
       "  'kudos',\n",
       "  'go',\n",
       "  'out',\n",
       "  'to',\n",
       "  'sagemiller',\n",
       "  ',',\n",
       "  'who',\n",
       "  'holds',\n",
       "  'her',\n",
       "  'own',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'entire',\n",
       "  'film',\n",
       "  ',',\n",
       "  'and',\n",
       "  'actually',\n",
       "  'has',\n",
       "  'you',\n",
       "  'feeling',\n",
       "  'her',\n",
       "  'character',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'unraveling',\n",
       "  '.',\n",
       "  'overall',\n",
       "  ',',\n",
       "  'the',\n",
       "  'film',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'stick',\n",
       "  'because',\n",
       "  'it',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'entertain',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'confusing',\n",
       "  ',',\n",
       "  'it',\n",
       "  'rarely',\n",
       "  'excites',\n",
       "  'and',\n",
       "  'it',\n",
       "  'feels',\n",
       "  'pretty',\n",
       "  'redundant',\n",
       "  'for',\n",
       "  'most',\n",
       "  'of',\n",
       "  'its',\n",
       "  'runtime',\n",
       "  ',',\n",
       "  'despite',\n",
       "  'a',\n",
       "  'pretty',\n",
       "  'cool',\n",
       "  'ending',\n",
       "  'and',\n",
       "  'explanation',\n",
       "  'to',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'craziness',\n",
       "  'that',\n",
       "  'came',\n",
       "  'before',\n",
       "  'it',\n",
       "  '.',\n",
       "  'oh',\n",
       "  ',',\n",
       "  'and',\n",
       "  'by',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'this',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'horror',\n",
       "  'or',\n",
       "  'teen',\n",
       "  'slasher',\n",
       "  'flick',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'just',\n",
       "  'packaged',\n",
       "  'to',\n",
       "  'look',\n",
       "  'that',\n",
       "  'way',\n",
       "  'because',\n",
       "  'someone',\n",
       "  'is',\n",
       "  'apparently',\n",
       "  'assuming',\n",
       "  'that',\n",
       "  'the',\n",
       "  'genre',\n",
       "  'is',\n",
       "  'still',\n",
       "  'hot',\n",
       "  'with',\n",
       "  'the',\n",
       "  'kids',\n",
       "  '.',\n",
       "  'it',\n",
       "  'also',\n",
       "  'wrapped',\n",
       "  'production',\n",
       "  'two',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'and',\n",
       "  'has',\n",
       "  'been',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'the',\n",
       "  'shelves',\n",
       "  'ever',\n",
       "  'since',\n",
       "  '.',\n",
       "  'whatever',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'skip',\n",
       "  'it',\n",
       "  '!',\n",
       "  'where',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'joblo',\n",
       "  'coming',\n",
       "  'from',\n",
       "  '?',\n",
       "  'a',\n",
       "  'nightmare',\n",
       "  'of',\n",
       "  'elm',\n",
       "  'street',\n",
       "  '3',\n",
       "  '(',\n",
       "  '7',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'blair',\n",
       "  'witch',\n",
       "  '2',\n",
       "  '(',\n",
       "  '7',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'the',\n",
       "  'crow',\n",
       "  '(',\n",
       "  '9',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'the',\n",
       "  'crow',\n",
       "  ':',\n",
       "  'salvation',\n",
       "  '(',\n",
       "  '4',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'lost',\n",
       "  'highway',\n",
       "  '(',\n",
       "  '10',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'memento',\n",
       "  '(',\n",
       "  '10',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'the',\n",
       "  'others',\n",
       "  '(',\n",
       "  '9',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')',\n",
       "  '-',\n",
       "  'stir',\n",
       "  'of',\n",
       "  'echoes',\n",
       "  '(',\n",
       "  '8',\n",
       "  '/',\n",
       "  '10',\n",
       "  ')']]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['plot',\n",
       "   ':',\n",
       "   'two',\n",
       "   'teen',\n",
       "   'couples',\n",
       "   'go',\n",
       "   'to',\n",
       "   'a',\n",
       "   'church',\n",
       "   'party',\n",
       "   ',',\n",
       "   'drink',\n",
       "   'and',\n",
       "   'then',\n",
       "   'drive',\n",
       "   '.',\n",
       "   'they',\n",
       "   'get',\n",
       "   'into',\n",
       "   'an',\n",
       "   'accident',\n",
       "   '.',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'guys',\n",
       "   'dies',\n",
       "   ',',\n",
       "   'but',\n",
       "   'his',\n",
       "   'girlfriend',\n",
       "   'continues',\n",
       "   'to',\n",
       "   'see',\n",
       "   'him',\n",
       "   'in',\n",
       "   'her',\n",
       "   'life',\n",
       "   ',',\n",
       "   'and',\n",
       "   'has',\n",
       "   'nightmares',\n",
       "   '.',\n",
       "   'what',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'the',\n",
       "   'deal',\n",
       "   '?',\n",
       "   'watch',\n",
       "   'the',\n",
       "   'movie',\n",
       "   'and',\n",
       "   '\"',\n",
       "   'sorta',\n",
       "   '\"',\n",
       "   'find',\n",
       "   'out',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   'critique',\n",
       "   ':',\n",
       "   'a',\n",
       "   'mind',\n",
       "   '-',\n",
       "   'fuck',\n",
       "   'movie',\n",
       "   'for',\n",
       "   'the',\n",
       "   'teen',\n",
       "   'generation',\n",
       "   'that',\n",
       "   'touches',\n",
       "   'on',\n",
       "   'a',\n",
       "   'very',\n",
       "   'cool',\n",
       "   'idea',\n",
       "   ',',\n",
       "   'but',\n",
       "   'presents',\n",
       "   'it',\n",
       "   'in',\n",
       "   'a',\n",
       "   'very',\n",
       "   'bad',\n",
       "   'package',\n",
       "   '.',\n",
       "   'which',\n",
       "   'is',\n",
       "   'what',\n",
       "   'makes',\n",
       "   'this',\n",
       "   'review',\n",
       "   'an',\n",
       "   'even',\n",
       "   'harder',\n",
       "   'one',\n",
       "   'to',\n",
       "   'write',\n",
       "   ',',\n",
       "   'since',\n",
       "   'i',\n",
       "   'generally',\n",
       "   'applaud',\n",
       "   'films',\n",
       "   'which',\n",
       "   'attempt',\n",
       "   'to',\n",
       "   'break',\n",
       "   'the',\n",
       "   'mold',\n",
       "   ',',\n",
       "   'mess',\n",
       "   'with',\n",
       "   'your',\n",
       "   'head',\n",
       "   'and',\n",
       "   'such',\n",
       "   '(',\n",
       "   'lost',\n",
       "   'highway',\n",
       "   '&',\n",
       "   'memento',\n",
       "   ')',\n",
       "   ',',\n",
       "   'but',\n",
       "   'there',\n",
       "   'are',\n",
       "   'good',\n",
       "   'and',\n",
       "   'bad',\n",
       "   'ways',\n",
       "   'of',\n",
       "   'making',\n",
       "   'all',\n",
       "   'types',\n",
       "   'of',\n",
       "   'films',\n",
       "   ',',\n",
       "   'and',\n",
       "   'these',\n",
       "   'folks',\n",
       "   'just',\n",
       "   'didn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'snag',\n",
       "   'this',\n",
       "   'one',\n",
       "   'correctly',\n",
       "   '.',\n",
       "   'they',\n",
       "   'seem',\n",
       "   'to',\n",
       "   'have',\n",
       "   'taken',\n",
       "   'this',\n",
       "   'pretty',\n",
       "   'neat',\n",
       "   'concept',\n",
       "   ',',\n",
       "   'but',\n",
       "   'executed',\n",
       "   'it',\n",
       "   'terribly',\n",
       "   '.',\n",
       "   'so',\n",
       "   'what',\n",
       "   'are',\n",
       "   'the',\n",
       "   'problems',\n",
       "   'with',\n",
       "   'the',\n",
       "   'movie',\n",
       "   '?',\n",
       "   'well',\n",
       "   ',',\n",
       "   'its',\n",
       "   'main',\n",
       "   'problem',\n",
       "   'is',\n",
       "   'that',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'simply',\n",
       "   'too',\n",
       "   'jumbled',\n",
       "   '.',\n",
       "   'it',\n",
       "   'starts',\n",
       "   'off',\n",
       "   '\"',\n",
       "   'normal',\n",
       "   '\"',\n",
       "   'but',\n",
       "   'then',\n",
       "   'downshifts',\n",
       "   'into',\n",
       "   'this',\n",
       "   '\"',\n",
       "   'fantasy',\n",
       "   '\"',\n",
       "   'world',\n",
       "   'in',\n",
       "   'which',\n",
       "   'you',\n",
       "   ',',\n",
       "   'as',\n",
       "   'an',\n",
       "   'audience',\n",
       "   'member',\n",
       "   ',',\n",
       "   'have',\n",
       "   'no',\n",
       "   'idea',\n",
       "   'what',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'going',\n",
       "   'on',\n",
       "   '.',\n",
       "   'there',\n",
       "   'are',\n",
       "   'dreams',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'characters',\n",
       "   'coming',\n",
       "   'back',\n",
       "   'from',\n",
       "   'the',\n",
       "   'dead',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'others',\n",
       "   'who',\n",
       "   'look',\n",
       "   'like',\n",
       "   'the',\n",
       "   'dead',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'strange',\n",
       "   'apparitions',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'disappearances',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'a',\n",
       "   'looooot',\n",
       "   'of',\n",
       "   'chase',\n",
       "   'scenes',\n",
       "   ',',\n",
       "   'there',\n",
       "   'are',\n",
       "   'tons',\n",
       "   'of',\n",
       "   'weird',\n",
       "   'things',\n",
       "   'that',\n",
       "   'happen',\n",
       "   ',',\n",
       "   'and',\n",
       "   'most',\n",
       "   'of',\n",
       "   'it',\n",
       "   'is',\n",
       "   'simply',\n",
       "   'not',\n",
       "   'explained',\n",
       "   '.',\n",
       "   'now',\n",
       "   'i',\n",
       "   'personally',\n",
       "   'don',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'mind',\n",
       "   'trying',\n",
       "   'to',\n",
       "   'unravel',\n",
       "   'a',\n",
       "   'film',\n",
       "   'every',\n",
       "   'now',\n",
       "   'and',\n",
       "   'then',\n",
       "   ',',\n",
       "   'but',\n",
       "   'when',\n",
       "   'all',\n",
       "   'it',\n",
       "   'does',\n",
       "   'is',\n",
       "   'give',\n",
       "   'me',\n",
       "   'the',\n",
       "   'same',\n",
       "   'clue',\n",
       "   'over',\n",
       "   'and',\n",
       "   'over',\n",
       "   'again',\n",
       "   ',',\n",
       "   'i',\n",
       "   'get',\n",
       "   'kind',\n",
       "   'of',\n",
       "   'fed',\n",
       "   'up',\n",
       "   'after',\n",
       "   'a',\n",
       "   'while',\n",
       "   ',',\n",
       "   'which',\n",
       "   'is',\n",
       "   'this',\n",
       "   'film',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'biggest',\n",
       "   'problem',\n",
       "   '.',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'obviously',\n",
       "   'got',\n",
       "   'this',\n",
       "   'big',\n",
       "   'secret',\n",
       "   'to',\n",
       "   'hide',\n",
       "   ',',\n",
       "   'but',\n",
       "   'it',\n",
       "   'seems',\n",
       "   'to',\n",
       "   'want',\n",
       "   'to',\n",
       "   'hide',\n",
       "   'it',\n",
       "   'completely',\n",
       "   'until',\n",
       "   'its',\n",
       "   'final',\n",
       "   'five',\n",
       "   'minutes',\n",
       "   '.',\n",
       "   'and',\n",
       "   'do',\n",
       "   'they',\n",
       "   'make',\n",
       "   'things',\n",
       "   'entertaining',\n",
       "   ',',\n",
       "   'thrilling',\n",
       "   'or',\n",
       "   'even',\n",
       "   'engaging',\n",
       "   ',',\n",
       "   'in',\n",
       "   'the',\n",
       "   'meantime',\n",
       "   '?',\n",
       "   'not',\n",
       "   'really',\n",
       "   '.',\n",
       "   'the',\n",
       "   'sad',\n",
       "   'part',\n",
       "   'is',\n",
       "   'that',\n",
       "   'the',\n",
       "   'arrow',\n",
       "   'and',\n",
       "   'i',\n",
       "   'both',\n",
       "   'dig',\n",
       "   'on',\n",
       "   'flicks',\n",
       "   'like',\n",
       "   'this',\n",
       "   ',',\n",
       "   'so',\n",
       "   'we',\n",
       "   'actually',\n",
       "   'figured',\n",
       "   'most',\n",
       "   'of',\n",
       "   'it',\n",
       "   'out',\n",
       "   'by',\n",
       "   'the',\n",
       "   'half',\n",
       "   '-',\n",
       "   'way',\n",
       "   'point',\n",
       "   ',',\n",
       "   'so',\n",
       "   'all',\n",
       "   'of',\n",
       "   'the',\n",
       "   'strangeness',\n",
       "   'after',\n",
       "   'that',\n",
       "   'did',\n",
       "   'start',\n",
       "   'to',\n",
       "   'make',\n",
       "   'a',\n",
       "   'little',\n",
       "   'bit',\n",
       "   'of',\n",
       "   'sense',\n",
       "   ',',\n",
       "   'but',\n",
       "   'it',\n",
       "   'still',\n",
       "   'didn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'the',\n",
       "   'make',\n",
       "   'the',\n",
       "   'film',\n",
       "   'all',\n",
       "   'that',\n",
       "   'more',\n",
       "   'entertaining',\n",
       "   '.',\n",
       "   'i',\n",
       "   'guess',\n",
       "   'the',\n",
       "   'bottom',\n",
       "   'line',\n",
       "   'with',\n",
       "   'movies',\n",
       "   'like',\n",
       "   'this',\n",
       "   'is',\n",
       "   'that',\n",
       "   'you',\n",
       "   'should',\n",
       "   'always',\n",
       "   'make',\n",
       "   'sure',\n",
       "   'that',\n",
       "   'the',\n",
       "   'audience',\n",
       "   'is',\n",
       "   '\"',\n",
       "   'into',\n",
       "   'it',\n",
       "   '\"',\n",
       "   'even',\n",
       "   'before',\n",
       "   'they',\n",
       "   'are',\n",
       "   'given',\n",
       "   'the',\n",
       "   'secret',\n",
       "   'password',\n",
       "   'to',\n",
       "   'enter',\n",
       "   'your',\n",
       "   'world',\n",
       "   'of',\n",
       "   'understanding',\n",
       "   '.',\n",
       "   'i',\n",
       "   'mean',\n",
       "   ',',\n",
       "   'showing',\n",
       "   'melissa',\n",
       "   'sagemiller',\n",
       "   'running',\n",
       "   'away',\n",
       "   'from',\n",
       "   'visions',\n",
       "   'for',\n",
       "   'about',\n",
       "   '20',\n",
       "   'minutes',\n",
       "   'throughout',\n",
       "   'the',\n",
       "   'movie',\n",
       "   'is',\n",
       "   'just',\n",
       "   'plain',\n",
       "   'lazy',\n",
       "   '!',\n",
       "   '!',\n",
       "   'okay',\n",
       "   ',',\n",
       "   'we',\n",
       "   'get',\n",
       "   'it',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   'there',\n",
       "   'are',\n",
       "   'people',\n",
       "   'chasing',\n",
       "   'her',\n",
       "   'and',\n",
       "   'we',\n",
       "   'don',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'know',\n",
       "   'who',\n",
       "   'they',\n",
       "   'are',\n",
       "   '.',\n",
       "   'do',\n",
       "   'we',\n",
       "   'really',\n",
       "   'need',\n",
       "   'to',\n",
       "   'see',\n",
       "   'it',\n",
       "   'over',\n",
       "   'and',\n",
       "   'over',\n",
       "   'again',\n",
       "   '?',\n",
       "   'how',\n",
       "   'about',\n",
       "   'giving',\n",
       "   'us',\n",
       "   'different',\n",
       "   'scenes',\n",
       "   'offering',\n",
       "   'further',\n",
       "   'insight',\n",
       "   'into',\n",
       "   'all',\n",
       "   'of',\n",
       "   'the',\n",
       "   'strangeness',\n",
       "   'going',\n",
       "   'down',\n",
       "   'in',\n",
       "   'the',\n",
       "   'movie',\n",
       "   '?',\n",
       "   'apparently',\n",
       "   ',',\n",
       "   'the',\n",
       "   'studio',\n",
       "   'took',\n",
       "   'this',\n",
       "   'film',\n",
       "   'away',\n",
       "   'from',\n",
       "   'its',\n",
       "   'director',\n",
       "   'and',\n",
       "   'chopped',\n",
       "   'it',\n",
       "   'up',\n",
       "   'themselves',\n",
       "   ',',\n",
       "   'and',\n",
       "   'it',\n",
       "   'shows',\n",
       "   '.',\n",
       "   'there',\n",
       "   'might',\n",
       "   \"'\",\n",
       "   've',\n",
       "   'been',\n",
       "   'a',\n",
       "   'pretty',\n",
       "   'decent',\n",
       "   'teen',\n",
       "   'mind',\n",
       "   '-',\n",
       "   'fuck',\n",
       "   'movie',\n",
       "   'in',\n",
       "   'here',\n",
       "   'somewhere',\n",
       "   ',',\n",
       "   'but',\n",
       "   'i',\n",
       "   'guess',\n",
       "   '\"',\n",
       "   'the',\n",
       "   'suits',\n",
       "   '\"',\n",
       "   'decided',\n",
       "   'that',\n",
       "   'turning',\n",
       "   'it',\n",
       "   'into',\n",
       "   'a',\n",
       "   'music',\n",
       "   'video',\n",
       "   'with',\n",
       "   'little',\n",
       "   'edge',\n",
       "   ',',\n",
       "   'would',\n",
       "   'make',\n",
       "   'more',\n",
       "   'sense',\n",
       "   '.',\n",
       "   'the',\n",
       "   'actors',\n",
       "   'are',\n",
       "   'pretty',\n",
       "   'good',\n",
       "   'for',\n",
       "   'the',\n",
       "   'most',\n",
       "   'part',\n",
       "   ',',\n",
       "   'although',\n",
       "   'wes',\n",
       "   'bentley',\n",
       "   'just',\n",
       "   'seemed',\n",
       "   'to',\n",
       "   'be',\n",
       "   'playing',\n",
       "   'the',\n",
       "   'exact',\n",
       "   'same',\n",
       "   'character',\n",
       "   'that',\n",
       "   'he',\n",
       "   'did',\n",
       "   'in',\n",
       "   'american',\n",
       "   'beauty',\n",
       "   ',',\n",
       "   'only',\n",
       "   'in',\n",
       "   'a',\n",
       "   'new',\n",
       "   'neighborhood',\n",
       "   '.',\n",
       "   'but',\n",
       "   'my',\n",
       "   'biggest',\n",
       "   'kudos',\n",
       "   'go',\n",
       "   'out',\n",
       "   'to',\n",
       "   'sagemiller',\n",
       "   ',',\n",
       "   'who',\n",
       "   'holds',\n",
       "   'her',\n",
       "   'own',\n",
       "   'throughout',\n",
       "   'the',\n",
       "   'entire',\n",
       "   'film',\n",
       "   ',',\n",
       "   'and',\n",
       "   'actually',\n",
       "   'has',\n",
       "   'you',\n",
       "   'feeling',\n",
       "   'her',\n",
       "   'character',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'unraveling',\n",
       "   '.',\n",
       "   'overall',\n",
       "   ',',\n",
       "   'the',\n",
       "   'film',\n",
       "   'doesn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'stick',\n",
       "   'because',\n",
       "   'it',\n",
       "   'doesn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'entertain',\n",
       "   ',',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'confusing',\n",
       "   ',',\n",
       "   'it',\n",
       "   'rarely',\n",
       "   'excites',\n",
       "   'and',\n",
       "   'it',\n",
       "   'feels',\n",
       "   'pretty',\n",
       "   'redundant',\n",
       "   'for',\n",
       "   'most',\n",
       "   'of',\n",
       "   'its',\n",
       "   'runtime',\n",
       "   ',',\n",
       "   'despite',\n",
       "   'a',\n",
       "   'pretty',\n",
       "   'cool',\n",
       "   'ending',\n",
       "   'and',\n",
       "   'explanation',\n",
       "   'to',\n",
       "   'all',\n",
       "   'of',\n",
       "   'the',\n",
       "   'craziness',\n",
       "   'that',\n",
       "   'came',\n",
       "   'before',\n",
       "   'it',\n",
       "   '.',\n",
       "   'oh',\n",
       "   ',',\n",
       "   'and',\n",
       "   'by',\n",
       "   'the',\n",
       "   'way',\n",
       "   ',',\n",
       "   'this',\n",
       "   'is',\n",
       "   'not',\n",
       "   'a',\n",
       "   'horror',\n",
       "   'or',\n",
       "   'teen',\n",
       "   'slasher',\n",
       "   'flick',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'just',\n",
       "   'packaged',\n",
       "   'to',\n",
       "   'look',\n",
       "   'that',\n",
       "   'way',\n",
       "   'because',\n",
       "   'someone',\n",
       "   'is',\n",
       "   'apparently',\n",
       "   'assuming',\n",
       "   'that',\n",
       "   'the',\n",
       "   'genre',\n",
       "   'is',\n",
       "   'still',\n",
       "   'hot',\n",
       "   'with',\n",
       "   'the',\n",
       "   'kids',\n",
       "   '.',\n",
       "   'it',\n",
       "   'also',\n",
       "   'wrapped',\n",
       "   'production',\n",
       "   'two',\n",
       "   'years',\n",
       "   'ago',\n",
       "   'and',\n",
       "   'has',\n",
       "   'been',\n",
       "   'sitting',\n",
       "   'on',\n",
       "   'the',\n",
       "   'shelves',\n",
       "   'ever',\n",
       "   'since',\n",
       "   '.',\n",
       "   'whatever',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   'skip',\n",
       "   'it',\n",
       "   '!',\n",
       "   'where',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'joblo',\n",
       "   'coming',\n",
       "   'from',\n",
       "   '?',\n",
       "   'a',\n",
       "   'nightmare',\n",
       "   'of',\n",
       "   'elm',\n",
       "   'street',\n",
       "   '3',\n",
       "   '(',\n",
       "   '7',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'blair',\n",
       "   'witch',\n",
       "   '2',\n",
       "   '(',\n",
       "   '7',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'the',\n",
       "   'crow',\n",
       "   '(',\n",
       "   '9',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'the',\n",
       "   'crow',\n",
       "   ':',\n",
       "   'salvation',\n",
       "   '(',\n",
       "   '4',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'lost',\n",
       "   'highway',\n",
       "   '(',\n",
       "   '10',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'memento',\n",
       "   '(',\n",
       "   '10',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'the',\n",
       "   'others',\n",
       "   '(',\n",
       "   '9',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')',\n",
       "   '-',\n",
       "   'stir',\n",
       "   'of',\n",
       "   'echoes',\n",
       "   '(',\n",
       "   '8',\n",
       "   '/',\n",
       "   '10',\n",
       "   ')'],\n",
       "  'neg')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer1.txt', 'w') as f:\n",
    "    f.write(str(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(documents, exclude=['docs'], columns = ['docs' , 'cat']) \n",
    "df.cat = df.cat.map({'neg':0, 'pos':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion: 0.5 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df.cat.value_counts()\n",
    "p = np.round(counts[1] / sum(counts), 2)\n",
    "print('Proportion:', p , ': 1')\n",
    "\n",
    "counts.plot(kind='bar', title='Neg/Pos');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('answer2.txt', 'w') as f:\n",
    "    f.write(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\" \".join(x) for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer=lambda doc: doc, lowercase=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x39659 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 666842 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer3.txt', 'w') as f:\n",
    "    f.write(str(bow.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81437126, 0.84684685, 0.84684685])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LR, bow, df.cat, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360216503929078"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_acc = np.mean(cross_val_score(LR, bow, df.cat, scoring = 'accuracy'))\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer4.txt', 'w') as f:\n",
    "    f.write(str(mean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9107764937833774"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_roc_auc = np.mean(cross_val_score(LR, bow, df.cat, scoring = 'roc_auc'))\n",
    "mean_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer5.txt', 'w') as f:\n",
    "    f.write(str(mean_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmp = make_pipeline(vectorizer, LR)\\nmp.fit(docs, df.cat)\\nfp = mp.predict(docs)\\ncross_val_score(mp, df.cat,scoring = 'roc_auc'\\n\""
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mp = make_pipeline(vectorizer, LR)\n",
    "mp.fit(docs, df.cat)\n",
    "fp = mp.predict(docs)\n",
    "cross_val_score(mp, df.cat,scoring = 'roc_auc'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unfortunately'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[37056]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(bow, df.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.13519839e-02 -1.78935973e-02  2.51622303e-06 ... -7.15497974e-03\n",
      "   3.79020749e-04 -1.40853359e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(LR.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = np.argsort(np.abs(LR.coef_[0]))[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38417, 14159, 39195, 37056,  2954])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = np.array(vectorizer.get_feature_names())[top_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = \" \".join(top5[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unfortunately bad'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer6.txt', 'w') as f:\n",
    "        f.write(top2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_CV_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])\n",
    "pipe_TFIDF_LR = Pipeline([\n",
    "       ('TFIDF', TfidfVectorizer()),\n",
    "       ('LR', linear_model.LogisticRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substract_means(pipeline, X, y):\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, n_jobs=-1)\n",
    "    mean = scores.mean()\n",
    "    std = scores.std()\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('LR',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_CV_LR.fit(docs, df.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_CV_LR = cross_val_score(pipe_CV_LR, docs, df.cat, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = scores_CV_LR.mean()\n",
    "std1 = scores_CV_LR.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_TFIDF_LR = cross_val_score(pipe_TFIDF_LR, docs, df.cat, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean2 = scores_TFIDF_LR.mean()\n",
    "std2 = scores_TFIDF_LR.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer2_1.txt', 'w') as f:\n",
    "    f.write('{:f} {:f} {:0f} {:f}'.format(mean1, std1, mean2, std2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'vectorizer__min_df': 10}, 0.839)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'vectorizer__min_df':[10, 20, 30, 40, 50]}]\n",
    "\n",
    "GS = GridSearchCV(pipe_CV_LR, param_grid = param_grid, cv=5)\n",
    "GS.fit(docs, df.cat)\n",
    "GS.best_params_, GS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_cv = cross_val_score(GS, docs, df.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81287425, 0.83333333, 0.84534535])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_CV10_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(min_df = 10)),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "         ])\n",
    "pipe_CV50_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(min_df = 50)),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_10 = cross_val_score(pipe_CV10_LR, docs, df.cat, cv=5, n_jobs=-1)\n",
    "cv_50 = cross_val_score(pipe_CV50_LR, docs, df.cat, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.82  , 0.85  , 0.8325, 0.8525, 0.84  ]),\n",
       " array([0.7925, 0.825 , 0.8025, 0.8175, 0.8275]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_10, cv_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer2_2.txt', 'w') as f:\n",
    "    f.write('{} {}'.format(cv_10.mean(), cv_50.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_CV_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])\n",
    "pipe_CV_SVC = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('SVC', LinearSVC())\n",
    "    ])\n",
    "pipe_CV_SGD = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('SGD', linear_model.SGDClassifier(random_state=42))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_comparsion(pipe1, pipe2, pipe3, X, y):\n",
    "    scores = []\n",
    "    scores1 = cross_val_score(pipe1, X, y, cv=5, n_jobs=-1)\n",
    "    scores2 = cross_val_score(pipe2, X, y, cv=5, n_jobs=-1)\n",
    "    scores3 = cross_val_score(pipe3, X, y, cv=5, n_jobs=-1)\n",
    "    scores = np.append(scores, [scores1, scores2, scores3])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = scores_comparsion(pipe_CV_LR, pipe_CV_SVC, pipe_CV_SGD, docs, df.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.815 , 0.84  , 0.8375, 0.8675, 0.845 , 0.8025, 0.84  , 0.83  ,\n",
       "       0.85  , 0.84  , 0.7975, 0.8375, 0.8325, 0.8525, 0.855 ])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7975"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer2_3.txt', 'w') as f:\n",
    "    f.write('{}'.format(np.min(sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hq/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_CVnltk_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=stopwords.words('english'))),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])\n",
    "pipe_CVself_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.8225, 0.855 , 0.835 , 0.8475, 0.845 ]),\n",
       " array([0.82  , 0.84  , 0.845 , 0.8425, 0.8475]))"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_nltk = cross_val_score(pipe_CVnltk_LR, docs, df.cat, cv=5, n_jobs=-1)\n",
    "cv_self = cross_val_score(pipe_CVself_LR, docs, df.cat, cv=5, n_jobs=-1)\n",
    "\n",
    "cv_nltk, cv_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nltk = cv_nltk.mean()\n",
    "std_nltk = cv_nltk.std()\n",
    "\n",
    "mean_self = cv_self.mean()\n",
    "std_self = cv_self.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer2_44.txt', 'w') as f:\n",
    "    f.write('{} {}'.format(mean_nltk, mean_self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_CV12_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])\n",
    "pipe_CV35_LR = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(3,5), analyzer='char_wb')),\n",
    "        ('LR', linear_model.LogisticRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_12 = cross_val_score(pipe_CV12_LR, docs, df.cat, cv=5, n_jobs=-1)\n",
    "cv_35 = cross_val_score(pipe_CV35_LR, docs, df.cat, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer2_5.txt', 'w') as f:\n",
    "    f.write('{} {}'.format(cv_12.mean(), cv_35.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
